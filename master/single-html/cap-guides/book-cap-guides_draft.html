<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Deployment, Administration, and User Guides | SUSE Cloud Application Platform 2.1.0</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" /><meta name="generator" content="DAPS 3.0.0 (https://opensuse.github.io/daps) using SUSE XSL Stylesheets 2.0.17 (based on DocBook XSL Stylesheets 1.79.2)" /><meta name="product-name" content="SUSE Cloud Application Platform" /><meta name="product-number" content="2.1.0" /><meta name="book-title" content="Deployment, Administration, and User Guides" /><meta name="description" content="Introducing SUSE Cloud Application Platform, a software platform for cloud-native application deployment based on KubeCF and Kubernetes." /><meta name="tracker-url" content="https://github.com/SUSE/doc-cap/issues/new" /><meta name="tracker-type" content="gh" /><meta name="tracker-gh-assignee" content="btat" /><meta name="tracker-gh-labels" content="bug,low priority" />
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css"></link>');
}
else {
  document.write('<link rel="stylesheet" type="text/css" href="static/css/fonts-onlylocal.css"></link>');
}

</script><noscript><link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css" /></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft single offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a></div><div id="_outer-wrap"><div id="_white-bg" style="background-color: #FABEBE;"><div id="_header"><div id="_logo"><img src="static/images/logo.png" alt="Logo" /></div><div class="crumbs inactive"><a class="single-crumb" href="#book-cap-guides" accesskey="c"><span class="single-contents-icon"></span>Deployment, Administration, and User Guides</a><div class="bubble-corner active-contents"></div></div><div class="clearme"></div></div></div><div id="_fixed-header-wrap" style="background-color: #FABEBE;" class="inactive"><div id="_fixed-header"><div class="crumbs inactive"><a class="single-crumb" href="#book-cap-guides" accesskey="c"><span class="single-contents-icon"></span>Show Contents: Deployment, Administration, and User Guides</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="clearme"></div></div><div class="clearme"></div></div><div class="active-contents bubble"><div class="bubble-container"><div id="_bubble-toc"><ol><li class="inactive"><a href="#preface-deployment"><span class="number"> </span><span class="name">About This Guide</span></a></li><li class="inactive"><a href="#part-cap-overview"><span class="number">I </span><span class="name">Overview of SUSE Cloud Application Platform</span></a><ol><li class="inactive"><a href="#cha-cap-overview"><span class="number">1 </span><span class="name">About SUSE Cloud Application Platform</span></a></li><li class="inactive"><a href="#cha-cap-depl-kube-requirements"><span class="number">2 </span><span class="name">Other Kubernetes Systems</span></a></li></ol></li><li class="inactive"><a href="#part-cap-deployment"><span class="number">II </span><span class="name">Deploying SUSE Cloud Application Platform</span></a><ol><li class="inactive"><a href="#cha-cap-depl-notes"><span class="number">3 </span><span class="name">Deployment and Administration Notes</span></a></li><li class="inactive"><a href="#cha-cap-depl-caasp"><span class="number">4 </span><span class="name">Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</span></a></li><li class="inactive"><a href="#cha-cap-depl-aks"><span class="number">5 </span><span class="name">Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</span></a></li><li class="inactive"><a href="#cha-cap-depl-eks"><span class="number">6 </span><span class="name">Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</span></a></li><li class="inactive"><a href="#cha-cap-depl-gke"><span class="number">7 </span><span class="name">Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</span></a></li><li class="inactive"><a href="#cha-cap-install-stratos"><span class="number">8 </span><span class="name">Installing the Stratos Web Console</span></a></li><li class="inactive"><a href="#cha-cap-depl-eirini"><span class="number">9 </span><span class="name">Eirini</span></a></li><li class="inactive"><a href="#cha-cap-depl-terraform"><span class="number">10 </span><span class="name">Deploying SUSE Cloud Application Platform Using Terraform</span></a></li><li class="inactive"><a href="#cha-cap-depl-air-gap-registry"><span class="number">11 </span><span class="name">Setting Up a Registry for an Air Gapped Environment</span></a></li><li class="inactive"><a href="#cha-cap-depl-private-registry"><span class="number">12 </span><span class="name">SUSE Private Registry</span></a></li></ol></li><li class="inactive"><a href="#part-cap-administration"><span class="number">III </span><span class="name">SUSE Cloud Application Platform Administration</span></a><ol><li class="inactive"><a href="#cha-cap-upgrade"><span class="number">13 </span><span class="name">Upgrading SUSE Cloud Application Platform</span></a></li><li class="inactive"><a href="#cha-cap-configuration-changes"><span class="number">14 </span><span class="name">Configuration Changes</span></a></li><li class="inactive"><a href="#cha-cap-create-admin-user"><span class="number">15 </span><span class="name">Creating Admin Users</span></a></li><li class="inactive"><a href="#cha-cap-manage-passwords"><span class="number">16 </span><span class="name">Managing Passwords</span></a></li><li class="inactive"><a href="#cha-cap-uaa-ui"><span class="number">17 </span><span class="name">Accessing the UAA User Interface</span></a></li><li class="inactive"><a href="#cha-cap-memory-limits"><span class="number">18 </span><span class="name">Container Memory Limits and Requests</span></a></li><li class="inactive"><a href="#cha-cap-ccdb-secret-rotation"><span class="number">19 </span><span class="name">Cloud Controller Database Secret Rotation</span></a></li><li class="inactive"><a href="#cha-cap-secrets-rotation"><span class="number">20 </span><span class="name">Rotating Automatically Generated Secrets</span></a></li><li class="inactive"><a href="#cha-cap-backup-restore"><span class="number">21 </span><span class="name">Backup and Restore</span></a></li><li class="inactive"><a href="#cha-cap-service-brokers"><span class="number">22 </span><span class="name">Service Brokers</span></a></li><li class="inactive"><a href="#cha-cap-app-autoscaler"><span class="number">23 </span><span class="name">App-AutoScaler</span></a></li><li class="inactive"><a href="#cha-cap-credhub"><span class="number">24 </span><span class="name">Integrating CredHub with SUSE Cloud Application Platform</span></a></li><li class="inactive"><a href="#cha-cap-buildpacks"><span class="number">25 </span><span class="name">Buildpacks</span></a></li></ol></li><li class="inactive"><a href="#part-cap-user-guide"><span class="number">IV </span><span class="name">SUSE Cloud Application Platform User Guide</span></a><ol><li class="inactive"><a href="#cha-cap-cf-cli"><span class="number">26 </span><span class="name">Deploying and Managing Applications with the Cloud Foundry Client</span></a></li></ol></li><li class="inactive"><a href="#part-cap-troubleshooting"><span class="number">V </span><span class="name">Troubleshooting</span></a><ol><li class="inactive"><a href="#cha-cap-depl-troubleshooting"><span class="number">27 </span><span class="name">Troubleshooting</span></a></li></ol></li><li class="inactive"><a href="#id-1.3.8"><span class="number">A </span><span class="name">Appendix</span></a></li><li class="inactive"><a href="#id-1.3.9"><span class="number">B </span><span class="name">GNU Licenses</span></a></li></ol></div><div class="clearme"></div></div></div></div><div id="_toc-bubble-wrap"></div><div id="_content" class="draft "><div class="documentation"><div xml:lang="en" class="book" id="book-cap-guides" lang="en"><div class="titlepage"><div><h6 class="version-info"><span class="productname ">SUSE Cloud Application Platform</span> <span class="productnumber ">2.1.0</span></h6><div><h1 class="title"><em class="citetitle ">Deployment, Administration, and User Guide</em>s</h1></div><div class="abstract "><p>
    Introducing SUSE Cloud Application Platform, a software platform for cloud-native application
    deployment based on KubeCF and Kubernetes.
   </p></div><div class="authorgroup"><div><span class="imprint-label">Authors: </span><span class="firstname ">Carla</span> <span class="surname ">Schroder</span>, <span class="firstname ">Billy</span> <span class="surname ">Tat</span>, <span class="firstname ">Claudia-Amelia</span> <span class="surname ">Marin</span>, and <span class="firstname ">Lukas</span> <span class="surname ">Kucharczyk</span></div></div><div class="date"><span class="imprint-label">Publication Date: </span>
February 25, 2021
</div></div></div><div class="toc"><dl><dt><span class="preface"><a href="#preface-deployment"><span class="name">About This Guide</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.3.2.6"><span class="name">Required Background</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.2.7"><span class="name">Available Documentation</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.2.8"><span class="name">Feedback</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.2.9"><span class="name">Documentation Conventions</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-support-statement"><span class="name">Support Statement for SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.2.11"><span class="name">About the Making of This Documentation</span></a></span></dt></dl></dd><dt><span class="part"><a href="#part-cap-overview"><span class="number">I </span><span class="name">Overview of SUSE Cloud Application Platform</span></a></span></dt><dd><dl><dt><span class="chapter"><a href="#cha-cap-overview"><span class="number">1 </span><span class="name">About SUSE Cloud Application Platform</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-changes"><span class="number">1.1 </span><span class="name">New in Version 2.1.0</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-overview"><span class="number">1.2 </span><span class="name">SUSE Cloud Application Platform Overview</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-architecture"><span class="number">1.3 </span><span class="name">SUSE Cloud Application Platform Architecture</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-depl-kube-requirements"><span class="number">2 </span><span class="name">Other Kubernetes Systems</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-changes-kube-reqs"><span class="number">2.1 </span><span class="name">Kubernetes Requirements</span></a></span></dt></dl></dd></dl></dd><dt><span class="part"><a href="#part-cap-deployment"><span class="number">II </span><span class="name">Deploying SUSE Cloud Application Platform</span></a></span></dt><dd><dl><dt><span class="chapter"><a href="#cha-cap-depl-notes"><span class="number">3 </span><span class="name">Deployment and Administration Notes</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.3.4.3.3"><span class="number">3.1 </span><span class="name">Important Changes</span></a></span></dt><dt><span class="sect1"><a href="#sec-pod-status"><span class="number">3.2 </span><span class="name">Status of Pods during Deployment</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.3.5"><span class="number">3.3 </span><span class="name">Length of Release Names</span></a></span></dt><dt><span class="sect1"><a href="#cha-cap-depl-notes-releases"><span class="number">3.4 </span><span class="name">Releases and Associated Versions</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-depl-caasp"><span class="number">4 </span><span class="name">Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-prereqs-caasp"><span class="number">4.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-caasp-cluster"><span class="number">4.2 </span><span class="name">Creating a SUSE CaaS Platform Cluster</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.4.6"><span class="number">4.3 </span><span class="name">Install the Helm Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-storage"><span class="number">4.4 </span><span class="name">Storage Class</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-config"><span class="number">4.5 </span><span class="name">Deployment Configuration</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-certificates"><span class="number">4.6 </span><span class="name">
  Certificates
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-ingress"><span class="number">4.7 </span><span class="name">
  Using an Ingress Controller
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-affinity"><span class="number">4.8 </span><span class="name">
  Affinity and Anti-affinity
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-high-availability"><span class="number">4.9 </span><span class="name">
  High Availability
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-external-blobstore"><span class="number">4.10 </span><span class="name">
  External Blobstore
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-external-database"><span class="number">4.11 </span><span class="name">
  External Database
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-addrepo-caasp"><span class="number">4.12 </span><span class="name">Add the Kubernetes Charts Repository</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-cap-on-caasp"><span class="number">4.13 </span><span class="name">Deploying SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-ldap"><span class="number">4.14 </span><span class="name">
  LDAP Integration
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-add-capacity"><span class="number">4.15 </span><span class="name">Expanding Capacity of a Cloud Application Platform Deployment on SUSE® CaaS Platform</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-depl-aks"><span class="number">5 </span><span class="name">Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-prereqs-aks"><span class="number">5.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-aks-instance"><span class="number">5.2 </span><span class="name">Create Resource Group and AKS Instance</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.5.7"><span class="number">5.3 </span><span class="name">Install the Helm Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-storage"><span class="number">5.4 </span><span class="name">
  Storage Class
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-config"><span class="number">5.5 </span><span class="name">Deployment Configuration</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-certificates"><span class="number">5.6 </span><span class="name">
  Certificates
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-ingress"><span class="number">5.7 </span><span class="name">
  Using an Ingress Controller
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-affinity"><span class="number">5.8 </span><span class="name">
  Affinity and Anti-affinity
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-high-availability"><span class="number">5.9 </span><span class="name">
  High Availability
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-external-blobstore"><span class="number">5.10 </span><span class="name">
  External Blobstore
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-external-database"><span class="number">5.11 </span><span class="name">
  External Database
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-addrepo-aks"><span class="number">5.12 </span><span class="name">Add the Kubernetes Charts Repository</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-cap-on-aks"><span class="number">5.13 </span><span class="name">Deploying SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-ldap"><span class="number">5.14 </span><span class="name">
  LDAP Integration
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-add-capacity"><span class="number">5.15 </span><span class="name">Expanding Capacity of a Cloud Application Platform Deployment on Microsoft AKS</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-depl-eks"><span class="number">6 </span><span class="name">Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-eks-prereqs"><span class="number">6.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-eks-cluster"><span class="number">6.2 </span><span class="name">Create an EKS Cluster</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.6.6"><span class="number">6.3 </span><span class="name">Install the Helm Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-storage-class"><span class="number">6.4 </span><span class="name">
  Storage Class
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-configuration"><span class="number">6.5 </span><span class="name">Deployment Configuration</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-certificates"><span class="number">6.6 </span><span class="name">
  Certificates
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-ingress"><span class="number">6.7 </span><span class="name">
  Using an Ingress Controller
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-affinity"><span class="number">6.8 </span><span class="name">
  Affinity and Anti-affinity
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-high-availability"><span class="number">6.9 </span><span class="name">
  High Availability
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-external-blobstore"><span class="number">6.10 </span><span class="name">
  External Blobstore
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-external-database"><span class="number">6.11 </span><span class="name">
  External Database
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-addrepo-eks"><span class="number">6.12 </span><span class="name">Add the Kubernetes Charts Repository</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-cap-on-eks"><span class="number">6.13 </span><span class="name">Deploying SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-ldap"><span class="number">6.14 </span><span class="name">
  LDAP Integration
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-add-capacity"><span class="number">6.15 </span><span class="name">Expanding Capacity of a Cloud Application Platform Deployment on Amazon EKS</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-depl-gke"><span class="number">7 </span><span class="name">Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-prereqs-gke"><span class="number">7.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-gke-cluster"><span class="number">7.2 </span><span class="name">Creating a GKE cluster</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-kubeconfig"><span class="number">7.3 </span><span class="name">Get <code class="literal">kubeconfig</code> File</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.7.7"><span class="number">7.4 </span><span class="name">Install the Helm Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-storage"><span class="number">7.5 </span><span class="name">
  Storage Class
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-config"><span class="number">7.6 </span><span class="name">Deployment Configuration</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-certificates"><span class="number">7.7 </span><span class="name">
  Certificates
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-ingress"><span class="number">7.8 </span><span class="name">
  Using an Ingress Controller
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-affinity"><span class="number">7.9 </span><span class="name">
  Affinity and Anti-affinity
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-high-availability"><span class="number">7.10 </span><span class="name">
  High Availability
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-external-blobstore"><span class="number">7.11 </span><span class="name">
  External Blobstore
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-external-database"><span class="number">7.12 </span><span class="name">
  External Database
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-addrepo-gke"><span class="number">7.13 </span><span class="name">Add the Kubernetes charts repository</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-cap-on-gke"><span class="number">7.14 </span><span class="name">Deploying SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-ldap"><span class="number">7.15 </span><span class="name">
  LDAP Integration
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-add-capacity"><span class="number">7.16 </span><span class="name">Expanding Capacity of a Cloud Application Platform Deployment on Google GKE</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-install-stratos"><span class="number">8 </span><span class="name">Installing the Stratos Web Console</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-stratos-prod"><span class="number">8.1 </span><span class="name">Deploy Stratos on SUSE® CaaS Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-eks"><span class="number">8.2 </span><span class="name">Deploy Stratos on Amazon EKS</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-aks"><span class="number">8.3 </span><span class="name">Deploy Stratos on Microsoft AKS</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-gke"><span class="number">8.4 </span><span class="name">Deploy Stratos on Google GKE</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-upgrade"><span class="number">8.5 </span><span class="name">Upgrading Stratos</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-metrics"><span class="number">8.6 </span><span class="name">Stratos Metrics</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-depl-eirini"><span class="number">9 </span><span class="name">Eirini</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-eirini-considerations"><span class="number">9.1 </span><span class="name">Limitations and Other Considerations</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eirini-enable"><span class="number">9.2 </span><span class="name">Enabling Eirini</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-depl-terraform"><span class="number">10 </span><span class="name">Deploying SUSE Cloud Application Platform Using Terraform</span></a></span></dt><dt><span class="chapter"><a href="#cha-cap-depl-air-gap-registry"><span class="number">11 </span><span class="name">Setting Up a Registry for an Air Gapped Environment</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-prereqs-air-gap-registry"><span class="number">11.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-air-gap-registry"><span class="number">11.2 </span><span class="name">Mirror Images to Registry</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-depl-private-registry"><span class="number">12 </span><span class="name">SUSE Private Registry</span></a></span></dt></dl></dd><dt><span class="part"><a href="#part-cap-administration"><span class="number">III </span><span class="name">SUSE Cloud Application Platform Administration</span></a></span></dt><dd><dl><dt><span class="chapter"><a href="#cha-cap-upgrade"><span class="number">13 </span><span class="name">Upgrading SUSE Cloud Application Platform</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-upgrade-considerations"><span class="number">13.1 </span><span class="name">Important Considerations</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-update"><span class="number">13.2 </span><span class="name">Upgrading SUSE Cloud Application Platform</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-configuration-changes"><span class="number">14 </span><span class="name">Configuration Changes</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-configuration-change-example"><span class="number">14.1 </span><span class="name">Configuration Change Example</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-configuration-change-other-examples"><span class="number">14.2 </span><span class="name">Other Examples</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-create-admin-user"><span class="number">15 </span><span class="name">Creating Admin Users</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-create-admin-prereqs"><span class="number">15.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-admin-procedure"><span class="number">15.2 </span><span class="name">Creating an Example Cloud Application Platform Cluster Administrator</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-manage-passwords"><span class="number">16 </span><span class="name">Managing Passwords</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-passwords-cli"><span class="number">16.1 </span><span class="name">Password Management with the Cloud Foundry Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-passwords-stratos"><span class="number">16.2 </span><span class="name">Changing User Passwords with Stratos</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-uaa-ui"><span class="number">17 </span><span class="name">Accessing the UAA User Interface</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-uaa-ui-prereqs"><span class="number">17.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-uaa-ui-procedure"><span class="number">17.2 </span><span class="name">Procedure</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-memory-limits"><span class="number">18 </span><span class="name">Container Memory Limits and Requests</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-memory-limits-enable"><span class="number">18.1 </span><span class="name">Enabling and Disabling Memory Limits and Request Sizes</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-memory-limits-configure"><span class="number">18.2 </span><span class="name">Configuring Memory Limits and Request Sizes</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-ccdb-secret-rotation"><span class="number">19 </span><span class="name">Cloud Controller Database Secret Rotation</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-ccdb-tables"><span class="number">19.1 </span><span class="name">Tables with Encrypted Information</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-secrets-rotation"><span class="number">20 </span><span class="name">Rotating Automatically Generated Secrets</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-secrets-rotation-finding"><span class="number">20.1 </span><span class="name">Finding Secrets</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-secrets-rotation-specific"><span class="number">20.2 </span><span class="name">Rotating Specific Secrets</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-backup-restore"><span class="number">21 </span><span class="name">Backup and Restore</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-backup-restore-with-plugin"><span class="number">21.1 </span><span class="name">Backup and Restore Using cf-plugin-backup</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-backup-restore-of-raw-data"><span class="number">21.2 </span><span class="name">Disaster Recovery through Raw Data Backup and Restore</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-service-brokers"><span class="number">22 </span><span class="name">Service Brokers</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-minibroker"><span class="number">22.1 </span><span class="name">Provisioning Services with Minibroker</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-app-autoscaler"><span class="number">23 </span><span class="name">App-AutoScaler</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-app-autoscaler-prereqs"><span class="number">23.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-enable-app-autoscaler"><span class="number">23.2 </span><span class="name">Enabling and Disabling the App-AutoScaler Service</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-app-autoscaler-usage"><span class="number">23.3 </span><span class="name">Using the App-AutoScaler Service</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-app-autoscaler-policies"><span class="number">23.4 </span><span class="name">Policies</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-credhub"><span class="number">24 </span><span class="name">Integrating CredHub with SUSE Cloud Application Platform</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-credhub"><span class="number">24.1 </span><span class="name">Installing the CredHub Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-credhub-enable"><span class="number">24.2 </span><span class="name">Enabling and Disabling CredHub</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-credhub-connect"><span class="number">24.3 </span><span class="name">Connecting to the CredHub Service</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-cap-buildpacks"><span class="number">25 </span><span class="name">Buildpacks</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-cap-system-buildpacks"><span class="number">25.1 </span><span class="name">System Buildpacks</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-using-buildpacks"><span class="number">25.2 </span><span class="name">Using Buildpacks</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-adding-buildpacks"><span class="number">25.3 </span><span class="name">Adding Buildpacks</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-updating-buildpacks"><span class="number">25.4 </span><span class="name">Updating Buildpacks</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-offline-buildpacks"><span class="number">25.5 </span><span class="name">Offline Buildpacks</span></a></span></dt></dl></dd></dl></dd><dt><span class="part"><a href="#part-cap-user-guide"><span class="number">IV </span><span class="name">SUSE Cloud Application Platform User Guide</span></a></span></dt><dd><dl><dt><span class="chapter"><a href="#cha-cap-cf-cli"><span class="number">26 </span><span class="name">Deploying and Managing Applications with the Cloud Foundry Client</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-cf-cli"><span class="number">26.1 </span><span class="name">Using the cf CLI with SUSE Cloud Application Platform</span></a></span></dt></dl></dd></dl></dd><dt><span class="part"><a href="#part-cap-troubleshooting"><span class="number">V </span><span class="name">Troubleshooting</span></a></span></dt><dd><dl><dt><span class="chapter"><a href="#cha-cap-depl-troubleshooting"><span class="number">27 </span><span class="name">Troubleshooting</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#sec-cap-tbl-logging"><span class="number">27.1 </span><span class="name">Logging</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-supportconfig"><span class="number">27.2 </span><span class="name">Using Supportconfig</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-toolong"><span class="number">27.3 </span><span class="name">Deployment Is Taking Too Long</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-rebuild-depl"><span class="number">27.4 </span><span class="name">Deleting and Rebuilding a Deployment</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-kubectl-queries"><span class="number">27.5 </span><span class="name">Querying with Kubectl</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-admission-webhook"><span class="number">27.6 </span><span class="name">Admission webhook denied</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-helm-namespace"><span class="number">27.7 </span><span class="name">Namespace does not exist</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-log-cache-memory"><span class="number">27.8 </span><span class="name">Log-cache Memory Allocation Issue</span></a></span></dt></dl></dd></dl></dd><dt><span class="appendix"><a href="#id-1.3.8"><span class="number">A </span><span class="name">Appendix</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#app-kubecf-values-yaml"><span class="number">A.1 </span><span class="name">Complete suse/kubecf values.yaml File</span></a></span></dt><dt><span class="sect1"><a href="#app-cf-operator-values-yaml"><span class="number">A.2 </span><span class="name">Complete suse/cf-operator values.yaml File</span></a></span></dt></dl></dd><dt><span class="appendix"><a href="#id-1.3.9"><span class="number">B </span><span class="name">GNU Licenses</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.3.9.4"><span class="number">B.1 </span><span class="name">GNU Free Documentation License</span></a></span></dt></dl></dd></dl></div><div class="list-of-figures"><div class="toc-title">List of Figures</div><dl><dt><span class="figure"><a href="#fig-cap-cloud-101"><span class="number">1.1 </span><span class="name">Cloud Platform Comparisons</span></a></span></dt><dt><span class="figure"><a href="#fig-cap-containerized"><span class="number">1.2 </span><span class="name">Containerized Platforms</span></a></span></dt><dt><span class="figure"><a href="#fig-cap-stack"><span class="number">1.3 </span><span class="name">SUSE Cloud Application Platform Stack</span></a></span></dt><dt><span class="figure"><a href="#fig-cap-cap-containers"><span class="number">1.4 </span><span class="name">KubeCF Containers, Grouped by Function</span></a></span></dt><dt><span class="figure"><a href="#fig-cap-simple-services"><span class="number">1.5 </span><span class="name">Simple Services Diagram</span></a></span></dt><dt><span class="figure"><a href="#fig-cap-detailed-services"><span class="number">1.6 </span><span class="name">Detailed Services Diagram</span></a></span></dt><dt><span class="figure"><a href="#id-1.3.4.8.3.22"><span class="number">8.1 </span><span class="name">Stratos UI Cloud Foundry Console</span></a></span></dt><dt><span class="figure"><a href="#stratos-kubernetes-view-caasp-png"><span class="number">8.2 </span><span class="name">Kubernetes Environment Information on Stratos</span></a></span></dt><dt><span class="figure"><a href="#id-1.3.4.8.4.24"><span class="number">8.3 </span><span class="name">Stratos UI Cloud Foundry Console</span></a></span></dt><dt><span class="figure"><a href="#id-1.3.4.8.4.25.6"><span class="number">8.4 </span><span class="name">Kubernetes Environment Information on Stratos</span></a></span></dt><dt><span class="figure"><a href="#id-1.3.4.8.5.18"><span class="number">8.5 </span><span class="name">Stratos UI Cloud Foundry Console</span></a></span></dt><dt><span class="figure"><a href="#id-1.3.4.8.5.19.6"><span class="number">8.6 </span><span class="name">Kubernetes Environment Information on Stratos</span></a></span></dt><dt><span class="figure"><a href="#id-1.3.4.8.6.18"><span class="number">8.7 </span><span class="name">Stratos UI Cloud Foundry Console</span></a></span></dt><dt><span class="figure"><a href="#id-1.3.4.8.6.19.6"><span class="number">8.8 </span><span class="name">Kubernetes Environment Information on Stratos</span></a></span></dt><dt><span class="figure"><a href="#stratos-app-instances-metrics-png"><span class="number">8.9 </span><span class="name">Cell Column on Application Instance Tab after Connecting Stratos Metrics</span></a></span></dt><dt><span class="figure"><a href="#stratos-app-metrics-tab-png"><span class="number">8.10 </span><span class="name">Application Metrics Tab after Connecting Stratos Metrics</span></a></span></dt><dt><span class="figure"><a href="#stratos-kubernetes-node-metrics-png"><span class="number">8.11 </span><span class="name">Node Metrics on the Stratos Kubernetes View</span></a></span></dt><dt><span class="figure"><a href="#fig-cap-stratos-profile-png"><span class="number">16.1 </span><span class="name">Stratos Profile Page</span></a></span></dt><dt><span class="figure"><a href="#fig-cap-stratos-edit-profile-png"><span class="number">16.2 </span><span class="name">Stratos Edit Profile Page</span></a></span></dt></dl></div><div><div class="legalnotice" id="id-1.3.1.5"><p>
  Copyright © 2006–
2021

  SUSE LLC and contributors. All rights reserved.
 </p><p>
  Permission is granted to copy, distribute and/or modify this document under
  the terms of the GNU Free Documentation License, Version 1.2 or (at your
  option) version 1.3; with the Invariant Section being this copyright notice
  and license. A copy of the license version 1.2 is included in the section
  entitled <span class="quote">“<span class="quote ">GNU Free Documentation License</span>”</span>.
 </p><p>
  For SUSE trademarks, see
  <a class="link" href="http://www.suse.com/company/legal/" target="_blank">http://www.suse.com/company/legal/</a>. All other
  third-party trademarks are the property of their respective owners. Trademark
  symbols (®, ™ etc.) denote trademarks of SUSE and its affiliates.
  Asterisks (*) denote third-party trademarks.
 </p><p>
  All information found in this book has been compiled with utmost attention to
  detail. However, this does not guarantee complete accuracy. Neither SUSE LLC,
  its affiliates, the authors nor the translators shall be held liable for
  possible errors or the consequences thereof.
 </p></div></div><div class="preface " id="preface-deployment"><div class="titlepage"><div><div><h1 class="title"><span class="number"> </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">About This Guide</span> <a title="Permalink" class="permalink" href="#preface-deployment">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_intro.xml</li><li><span class="ds-label">ID: </span>preface-deployment</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.3.2.6"><span class="name">Required Background</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.2.7"><span class="name">Available Documentation</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.2.8"><span class="name">Feedback</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.2.9"><span class="name">Documentation Conventions</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-support-statement"><span class="name">Support Statement for SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.2.11"><span class="name">About the Making of This Documentation</span></a></span></dt></dl></div></div><p>
  SUSE Cloud Application Platform is a software platform for cloud-native applications based on
  Cloud Foundry Application Runtime (cf-operator, KubeCF, and Stratos) with
  additional supporting components.
 </p><p>
  Cloud Application Platform is designed to run on any Kubernetes cluster. This guide describes how
  to deploy it on:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    For SUSE® CaaS Platform, see <a class="xref" href="#cha-cap-depl-caasp" title="Chapter 4. Deploying SUSE Cloud Application Platform on SUSE CaaS Platform">Chapter 4, <em>Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</em></a>.
   </p></li><li class="listitem "><p>
    For Microsoft Azure Kubernetes Service, see <a class="xref" href="#cha-cap-depl-aks" title="Chapter 5. Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)">Chapter 5, <em>Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Amazon Elastic Kubernetes Service, see <a class="xref" href="#cha-cap-depl-eks" title="Chapter 6. Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)">Chapter 6, <em>Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Google Kubernetes Engine, see <a class="xref" href="#cha-cap-depl-gke" title="Chapter 7. Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)">Chapter 7, <em>Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</em></a>.
   </p></li></ul></div><div class="sect1 " id="id-1.3.2.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Required Background</span> <a title="Permalink" class="permalink" href="#id-1.3.2.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_intro_target_audience_i.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  To keep the scope of these guidelines manageable, certain technical
  assumptions have been made:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    You have some computer experience and are familiar with common technical
    terms.
   </p></li><li class="listitem "><p>
    You are familiar with the documentation for your system and the network on
    which it runs.
   </p></li><li class="listitem "><p>
    You have a basic understanding of Linux systems.
   </p></li></ul></div></div><div class="sect1 " id="id-1.3.2.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Available Documentation</span> <a title="Permalink" class="permalink" href="#id-1.3.2.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_intro_available_doc_i.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  We provide HTML and PDF versions of our books in different languages.
  Documentation for our products is available at
  <a class="link" href="http://documentation.suse.com/" target="_blank">http://documentation.suse.com/</a>, where you can also
  find the latest updates and browse or download the documentation in various
  formats.
 </p><p>
  The following documentation is available for this product:
 </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.2.7.5.1"><span class="term "><a class="xref" href="#book-cap-guides" title="Deployment, Administration, and User Guides"><em class="citetitle ">Deployment, Administration, and User Guide</em>s</a></span></dt><dd><p>
     The SUSE Cloud Application Platform guide is a comprehensive guide providing deployment,
     administration, and user guides, and architecture and minimum system
     requirements.
    </p></dd></dl></div></div><div class="sect1 " id="id-1.3.2.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Feedback</span> <a title="Permalink" class="permalink" href="#id-1.3.2.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_intro_feedback_i.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  Several feedback channels are available:
 </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.2.8.4.1"><span class="term ">Bugs and Enhancement Requests</span></dt><dd><p>
     For services and support options available for your product, refer to
     <a class="link" href="http://www.suse.com/support/" target="_blank">http://www.suse.com/support/</a>.
    </p><p>

     To report bugs for a product component, go to
     <a class="link" href="https://scc.suse.com/support/requests" target="_blank">https://scc.suse.com/support/requests</a>, log in, and
     click <span class="guimenu ">Create New</span>.
    </p></dd><dt id="id-1.3.2.8.4.2"><span class="term ">User Comments</span></dt><dd><p>
     We want to hear your comments about and suggestions for this manual and
     the other documentation included with this product. Use the User Comments
     feature at the bottom of each page in the online documentation or go to
     <a class="link" href="http://documentation.suse.com/feedback.html" target="_blank">http://documentation.suse.com/feedback.html</a> and
     enter your comments there.
    </p></dd><dt id="id-1.3.2.8.4.3"><span class="term ">Mail</span></dt><dd><p>
     For feedback on the documentation of this product, you can also send a
     mail to <code class="literal">doc-team@suse.com</code>. Make sure to include the
     document title, the product version and the publication date of the
     documentation. To report errors or suggest enhancements, provide a concise
     description of the problem and refer to the respective section number and
     page (or URL).
    </p></dd></dl></div></div><div class="sect1 " id="id-1.3.2.9"><div class="titlepage"><div><div><h2 class="title"><span class="number">4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Documentation Conventions</span> <a title="Permalink" class="permalink" href="#id-1.3.2.9">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_intro_typografie_i.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  The following notices and typographical conventions are used in this
  documentation:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    <code class="filename">/etc/passwd</code>: directory names and file names
   </p></li><li class="listitem "><p>
    <em class="replaceable ">PLACEHOLDER</em>: replace
    <em class="replaceable ">PLACEHOLDER</em> with the actual value
   </p></li><li class="listitem "><p>
    <code class="envar">PATH</code>: the environment variable PATH
   </p></li><li class="listitem "><p>
    <code class="command">ls</code>, <code class="option">--help</code>: commands, options, and
    parameters
   </p></li><li class="listitem "><p>
    <code class="systemitem">user</code>: users or groups
   </p></li><li class="listitem "><p>
    <span class="package ">package name</span> : name of a package
   </p></li><li class="listitem "><p>
    <span class="keycap">Alt</span>, <span class="keycap">Alt</span><span class="key-connector">–</span><span class="keycap">F1</span>: a key to press or a key combination; keys
    are shown in uppercase as on a keyboard
   </p></li><li class="listitem "><p>
    <span class="guimenu ">File</span>, <span class="guimenu ">File</span> › <span class="guimenu ">Save
    As</span>: menu items, buttons
   </p></li><li class="listitem "><p><strong class="arch-arrow-start">AMD/Intel</strong>
    This paragraph is only relevant for the AMD64/Intel 64 architecture. The
    arrows mark the beginning and the end of the text block.
   <strong class="arch-arrow-end"></strong></p><p><strong class="arch-arrow-start">IBM Z, POWER</strong>
    This paragraph is only relevant for the architectures
    <code class="literal">z Systems</code> and <code class="literal">POWER</code>. The arrows
    mark the beginning and the end of the text block.
   <strong class="arch-arrow-end"></strong></p></li><li class="listitem "><p>
    <span class="emphasis"><em>Dancing Penguins</em></span> (Chapter
    <span class="emphasis"><em>Penguins</em></span>, ↑Another Manual): This is a reference
    to a chapter in another manual.
   </p></li><li class="listitem "><p>
    Commands that must be run with <code class="systemitem">root</code> privileges. Often you can also
    prefix these commands with the <code class="command">sudo</code> command to run them
    as non-privileged user.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code><code class="command">command</code>
<code class="prompt user">tux &gt; </code><code class="command">sudo command</code></pre></div></li><li class="listitem "><p>
    Commands that can be run by non-privileged users.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code><code class="command">command</code></pre></div></li><li class="listitem "><p>
    Notices
   </p><div id="id-1.3.2.9.4.13.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: Warning Notice</h6><p>
     Vital information you must be aware of before proceeding. Warns you about
     security issues, potential loss of data, damage to hardware, or physical
     hazards.
    </p></div><div id="id-1.3.2.9.4.13.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Important Notice</h6><p>
     Important information you should be aware of before proceeding.
    </p></div><div id="id-1.3.2.9.4.13.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note: Note Notice</h6><p>
     Additional information, for example about differences in software
     versions.
    </p></div><div id="id-1.3.2.9.4.13.5" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.png" /><h6>Tip: Tip Notice</h6><p>
     Helpful information, like a guideline or a piece of practical advice.
    </p></div></li></ul></div></div><div class="sect1 " id="sec-cap-support-statement"><div class="titlepage"><div><div><h2 class="title"><span class="number">5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Support Statement for SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#sec-cap-support-statement">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_intro_support_statement_i.xml</li><li><span class="ds-label">ID: </span>sec-cap-support-statement</li></ul></div></div></div></div><p>
  To receive support, you need an appropriate subscription with SUSE. For more
  information, see
  <a class="link" href="https://www.suse.com/support/?id=SUSE_Cloud_Application_Platform" target="_blank">https://www.suse.com/support/?id=SUSE_Cloud_Application_Platform</a>.
 </p><p>
  The following definitions apply:
 </p><div class="sect2 " id="id-1.3.2.10.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Version Support</span> <a title="Permalink" class="permalink" href="#id-1.3.2.10.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_intro_support_statement_i.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.2.10.5.2.1"><span class="term ">Technical Support and Troubleshooting (L1 - L2)</span></dt><dd><p>
      Current and previous major versions (n-1). For example, SUSE  will
      provide technical support and troubleshooting for versions 1.0, 1.1, 1.2,
      1.3 (and all 2.x point releases) until the release of 3.0.
     </p></dd><dt id="id-1.3.2.10.5.2.2"><span class="term ">Patches and updates (L3)</span></dt><dd><p>
      On the latest or last minor release of each major release. For example,
      SUSE  will provide patches and updates for 1.3 (and
      2.<span class="emphasis"><em>latest</em></span>) until the release of 3.0.
     </p></dd></dl></div><p>
   SUSE Cloud Application Platform closely follows upstream Cloud Foundry releases which may implement
   fixes and changes which are not backwards compatible with previous releases.
   SUSE will backport patches for critical bugs and security issues on a best
   efforts basis.
  </p></div><div class="sect2 " id="sec-cap-platform-support"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Platform Support</span> <a title="Permalink" class="permalink" href="#sec-cap-platform-support">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_intro_support_statement_i.xml</li><li><span class="ds-label">ID: </span>sec-cap-platform-support</li></ul></div></div></div></div><p>
   SUSE Cloud Application Platform is fully supported on Amazon EKS, Microsoft Azure AKS and
   Google GKE. Each release is tested by SUSE Cloud Application Platform QA on these platforms.
  </p><p>
   SUSE Cloud Application Platform is fully supported on SUSE CaaS Platform, wherever it happens to be
   installed. If SUSE CaaS Platform is supported on a particular cloud service provider
   (CSP), the customer can get support for SUSE Cloud Application Platform in that context.
  </p><p>
   SUSE can provide support for SUSE Cloud Application Platform on 3rd party/generic Kubernetes on a
   case-by-case basis provided:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     The Kubernetes cluster satisfies the Requirements listed here at
     <a class="link" href="https://documentation.suse.com/suse-cap/2.1.0/html/cap-guides/cha-cap-depl-kube-requirements.html#sec-cap-changes-kube-reqs" target="_blank">https://documentation.suse.com/suse-cap/2.1.0/html/cap-guides/cha-cap-depl-kube-requirements.html#sec-cap-changes-kube-reqs</a>.
    </p></li><li class="listitem "><p>
     The <code class="filename">kube-ready-state-check.sh</code> script has been run on
     the target Kubernetes cluster and does not show any configuration problems.
    </p></li><li class="listitem "><p>
     A SUSE Services or Sales Engineer has verified that SUSE Cloud Application Platform works
     correctly on the target Kubernetes cluster.
    </p></li></ol></div></div><div class="sect2 " id="id-1.3.2.10.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Technology Previews</span> <a title="Permalink" class="permalink" href="#id-1.3.2.10.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_intro_support_statement_i.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    Technology previews are packages, stacks, or features delivered by SUSE
    to provide glimpses into upcoming innovations. The previews are included for
    your convenience to give you the chance to test new technologies within your
    environment. We would appreciate your feedback! If you test a technology
    preview, please contact your SUSE representative and let them know about
    your experience and use cases. Your input is helpful for future development.
   </p><p>
    However, technology previews come with the following limitations:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      Technology previews are still in development. Therefore, they may be functionally
      incomplete, unstable, or in other ways  <span class="emphasis"><em>not</em></span> suitable
      for production use.
     </p></li><li class="listitem "><p>
      Technology previews are <span class="emphasis"><em>not</em></span> supported.
     </p></li><li class="listitem "><p>
      Details and functionality of technology previews are subject to change.
      As a result, upgrading to subsequent releases of a technology preview may
      be impossible and require a fresh installation.
     </p></li><li class="listitem "><p>
      Technology previews can be dropped at any time. For example, if SUSE
      discovers that a preview does not meet the customer or market needs, or does
      not prove to comply with enterprise standards. SUSE does not commit to
      providing a supported version of such technologies in the future.
     </p></li></ul></div><p>
   For an overview of technology previews shipped with your product, see the
   release notes at <a class="link" href="https://www.suse.com/releasenotes/" target="_blank">https://www.suse.com/releasenotes/</a>.
  </p></div></div><div xml:lang="en" class="sect1 " id="id-1.3.2.11" lang="en"><div class="titlepage"><div><div><h2 class="title"><span class="number">6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">About the Making of This Documentation</span> <a title="Permalink" class="permalink" href="#id-1.3.2.11">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_intro_making_i.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  This documentation is written in
  <a class="link" href="https://github.com/openSUSE/geekodoc" target="_blank">GeekoDoc</a>,
  a subset of
  <a class="link" href="http://www.docbook.org" target="_blank">DocBook 5</a>.
  The XML source files were validated by <code class="command">jing</code> (see
  <a class="link" href="https://code.google.com/p/jing-trang/" target="_blank">https://code.google.com/p/jing-trang/</a>), processed by
  <code class="command">xsltproc</code>, and converted into XSL-FO using a customized
  version of Norman Walsh's stylesheets. The final PDF is formatted through FOP
  from
  <a class="link" href="https://xmlgraphics.apache.org/fop" target="_blank">Apache
  Software Foundation</a>. The open source tools and the environment used to
  build this documentation are provided by the DocBook Authoring and Publishing
  Suite (DAPS). The project's home page can be found at
  <a class="link" href="https://github.com/openSUSE/daps" target="_blank">https://github.com/openSUSE/daps</a>.
 </p><p>
  The XML source code of this documentation can be found at
  <a class="link" href="https://github.com/SUSE/doc-cap" target="_blank">https://github.com/SUSE/doc-cap</a>.
 </p></div></div><div class="part" id="part-cap-overview"><div class="titlepage"><div><div><h1 class="title"><span class="number">Part I </span><span class="name">Overview of SUSE Cloud Application Platform </span><a title="Permalink" class="permalink" href="#part-cap-overview">#</a></h1></div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="#cha-cap-overview"><span class="number">1 </span><span class="name">About SUSE Cloud Application Platform</span></a></span></dt><dd class="toc-abstract"><p>
     KubeCF has been updated to 2.5.8:
    </p></dd><dt><span class="chapter"><a href="#cha-cap-depl-kube-requirements"><span class="number">2 </span><span class="name">Other Kubernetes Systems</span></a></span></dt><dd class="toc-abstract"><p>
   SUSE Cloud Application Platform is designed to run on any Kubernetes system that meets the
   following requirements:
  </p></dd></dl></div><div class="chapter " id="cha-cap-overview"><div class="titlepage"><div><div><h2 class="title"><span class="number">1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">About SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#cha-cap-overview">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_overview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-changes"><span class="number">1.1 </span><span class="name">New in Version 2.1.0</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-overview"><span class="number">1.2 </span><span class="name">SUSE Cloud Application Platform Overview</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-architecture"><span class="number">1.3 </span><span class="name">SUSE Cloud Application Platform Architecture</span></a></span></dt></dl></div></div><div class="sect1 " id="sec-cap-changes"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">New in Version 2.1.0</span> <a title="Permalink" class="permalink" href="#sec-cap-changes">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_overview.xml</li><li><span class="ds-label">ID: </span>sec-cap-changes</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     KubeCF has been updated to 2.5.8:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       For a full list of features and fixes see <a class="link" href="https://github.com/cloudfoundry-incubator/kubecf/releases/tag/v2.5.8" target="_blank">https://github.com/cloudfoundry-incubator/kubecf/releases/tag/v2.5.8</a>
      </p></li></ul></div></li><li class="listitem "><p>
     cf-operator has been updated to 6.1.17:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       For a full list of features and fixes see <a class="link" href="https://github.com/cloudfoundry-incubator/quarks-operator/releases/tag/v6.1.17" target="_blank">https://github.com/cloudfoundry-incubator/quarks-operator/releases/tag/v6.1.17</a>
      </p></li></ul></div></li><li class="listitem "><p>
     Stratos Console has been updated to 4.2.0:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       Configurable NGINX protocols and ciphers using Helm values
      </p></li><li class="listitem "><p>
       For a full list of features and fixes see <a class="link" href="https://github.com/SUSE/stratos/blob/master/CHANGELOG.md#420" target="_blank">https://github.com/SUSE/stratos/blob/master/CHANGELOG.md#420</a>
      </p></li></ul></div></li></ul></div><p>
   See all product manuals for SUSE Cloud Application Platform 2.x at
   <a class="link" href="https://documentation.suse.com/suse-cap/2/" target="_blank">https://documentation.suse.com/suse-cap/2/</a>.
  </p><div id="id-1.3.3.3.2.4" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.png" /><h6>Tip: Read the Release Notes</h6><p>
    Make sure to review the release notes for SUSE Cloud Application Platform published at
    <a class="link" href="https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2.0/" target="_blank">https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2.0/</a>.
   </p></div></div><div class="sect1 " id="sec-cap-overview"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">SUSE Cloud Application Platform Overview</span> <a title="Permalink" class="permalink" href="#sec-cap-overview">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_overview.xml</li><li><span class="ds-label">ID: </span>sec-cap-overview</li></ul></div></div></div></div><p>
    SUSE Cloud Application Platform is a software platform for cloud-native applications based on
    Cloud Foundry Application Runtime (cf-operator, KubeCF, and Stratos) with
    additional supporting components.
   </p><p>
   SUSE Cloud Application Platform describes the complete software stack, including the operating
   system, Kubernetes, and KubeCF.
  </p><p>
   SUSE Cloud Application Platform is comprised of cf-operator (<code class="literal">cf-operator</code>),
   KubeCF (<code class="literal">kubecf</code>), the Stratos Web user interface, and
   Stratos Metrics.
  </p><p>
   The Cloud Foundry code base provides the basic functionality. KubeCF differentiates
   itself from other Cloud Foundry distributions by running in Linux containers managed
   by Kubernetes, rather than virtual machines managed with BOSH, for greater
   fault tolerance and lower memory use.
  </p><p>
   All Docker images for the SUSE Linux Enterprise builds are hosted on
   <code class="literal">registry.suse.com</code>. These are the commercially-supported
   images. (Community-supported images for openSUSE are hosted on
   <a class="link" href="https://hub.docker.com" target="_blank">Docker Hub</a>.) Product
   manuals on
   <a class="link" href="https://documentation.suse.com/suse-cap/2/" target="_blank">https://documentation.suse.com/suse-cap/2/</a>  refer to the
   commercially-supported SUSE Linux Enterprise version.
  </p><p>
   Cloud Application Platform is designed to run on any Kubernetes cluster as described in
   <a class="xref" href="#sec-cap-platform-support" title="5.2. Platform Support">Section 5.2, “Platform Support”</a>. This guide describes how
   to deploy it:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    For SUSE® CaaS Platform, see <a class="xref" href="#cha-cap-depl-caasp" title="Chapter 4. Deploying SUSE Cloud Application Platform on SUSE CaaS Platform">Chapter 4, <em>Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</em></a>.
   </p></li><li class="listitem "><p>
    For Microsoft Azure Kubernetes Service, see <a class="xref" href="#cha-cap-depl-aks" title="Chapter 5. Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)">Chapter 5, <em>Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Amazon Elastic Kubernetes Service, see <a class="xref" href="#cha-cap-depl-eks" title="Chapter 6. Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)">Chapter 6, <em>Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Google Kubernetes Engine, see <a class="xref" href="#cha-cap-depl-gke" title="Chapter 7. Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)">Chapter 7, <em>Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</em></a>.
   </p></li></ul></div><p>
   SUSE Cloud Application Platform serves different but complementary purposes for operators and
   application developers.
  </p><p>
   For operators, the platform is:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Easy to install, manage, and maintain
    </p></li><li class="listitem "><p>
     Secure by design
    </p></li><li class="listitem "><p>
     Fault tolerant and self-healing
    </p></li><li class="listitem "><p>
     Offers high availability for critical components
    </p></li><li class="listitem "><p>
     Uses industry-standard components
    </p></li><li class="listitem "><p>
     Avoids single vendor lock-in
    </p></li></ul></div><p>
   For developers, the platform:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Allocates computing resources on demand via API or Web interface
    </p></li><li class="listitem "><p>
     Offers users a choice of language and Web framework
    </p></li><li class="listitem "><p>
     Gives access to databases and other data services
    </p></li><li class="listitem "><p>
     Emits and aggregates application log streams
    </p></li><li class="listitem "><p>
     Tracks resource usage for users and groups
    </p></li><li class="listitem "><p>
     Makes the software development workflow more efficient
    </p></li></ul></div><p>
   The principle interface and API for deploying applications to SUSE Cloud Application Platform
   is KubeCF. Most Cloud Foundry distributions run on virtual machines managed
   by BOSH. KubeCF runs in SUSE Linux Enterprise containers managed by Kubernetes.
   Containerizing the components of the platform itself has these advantages:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Improves fault tolerance. Kubernetes monitors the health of all containers,
     and automatically restarts faulty containers faster than virtual machines
     can be restarted or replaced.
    </p></li><li class="listitem "><p>
     Reduces physical memory overhead. KubeCF components deployed in containers
     consume substantially less memory, as host-level operations are shared
     between containers by Kubernetes.
    </p></li></ul></div><p>
   SUSE Cloud Application Platform uses cf-operator, a Kubernetes Operator deployed via a Helm chart, to
   install custom resource definitions that convert BOSH releases into
   Kubernetes resources, such as <code class="literal">Pod</code>, <code class="literal">Deployment</code>,
   and <code class="literal">StatefulSet</code>. This is made possible
   by leveraging KubeCF, a version of Cloud Foundry deployed as Helm chart.
  </p></div><div class="sect1 " id="sec-cap-architecture"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">SUSE Cloud Application Platform Architecture</span> <a title="Permalink" class="permalink" href="#sec-cap-architecture">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_overview.xml</li><li><span class="ds-label">ID: </span>sec-cap-architecture</li></ul></div></div></div></div><p>
   The following figures illustrate the main structural concepts of
   SUSE Cloud Application Platform. <a class="xref" href="#fig-cap-cloud-101" title="Cloud Platform Comparisons">Figure 1.1, “Cloud Platform Comparisons”</a> shows a comparison of the
   basic cloud platforms:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Infrastructure as a Service (IaaS)
    </p></li><li class="listitem "><p>
     Container as a Service (CaaS)
    </p></li><li class="listitem "><p>
     Platform as a Service (PaaS)
    </p></li><li class="listitem "><p>
     Software as a Service (SaaS)
    </p></li></ul></div><p>
   SUSE CaaS Platform is a Container as a Service platform, and SUSE Cloud Application Platform is a
   PaaS.
  </p><div class="figure" id="fig-cap-cloud-101"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/cloud-101.svg" target="_blank"><img src="images/cloud-101.svg" width="" alt="Comparison of cloud platforms." /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 1.1: </span><span class="name">Cloud Platform Comparisons </span><a title="Permalink" class="permalink" href="#fig-cap-cloud-101">#</a></h6></div></div><p>
   <a class="xref" href="#fig-cap-containerized" title="Containerized Platforms">Figure 1.2, “Containerized Platforms”</a> illustrates how SUSE Cloud Application Platform containerize the platform itself on top of a cloud provider.
  </p><div class="figure" id="fig-cap-containerized"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/cap-containerized.svg" target="_blank"><img src="images/cap-containerized.svg" width="" alt="SUSE SUSE CaaS Platform and SUSE Cloud Application Platform containerize the platform itself." /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 1.2: </span><span class="name">Containerized Platforms </span><a title="Permalink" class="permalink" href="#fig-cap-containerized">#</a></h6></div></div><p>
   <a class="xref" href="#fig-cap-stack" title="SUSE Cloud Application Platform Stack">Figure 1.3, “SUSE Cloud Application Platform Stack”</a> shows the relationships of the major
   components of the software stack. SUSE Cloud Application Platform runs on Kubernetes, which in
   turn runs on multiple platforms, from bare metal to various cloud stacks.
   Your applications run on SUSE Cloud Application Platform and provide services.
  </p><div class="figure" id="fig-cap-stack"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/cap-kube.svg" target="_blank"><img src="images/cap-kube.svg" width="" alt="Relationships of the main Cloud Application Platform components." /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 1.3: </span><span class="name">SUSE Cloud Application Platform Stack </span><a title="Permalink" class="permalink" href="#fig-cap-stack">#</a></h6></div></div><div class="sect2 " id="sec-cap-components"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">KubeCF Components</span> <a title="Permalink" class="permalink" href="#sec-cap-components">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_overview.xml</li><li><span class="ds-label">ID: </span>sec-cap-components</li></ul></div></div></div></div><p>
    KubeCF is comprised of developer and administrator clients, trusted download
    sites, transient and long-running components, APIs, and authentication:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      Clients for developers and admins to interact with KubeCF: the cf CLI,
      which provides the <code class="command">cf</code> command, Stratos Web interface,
      IDE plugins.
     </p></li><li class="listitem "><p>
      Docker Trusted Registry owned by SUSE.
     </p></li><li class="listitem "><p>
      SUSE Helm chart repository.
     </p></li><li class="listitem "><p>
      Helm, the Kubernetes package manager, and the <code class="command">helm</code>
      command line client.
     </p></li><li class="listitem "><p>
      <code class="command">kubectl</code>, the command line client for Kubernetes.
     </p></li><li class="listitem "><p>
       <code class="command">cf-operator</code>, a Kubernetes Operator that converts BOSH
       releases to Kubernetes resources.
     </p></li><li class="listitem "><p>
       <code class="command">KubeCF</code>, a version of Cloud Foundry deployed via cf-operator.
     </p></li><li class="listitem "><p>
      Long-running KubeCF components.
     </p></li><li class="listitem "><p>
      KubeCF post-deployment components: Transient KubeCF components that start
      after all KubeCF components are started, perform their tasks, and then
      exit.
     </p></li><li class="listitem "><p>
      KubeCF Linux cell, an elastic runtime component that runs Linux
      applications.
     </p></li><li class="listitem "><p>
      <code class="literal">uaa</code>, a Cloud Application Platform service for authentication and
      authorization.
     </p></li><li class="listitem "><p>
      The Kubernetes API.
     </p></li></ul></div></div><div class="sect2 " id="sec-cap-containers"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">KubeCF Containers</span> <a title="Permalink" class="permalink" href="#sec-cap-containers">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_overview.xml</li><li><span class="ds-label">ID: </span>sec-cap-containers</li></ul></div></div></div></div><p>
    <a class="xref" href="#fig-cap-cap-containers" title="KubeCF Containers, Grouped by Function">Figure 1.4, “KubeCF Containers, Grouped by Function”</a> provides a look at KubeCF's
    containers.
   </p><div class="figure" id="fig-cap-cap-containers"><div class="figure-contents"><div class="mediaobject"><object xmlns="" type="image/svg+xml" data="images/cap-containers.svg" width=""></object></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 1.4: </span><span class="name">KubeCF Containers, Grouped by Function </span><a title="Permalink" class="permalink" href="#fig-cap-cap-containers">#</a></h6></div></div><div class="variablelist "><div class="variablelist-title-wrap"><h6 class="variablelist-title"><span class="name">List of KubeCF Containers </span><a title="Permalink" class="permalink" href="#id-1.3.3.3.4.11.4">#</a></h6></div><dl class="variablelist"><dt id="id-1.3.3.3.4.11.4.2"><span class="term ">adapter</span></dt><dd><p>
       Part of the logging system, manages connections to user application
       syslog drains.
      </p></dd><dt id="id-1.3.3.3.4.11.4.3"><span class="term ">api</span></dt><dd><p>
       Contains the KubeCF Cloud Controller, which implements the CF API. It is
       exposed via the router.
      </p></dd><dt id="id-1.3.3.3.4.11.4.4"><span class="term ">cc-worker</span></dt><dd><p>
       Sidekick to the Cloud Controller, processes background tasks.
      </p></dd><dt id="id-1.3.3.3.4.11.4.5"><span class="term ">database</span></dt><dd><p>
       A PXC database to store persistent data for various CAP components such as the cloud controller, UAA, etc.
      </p></dd><dt id="id-1.3.3.3.4.11.4.6"><span class="term ">diego-api</span></dt><dd><p>
       API for the Diego scheduler.
      </p></dd><dt id="id-1.3.3.3.4.11.4.7"><span class="term ">diego-cell (privileged)</span></dt><dd><p>
       The elastic layer of KubeCF, where applications live.
      </p></dd><dt id="id-1.3.3.3.4.11.4.8"><span class="term ">eirini</span></dt><dd><p>
       An alternative to the Diego scheduler.
      </p></dd><dt id="id-1.3.3.3.4.11.4.9"><span class="term ">eirini-persi</span></dt><dd><p>
       Enables persistent storage for applications when using the Eirini scheduler.
      </p></dd><dt id="id-1.3.3.3.4.11.4.10"><span class="term ">eirini-ssh</span></dt><dd><p>
       Provides SSH access to user applications when using the Eirini scheduler.
      </p></dd><dt id="id-1.3.3.3.4.11.4.11"><span class="term ">doppler</span></dt><dd><p>
       Routes log messages from applications and components.
      </p></dd><dt id="id-1.3.3.3.4.11.4.12"><span class="term ">log-api</span></dt><dd><p>
       Part of the logging system; exposes log streams to users using web
       sockets and proxies user application log messages to syslog drains.
       Exposed using the router.
      </p></dd><dt id="id-1.3.3.3.4.11.4.13"><span class="term ">nats</span></dt><dd><p>
       A pub-sub messaging queue for the routing system.
      </p></dd><dt id="id-1.3.3.3.4.11.4.14"><span class="term ">router</span></dt><dd><p>
       Routes application and API traffic. Exposed using a Kubernetes service.
      </p></dd><dt id="id-1.3.3.3.4.11.4.15"><span class="term ">routing-api</span></dt><dd><p>
       API for the routing system.
      </p></dd><dt id="id-1.3.3.3.4.11.4.16"><span class="term ">scheduler</span></dt><dd><p>
       Service used to create, schedule and interact with jobs that execute on
       Cloud Foundry
      </p></dd><dt id="id-1.3.3.3.4.11.4.17"><span class="term ">singleton-blobstore</span></dt><dd><p>
       A WebDAV blobstore for storing application bits, buildpacks, and stacks.
      </p></dd><dt id="id-1.3.3.3.4.11.4.18"><span class="term ">tcp-router</span></dt><dd><p>
       Routes TCP traffic for your applications.
      </p></dd><dt id="id-1.3.3.3.4.11.4.19"><span class="term ">uaa</span></dt><dd><p>
       User account and authentication.
      </p></dd></dl></div></div><div class="sect2 " id="sec-cap-service-diagram"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">KubeCF Service Diagram</span> <a title="Permalink" class="permalink" href="#sec-cap-service-diagram">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_overview.xml</li><li><span class="ds-label">ID: </span>sec-cap-service-diagram</li></ul></div></div></div></div><p>
    This simple service diagram illustrates how KubeCF components communicate
    with each other (<a class="xref" href="#fig-cap-simple-services" title="Simple Services Diagram">Figure 1.5, “Simple Services Diagram”</a>). See
    <a class="xref" href="#fig-cap-detailed-services" title="Detailed Services Diagram">Figure 1.6, “Detailed Services Diagram”</a> for a more detailed view.
   </p><div class="figure" id="fig-cap-simple-services"><div class="figure-contents"><div class="mediaobject"><object xmlns="" type="image/svg+xml" data="images/cap-simple-services.svg" width=""></object></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 1.5: </span><span class="name">Simple Services Diagram </span><a title="Permalink" class="permalink" href="#fig-cap-simple-services">#</a></h6></div></div><p>
    This table describes how these services operate.
   </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col /><col /><col /><col /><col /></colgroup><thead><tr><th>Interface, Network Name, Network Protocol</th><th>Requestor &amp; Request</th><th>Request Credentials &amp; Request Authorization</th><th>Listener, Response &amp; Response Credentials</th><th>Description of Operation</th></tr></thead><tbody><tr><td>
        <p>
	 1
	</p>
	<p>
         External (HTTPS)
	</p>
       </td><td>
        <p>
 	 <span class="bold"><strong>Requestor</strong></span>: Helm Client
	</p>
	
	<p>
         <span class="bold"><strong>Request</strong></span>: Deploy Cloud Application Platform
	</p>
       </td><td>
        <p>
 	 <span class="bold"><strong>Request Credentials</strong></span>: OAuth2 Bearer
	 token
        </p>
	<p>
	 <span class="bold"><strong>Request Authorization</strong></span>: Deployment of
	 Cloud Application Platform Services on Kubernetes
	</p>
       </td><td>
	<p>
	 <span class="bold"><strong>Listener</strong></span>: Helm/Kubernetes API
	</p>	
	<p>
         <span class="bold"><strong>Response</strong></span>: Operation ack and handle
	</p>
	<p>
         <span class="bold"><strong>Response Credentials</strong></span>: TLS certificate
	 on external endpoint
	</p>
       </td><td>
        <p>
	 Operator deploys Cloud Application Platform on Kubernetes
	</p>
       </td></tr><tr><td>
	<p>
	 2
        </p>
	<p>
         External (HTTPS)
	</p>	
       </td><td>
        <p>
	 <span class="bold"><strong>Requestor</strong></span>: Internal Kubernetes components
	</p>
	<p>
         <span class="bold"><strong>Request</strong></span>: Download Docker Images
	</p>
       </td><td>
        <p>
 	 <span class="bold"><strong>Request Credentials</strong></span>: Refer to
	 registry.suse.com
	</p>
	<p>
 	 <span class="bold"><strong>Request Authorization</strong></span>: Refer to
	 registry.suse.com
	</p>
       </td><td>
        <p>
 	 <span class="bold"><strong>Listener</strong></span>: registry.suse.com
	</p>
	<p>
	 <span class="bold"><strong>Response</strong></span>: Docker images
	</p>
	<p>
	 <span class="bold"><strong>Response Credentials</strong></span>: None
	</p>
       </td><td>
	<p>
 	 Docker images that make up Cloud Application Platform are downloaded
	</p>
       </td></tr><tr><td>
        <p>
         3
	</p>
	<p>
         Tenant (HTTPS)
	</p>
       </td><td>
	<p>
	 <span class="bold"><strong>Requestor</strong></span>: Cloud Application Platform components
	</p>
	<p>
	 <span class="bold"><strong>Request</strong></span>: Get tokens
	</p>
       </td><td>
        <p>
 	 <span class="bold"><strong>Request Credentials</strong></span>: OAuth2 client
	 secret
	</p>
        <p>
	 <span class="bold"><strong>Request Authorization</strong></span>: Varies, based
	 on configured OAuth2 client scopes
	</p>
       </td><td>
	<p>
         <span class="bold"><strong>Listener</strong></span>: <code class="literal">uaa</code>
	</p>
        <p>
	 <span class="bold"><strong>Response</strong></span>: An OAuth2 refresh token used
	 to interact with other service
	</p>
	<p>
         <span class="bold"><strong>Response Credentials</strong></span>: TLS certificate
	</p>
       </td><td>
	<p>
	 KubeCF components ask <code class="literal">uaa</code> for tokens so they can talk
	 to each other
	</p>
       </td></tr><tr><td>
        <p>
         4
	</p>
	<p>
         External (HTTPS)
	</p>
       </td><td>
        <p>
         <span class="bold"><strong>Requestor</strong></span>: KubeCF clients
	</p>
        <p>
         <span class="bold"><strong>Request</strong></span>: KubeCF API Requests
	</p>
       </td><td>
        <p>                                                                  
	 <span class="bold"><strong>Request Credentials</strong></span>: OAuth2 Bearer
	 token
        </p>
        <p>                                                                  
	 <span class="bold"><strong>Request Authorization</strong></span>: KubeCF
	 application management             
        </p>
       </td><td>
	<p>
         <span class="bold"><strong>Listener</strong></span>: Cloud Application Platform components
	</p>
        <p>
	 <span class="bold"><strong>Response</strong></span>: JSON object and HTTP Status
	 code
	</p>
	<p>
	 <span class="bold"><strong>Response Credentials</strong></span>: TLS certificate
	 on external endpoint
	</p>
       </td><td>
        <p>
	 Cloud Application Platform Clients interact with the KubeCF API (for example users deploying
	 apps)
        </p>
       </td></tr><tr><td>
        <p>
         5
	</p>
	<p>
         External (WSS)
	</p>
       </td><td>
        <p>
         <span class="bold"><strong>Requestor</strong></span>: KubeCF clients
	</p>
	<p>
         <span class="bold"><strong>Request</strong></span>: Log streaming
	</p>
       </td><td>
        <p>
 	 <span class="bold"><strong>Request Credentials</strong></span>: OAuth2 Bearer
	 token
	</p>
	<p>
	 <span class="bold"><strong>Request Authorization</strong></span>: KubeCF
	 application management
	</p>
       </td><td>
        <p>
         <span class="bold"><strong>Listener</strong></span>: Cloud Application Platform components
	</p>
	<p>
         <span class="bold"><strong>Response</strong></span>: A stream of KubeCF logs
	</p>
	<p>
	 <span class="bold"><strong>Response Credentials</strong></span>: TLS certificate
	 on external endpoint
	</p>
       </td><td>
	<p>
	 KubeCF clients ask for logs (for example user looking at application
	 logs or administrator viewing system logs)
	</p>
       </td></tr><tr><td>
        <p>
         6
	</p>
	<p>
         External (SSH)
	</p>
       </td><td>
        <p>
         <span class="bold"><strong>Requestor</strong></span>: KubeCF clients, SSH clients
	</p>
	<p>
         <span class="bold"><strong>Request</strong></span>: SSH Access to Application
	</p>
       </td><td>
        <p>
	 <span class="bold"><strong>Request Credentials</strong></span>: OAuth2 bearer
	 token
	</p>
	<p>
	 <span class="bold"><strong>Request Authorization</strong></span>: KubeCF
	 application management
	</p>
       </td><td>
        <p>
         <span class="bold"><strong>Listener</strong></span>: Cloud Application Platform components
	</p>
        <p>
	 <span class="bold"><strong>Response</strong></span>: A duplex connection is
	 created allowing the user to interact with a shell
	</p>
	<p>
	 <span class="bold"><strong>Response Credentials</strong></span>: RSA SSH Key on
	 external endpoint
	</p>
       </td><td>
	<p>
	 KubeCF Clients open an SSH connection to an application's container (for
	 example users debugging their applications)
	</p>
       </td></tr><tr><td>
        <p>
         7
	</p>
	<p>
         External (HTTPS)
	</p>
       </td><td>
        <p>
         <span class="bold"><strong>Requestor</strong></span>: Helm
	</p>
	<p>
         <span class="bold"><strong>Request</strong></span>: Download charts
	</p>
       </td><td>
        <p>
         <span class="bold"><strong>Request Credentials</strong></span>: Refer to
	 kubernetes-charts.suse.com
	</p>
	<p>
         <span class="bold"><strong>Request Authorization</strong></span>: Refer to
	 kubernetes-charts.suse.com
	</p>
       </td><td>
        <p>
	 <span class="bold"><strong>Listener</strong></span>: kubernetes-charts.suse.com
	</p>
        <p>
         <span class="bold"><strong>Response</strong></span>: Helm charts
	</p>
	<p>
	 <span class="bold"><strong>Response Credentials</strong></span>: Helm charts
	 for Cloud Application Platform are downloaded
	</p>
       </td><td>
        <p>
         Helm charts for Cloud Application Platform are downloaded
	</p>
       </td></tr></tbody></table></div></div><div class="sect2 " id="sec-cap-services-detailed"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Detailed Services Diagram</span> <a title="Permalink" class="permalink" href="#sec-cap-services-detailed">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_overview.xml</li><li><span class="ds-label">ID: </span>sec-cap-services-detailed</li></ul></div></div></div></div><p>
    <a class="xref" href="#fig-cap-detailed-services" title="Detailed Services Diagram">Figure 1.6, “Detailed Services Diagram”</a> presents a more detailed view
    of KubeCF services and how they interact with each other. Services labeled
    in red are unencrypted, while services labeled in green run over HTTPS.
   </p><div class="figure" id="fig-cap-detailed-services"><div class="figure-contents"><div class="mediaobject"><object xmlns="" type="image/svg+xml" data="images/cap-detailed-services.svg" width=""></object></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 1.6: </span><span class="name">Detailed Services Diagram </span><a title="Permalink" class="permalink" href="#fig-cap-detailed-services">#</a></h6></div></div></div></div></div><div class="chapter " id="cha-cap-depl-kube-requirements"><div class="titlepage"><div><div><h2 class="title"><span class="number">2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Other Kubernetes Systems</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-kube-requirements">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_kube_requirements.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-changes-kube-reqs"><span class="number">2.1 </span><span class="name">Kubernetes Requirements</span></a></span></dt></dl></div></div><div class="sect1 " id="sec-cap-changes-kube-reqs"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes Requirements</span> <a title="Permalink" class="permalink" href="#sec-cap-changes-kube-reqs">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_kube_requirements.xml</li><li><span class="ds-label">ID: </span>sec-cap-changes-kube-reqs</li></ul></div></div></div></div><p>
   SUSE Cloud Application Platform is designed to run on any Kubernetes system that meets the
   following requirements:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Kubernetes API version of at least 1.14
    </p></li><li class="listitem "><p>
 Ensure nodes use a mininum kernel version of 3.19 and the kernel
 parameter <code class="literal">max_user_namespaces</code> should be set greater than 0. 
</p></li><li class="listitem "><p>
     The container runtime storage driver should
     <span class="bold"><strong>not</strong></span> be <code class="literal">aufs</code>.
    </p></li><li class="listitem "><p>
     Presence of a storage class for SUSE Cloud Application Platform to use
    </p></li><li class="listitem "><p>
     <code class="command">kubectl</code> can authenticate with the apiserver
    </p></li><li class="listitem "><p>
     <code class="literal">kube-dns</code> or <code class="literal">core-dns</code> should be
     running and ready
    </p></li><li class="listitem "><p>
     <code class="command">ntp</code>, <code class="command">systemd-timesyncd</code>, 
     or <code class="command">chrony</code> must be installed and active
    </p></li><li class="listitem "><p>
     The container runtime must be configured to allow privileged containers
    </p></li><li class="listitem "><p>
     Privileged container must be enabled in <code class="literal">kube-apiserver</code>.
     See <a class="link" href="https://kubernetes.io/docs/admin/kube-apiserver" target="_blank">
     kube-apiserver</a>.
    </p></li><li class="listitem "><p>
     For Kubernetes deployments prior to version 1.15, privileged must be enabled
     in <code class="literal">kubelet</code>
    </p></li><li class="listitem "><p>
     The <code class="literal">TasksMax</code> property of the
     <code class="literal">containerd</code> service definition must be set to infinity
    </p></li></ul></div></div></div></div><div class="part" id="part-cap-deployment"><div class="titlepage"><div><div><h1 class="title"><span class="number">Part II </span><span class="name">Deploying SUSE Cloud Application Platform </span><a title="Permalink" class="permalink" href="#part-cap-deployment">#</a></h1></div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="#cha-cap-depl-notes"><span class="number">3 </span><span class="name">Deployment and Administration Notes</span></a></span></dt><dd class="toc-abstract"><p>
  Important things to know before deploying SUSE Cloud Application Platform.
 </p></dd><dt><span class="chapter"><a href="#cha-cap-depl-caasp"><span class="number">4 </span><span class="name">Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</span></a></span></dt><dd class="toc-abstract"><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p></dd><dt><span class="chapter"><a href="#cha-cap-depl-aks"><span class="number">5 </span><span class="name">Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</span></a></span></dt><dd class="toc-abstract"><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p></dd><dt><span class="chapter"><a href="#cha-cap-depl-eks"><span class="number">6 </span><span class="name">Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</span></a></span></dt><dd class="toc-abstract"><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p></dd><dt><span class="chapter"><a href="#cha-cap-depl-gke"><span class="number">7 </span><span class="name">Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</span></a></span></dt><dd class="toc-abstract"><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p></dd><dt><span class="chapter"><a href="#cha-cap-install-stratos"><span class="number">8 </span><span class="name">Installing the Stratos Web Console</span></a></span></dt><dd class="toc-abstract"><p>
   The Stratos user interface (UI) is a modern web-based management application
   for Cloud Foundry. It provides a graphical management console for both
   developers and system administrators.
  </p></dd><dt><span class="chapter"><a href="#cha-cap-depl-eirini"><span class="number">9 </span><span class="name">Eirini</span></a></span></dt><dd class="toc-abstract"><p>
  Eirini, an alternative to Diego, is a scheduler for the Cloud Foundry Application
  Runtime (CFAR) that runs Cloud Foundry user applications in Kubernetes. For details about
  Eirini, see <a class="link" href="https://www.cloudfoundry.org/project-eirini/" target="_blank">https://www.cloudfoundry.org/project-eirini/</a>
  and <a class="link" href="http://eirini.cf" target="_blank">http://eirini.cf</a>
 </p></dd><dt><span class="chapter"><a href="#cha-cap-depl-terraform"><span class="number">10 </span><span class="name">Deploying SUSE Cloud Application Platform Using Terraform</span></a></span></dt><dd class="toc-abstract"><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p></dd><dt><span class="chapter"><a href="#cha-cap-depl-air-gap-registry"><span class="number">11 </span><span class="name">Setting Up a Registry for an Air Gapped Environment</span></a></span></dt><dd class="toc-abstract"><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p></dd><dt><span class="chapter"><a href="#cha-cap-depl-private-registry"><span class="number">12 </span><span class="name">SUSE Private Registry</span></a></span></dt><dd class="toc-abstract"><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p></dd></dl></div><div class="chapter " id="cha-cap-depl-notes"><div class="titlepage"><div><div><h2 class="title"><span class="number">3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment and Administration Notes</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-notes">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_admin_notes.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.3.4.3.3"><span class="number">3.1 </span><span class="name">Important Changes</span></a></span></dt><dt><span class="sect1"><a href="#sec-pod-status"><span class="number">3.2 </span><span class="name">Status of Pods during Deployment</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.3.5"><span class="number">3.3 </span><span class="name">Length of Release Names</span></a></span></dt><dt><span class="sect1"><a href="#cha-cap-depl-notes-releases"><span class="number">3.4 </span><span class="name">Releases and Associated Versions</span></a></span></dt></dl></div></div><p>
  Important things to know before deploying SUSE Cloud Application Platform.
 </p><div class="sect1 " id="id-1.3.4.3.3"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Important Changes</span> <a title="Permalink" class="permalink" href="#id-1.3.4.3.3">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_admin_notes.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Schedulers such as Diego and Eirini, and stacks such as
   <code class="literal">cflinuxfs3</code> or <code class="literal">sle15</code>, have different
   memory requirements for applications. Not every combination is tested so
   there is no universal memory setting for Cloud Application Platform, and because it depends on the
   application deployed, it is up to the user to adjust the setting based on
   their application.
  </p></div><div class="sect1 " id="sec-pod-status"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Status of Pods during Deployment</span> <a title="Permalink" class="permalink" href="#sec-pod-status">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_admin_notes.xml</li><li><span class="ds-label">ID: </span>sec-pod-status</li></ul></div></div></div></div><p>
  During deployment, pods are spawned over time, starting with a single
  pod whose name stars with <code class="literal">ig-</code>. This pod will eventually
  disappear and will be replaced by other pods whose progress
  then can be followed as usual.
 </p><p>
  The whole process can take around 20—30 minutes to finish.
 </p><p>
  The initial stage may look like this:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get pods --namespace kubecf
ig-kubecf-f9085246244fbe70-jvg4z   1/21    Running             0          8m28s</pre></div><p>
  Later the progress may look like this:
 </p><div class="verbatim-wrap"><pre class="screen">NAME                        READY   STATUS       RESTARTS   AGE
adapter-0                   4/4     Running      0          6m45s
api-0                       0/15    Init:30/63   0          6m38s
bits-0                      0/6     Init:8/15    0          6m34s
bosh-dns-7787b4bb88-2wg9s   1/1     Running      0          7m7s
bosh-dns-7787b4bb88-t42mh   1/1     Running      0          7m7s
cc-worker-0                 0/4     Init:5/9     0          6m36s
credhub-0                   0/5     Init:6/11    0          6m33s
database-0                  2/2     Running      0          6m36s
diego-api-0                 6/6     Running      2          6m38s
doppler-0                   0/9     Init:7/16    0          6m40s
eirini-0                    9/9     Running      0          6m37s
log-api-0                   0/7     Init:6/13    0          6m35s
nats-0                      4/4     Running      0          6m39s
router-0                    0/5     Init:5/11    0          6m33s
routing-api-0               0/4     Init:5/10    0          6m42s
scheduler-0                 0/8     Init:8/17    0          6m35s
singleton-blobstore-0       0/6     Init:6/11    0          6m46s
tcp-router-0                0/5     Init:5/11    0          6m37s
uaa-0                       0/6     Init:8/13    0          6m36s</pre></div></div><div class="sect1 " id="id-1.3.4.3.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Length of Release Names</span> <a title="Permalink" class="permalink" href="#id-1.3.4.3.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_admin_notes.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  Release names (for example, when you run <code class="command">helm install
  RELEASE_NAME</code>) have a maximum length of 36 characters.
 </p></div><div class="sect1 " id="cha-cap-depl-notes-releases"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Releases and Associated Versions</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-notes-releases">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_admin_notes.xml</li><li><span class="ds-label">ID: </span>cha-cap-depl-notes-releases</li></ul></div></div></div></div><div id="id-1.3.4.3.6.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: KubeCF and cf-operator versions</h6><p>
   KubeCF and cf-operator interoperate closely. Before you deploy a
   specific version combination, make sure they were confirmed to work. For more
   information see <a class="xref" href="#cha-cap-depl-notes-releases" title="3.4. Releases and Associated Versions">Section 3.4, “Releases and Associated Versions”</a>.
  </p></div><p>
   The supported upgrade method is to install all upgrades, in order. Skipping
   releases is not supported. This table matches the Helm chart versions to
   each release as well as other version related information.
  </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col /><col /><col /><col /><col /><col /><col /><col /><col /></colgroup><thead><tr><th>CAP Release</th><th>cf-operator Helm Chart Version</th><th>KubeCF Helm Chart Version</th><th>Stratos Helm Chart Version</th><th>Stratos Metrics Helm Chart Version</th><th>Minimum Kubernetes Version Required</th><th>CF API Implemented</th><th>Known Compatible CF CLI Version</th><th>CF CLI URL</th></tr></thead><tbody><tr><td>2.1.0 (current release)</td><td>6.1.17+0.gec409fd7</td><td>2.5.8</td><td>4.2.0</td><td>1.3.0</td><td>1.14</td><td>2.144.0</td><td>6.49.0</td><td><a class="link" href="https://github.com/cloudfoundry/cli/releases/tag/v6.49.0" target="_blank">https://github.com/cloudfoundry/cli/releases/tag/v6.49.0</a></td></tr><tr><td>2.0.1</td><td>4.5.13+.gd4738712</td><td>2.2.3</td><td>4.0.1</td><td>1.2.1</td><td>1.14</td><td>2.144.0</td><td>6.49.0</td><td><a class="link" href="https://github.com/cloudfoundry/cli/releases/tag/v6.49.0" target="_blank">https://github.com/cloudfoundry/cli/releases/tag/v6.49.0</a></td></tr><tr><td>2.0</td><td>4.5.6+0.gffc6f942</td><td>2.2.2</td><td>3.2.1</td><td>1.2.1</td><td>1.14</td><td>2.144.0</td><td>6.49.0</td><td><a class="link" href="https://github.com/cloudfoundry/cli/releases/tag/v6.49.0" target="_blank">https://github.com/cloudfoundry/cli/releases/tag/v6.49.0</a></td></tr></tbody></table></div></div></div><div class="chapter " id="cha-cap-depl-caasp"><div class="titlepage"><div><div><h2 class="title"><span class="number">4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-caasp">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-prereqs-caasp"><span class="number">4.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-caasp-cluster"><span class="number">4.2 </span><span class="name">Creating a SUSE CaaS Platform Cluster</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.4.6"><span class="number">4.3 </span><span class="name">Install the Helm Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-storage"><span class="number">4.4 </span><span class="name">Storage Class</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-config"><span class="number">4.5 </span><span class="name">Deployment Configuration</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-certificates"><span class="number">4.6 </span><span class="name">
  Certificates
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-ingress"><span class="number">4.7 </span><span class="name">
  Using an Ingress Controller
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-affinity"><span class="number">4.8 </span><span class="name">
  Affinity and Anti-affinity
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-high-availability"><span class="number">4.9 </span><span class="name">
  High Availability
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-external-blobstore"><span class="number">4.10 </span><span class="name">
  External Blobstore
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-external-database"><span class="number">4.11 </span><span class="name">
  External Database
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-addrepo-caasp"><span class="number">4.12 </span><span class="name">Add the Kubernetes Charts Repository</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-cap-on-caasp"><span class="number">4.13 </span><span class="name">Deploying SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-ldap"><span class="number">4.14 </span><span class="name">
  LDAP Integration
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-caasp-add-capacity"><span class="number">4.15 </span><span class="name">Expanding Capacity of a Cloud Application Platform Deployment on SUSE® CaaS Platform</span></a></span></dt></dl></div></div><div id="id-1.3.4.4.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        <a class="link" href="https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2.0/" target="_blank">
        SUSE Cloud Application Platform Release Notes</a>
      </p></li><li class="listitem "><p>
        <a class="xref" href="#cha-cap-depl-notes" title="Chapter 3. Deployment and Administration Notes">Chapter 3, <em>Deployment and Administration Notes</em></a>
      </p></li></ul></div></div><p>
  SUSE Cloud Application Platform supports deployment on SUSE CaaS Platform. SUSE CaaS Platform is an enterprise-class
  container management solution that enables IT and DevOps professionals to more
  easily deploy, manage, and scale container-based applications and services. It
  includes Kubernetes to automate lifecycle management of modern applications, and
  surrounding technologies that enrich Kubernetes and make the platform itself
  easy to operate. As a result, enterprises that use SUSE CaaS Platform can reduce
  application delivery cycle times and improve business agility. This chapter
  describes the steps to prepare a SUSE Cloud Application Platform deployment on SUSE CaaS Platform. See
  <a class="link" href="https://documentation.suse.com/suse-caasp/4.5/" target="_blank">https://documentation.suse.com/suse-caasp/4.5/</a>
  for more information on SUSE CaaS Platform.
 </p><div class="sect1 " id="sec-cap-prereqs-caasp"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#sec-cap-prereqs-caasp">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-prereqs-caasp</li></ul></div></div></div></div><p>
   The following are required to deploy and use SUSE Cloud Application Platform on SUSE CaaS Platform:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Access to one of the platforms listed at
     <a class="link" href="https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-deployment/#_platform" target="_blank">https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-deployment/#_platform</a> to deploy SUSE CaaS Platform.
    </p></li><li class="listitem "><p>
     A management workstation, which is used to deploy and control a SUSE CaaS Platform
     cluster, that is capable of running <code class="literal">skuba</code> (see
     <a class="link" href="https://github.com/SUSE/skuba" target="_blank">https://github.com/SUSE/skuba</a> for installation
     instructions). The management workstation can be a regular
     desktop workstation or laptop running SUSE Linux Enterprise 15 SP1 or later.
    </p></li><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">kubectl</code>, the Kubernetes command line tool. For more
 information, refer to
 <a class="link" href="https://kubernetes.io/docs/reference/kubectl/overview/" target="_blank">https://kubernetes.io/docs/reference/kubectl/overview/</a>.
</p><p>
 For SLE 12 SP3 or 15 SP1 systems, install the package
 <span class="package ">kubernetes-client</span> from the <span class="emphasis"><em>Public Cloud</em></span>
 module.
</p><p>
 For other systems, follow the instructions at
 <a class="link" href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a>.
</p></li><li class="listitem "><p>
 <code class="command">jq</code>, a command line JSON processor. See
 <a class="link" href="https://stedolan.github.io/jq/" target="_blank">https://stedolan.github.io/jq/</a> for more information and
 installation instructions.
</p></li><li class="listitem "><p>
 <code class="command">curl</code>, the Client URL (cURL) command line tool.
</p></li><li class="listitem "><p>
 <code class="command">sed</code>, the stream editor.
</p></li></ul></div></div><div class="sect1 " id="sec-cap-create-caasp-cluster"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a SUSE CaaS Platform Cluster</span> <a title="Permalink" class="permalink" href="#sec-cap-create-caasp-cluster">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-create-caasp-cluster</li></ul></div></div></div></div><p>
   When creating a SUSE CaaS Platform cluster, take note of the following general
   guidelines to ensure there are sufficient resources available to run a
   SUSE Cloud Application Platform deployment:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Minimum 2.3 GHz processor
    </p></li><li class="listitem "><p>
     2 vCPU per physical core
    </p></li><li class="listitem "><p>
     4 GB RAM per vCPU
    </p></li><li class="listitem "><p>
     Worker nodes need a minimum of 4 vCPU and 16 GB RAM
    </p></li></ul></div><p>
   As a minimum, a SUSE Cloud Application Platform deployment with a basic workload will require:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     1 master node
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       vCPU: 2
      </p></li><li class="listitem "><p>
       RAM: 8 GB
      </p></li><li class="listitem "><p>
       Storage: 60 GB (SSD)
      </p></li></ul></div></li><li class="listitem "><p>
     2 worker nodes. Each node configured with:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       (v)CPU: 4
      </p></li><li class="listitem "><p>
       RAM: 16 GB
      </p></li><li class="listitem "><p>
       Storage: 100 GB
      </p></li></ul></div></li><li class="listitem "><p>
     Persistent storage: 40 GB
    </p></li></ul></div><p>
   For steps to deploy a SUSE CaaS Platform cluster, refer to the SUSE CaaS Platform Deployment Guide
   at <a class="link" href="https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-deployment/" target="_blank">https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-deployment/</a>
  </p><p>
   Before proceeding with the deployment, take note of the following to
   ensure the SUSE CaaS Platform cluster is suitable for a deployment of SUSE Cloud Application Platform:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Additional changes need to be applied to increase the maximum number of
     processes allowed in a container. If the maximum is insufficient,
     SUSE Cloud Application Platform clusters with multiple application deployed will observe
     applications failing to start.
    </p><p>
     Operators should be aware there are potential security concerns when raising
     the PIDs limit/maximum (fork bombs for example). As a best practice, these
     should be kept as low as possible. The example values are for guidance
     purposes only. Operators are encouraged to identify the typical PIDs usage
     for their workloads and adjust the modifications accordingly. If problems
     persist, these can be raised to a maximum of 32768 provided SUSE Cloud Application Platform
     is the only workload on the SUSE CaaS Platform cluster.
    </p><p>
     For SUSE CaaS Platform 4.5 clusters, apply the following changes directly to each node
     in the cluster.
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       Prior to rebooting/bootstrapping, modify
       <code class="filename">/etc/crio/crio.conf.d/00-default.conf</code> to increase the
       PIDs limit:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo sed -i -e 's|pids_limit = 1024|pids_limit = 3072|g' /etc/crio/crio.conf.d/00-default.conf</pre></div></li></ul></div><p>
     For SUSE CaaS Platform 4.2 clusters, apply the following changes directly to each node
     in the cluster.
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       Prior to rebooting/bootstrapping, modify
       <code class="filename">/etc/crio/crio.conf</code> to increase the PIDs limit:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo sed -i -e 's|pids_limit = 1024|pids_limit = 3072|g' /etc/crio/crio.conf</pre></div></li><li class="listitem "><p> 
       After rebooting/bootstrapping modify
       <code class="filename">/sys/fs/cgroup/pids/kubepods/pids.max</code> to increase the
       PIDs maximum:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo bash -c \"echo '3072' &gt; /sys/fs/cgroup/pids/kubepods/pids.max\"</pre></div></li></ul></div><p>
     Note that these modifications are not persistent and will need to be
     reapplied in the event of a SUSE CaaS Platform node restart or update.
    </p></li><li class="listitem "><p>
     At the cluster initialization step, <span class="bold"><strong>do not</strong></span>
     use the <code class="literal">--strict-capability-defaults</code> option when running
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>skuba cluster init</pre></div><p>
     This ensures the presence of extra CRI-O capabilities compatible with
     Docker containers. For more details refer to the
     <a class="link" href="https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-deployment/#_transitioning_from_docker_to_cri_o" target="_blank">https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-deployment/#_transitioning_from_docker_to_cri_o</a>
    </p></li></ul></div></div><div class="sect1 " id="id-1.3.4.4.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the Helm Client</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Helm is a Kubernetes package manager used to install and manage SUSE Cloud Application Platform.
   This requires installing the Helm client, <code class="command">helm</code>, on your
   remote management workstation. Cloud Application Platform requires Helm 3.
   For more information regarding Helm, refer to the documentation at
   <a class="link" href="https://helm.sh/docs/" target="_blank">https://helm.sh/docs/</a>.
  </p><div id="id-1.3.4.4.6.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Make sure that you are installing and using Helm 3 and not Helm 2.</p></div><p>
   If your remote management workstation has the SUSE CaaS Platform package repository,
   install <code class="command">helm</code> by running
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install helm3
<code class="prompt user">tux &gt; </code>sudo update-alternatives --set helm /usr/bin/helm3</pre></div><p>
   Otherwise, <code class="command">helm</code> can be installed  by referring to the
   documentation at <a class="link" href="https://helm.sh/docs/intro/install/" target="_blank">https://helm.sh/docs/intro/install/</a>.
  </p></div><div class="sect1 " id="sec-cap-caasp-storage"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Storage Class</span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-storage">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-storage</li></ul></div></div></div></div><p>
   In some SUSE Cloud Application Platform instance groups, such as <code class="literal">bits</code>,
   <code class="literal">database</code> and <code class="literal">singleton-blobstore</code>
   require a storage class. To learn more about storage classes, see
   <a class="link" href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank">https://kubernetes.io/docs/concepts/storage/storage-classes/</a>.
   Examples of provisioners include:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     SUSE Enterprise Storage (see
     <a class="link" href="https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-admin/#RBD-dynamic-persistent-volumes" target="_blank">https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-admin/#RBD-dynamic-persistent-volumes</a>)
    </p><p>
     If you are using SUSE Enterprise Storage you must copy the Ceph admin secret to the
     <code class="literal">kubecf</code> namespaces used by SUSE Cloud Application Platform:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get secret ceph-secret-admin --output json --namespace default | \
sed 's/"namespace": "default"/"namespace": "kubecf"/' | kubectl create --filename -</pre></div></li><li class="listitem "><p>
     Network File System (see
     <a class="link" href="https://kubernetes.io/docs/concepts/storage/volumes/#nfs" target="_blank">https://kubernetes.io/docs/concepts/storage/volumes/#nfs</a>
    </p></li></ul></div><p>
   By default, SUSE Cloud Application Platform will use the cluster's default storage class.
   To designate or change the default storage class, refer to
   <a class="link" href="https://kubernetes.io/docs/tasks/administer-cluster/change-default-storage-class/" target="_blank">https://kubernetes.io/docs/tasks/administer-cluster/change-default-storage-class/</a>
   for instructions.
  </p><p>
   In some cases, the default and predefined storage classes may not be suitable
   for certain workloads. If this is the case, operators can define their own
   custom StorageClass resource according to the specification at
   <a class="link" href="https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource" target="_blank">https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource</a>.
  </p><p>
   With the storage class defined, run:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create --filename <em class="replaceable ">my-storage-class.yaml</em></pre></div><p>
   Then verify the storage class is available by running
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get storageclass</pre></div><p>
   If operators do not want to use the default storage class or one does not
   exist, a storage class <span class="bold"><strong>must</strong></span> be specified by
   setting the <code class="literal">kube.storage_class</code> value in your
   <code class="filename">kubecf-config-values.yaml</code> configuration file to the name of the storage class as seen
   in this example.
  </p><div class="verbatim-wrap"><pre class="screen">kube:
  storage_class: <em class="replaceable ">my-storage-class</em></pre></div></div><div class="sect1 " id="sec-cap-caasp-config"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment Configuration</span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-config">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-config</li></ul></div></div></div></div><p>
   SUSE Cloud Application Platform is configured using Helm values (see
   <a class="link" href="https://helm.sh/docs/chart_template_guide/values_files/" target="_blank">https://helm.sh/docs/chart_template_guide/values_files/</a>
   . Helm values can be set as either command line parameters or using a
   <code class="filename">values.yaml</code> file. The following
   <code class="filename">values.yaml</code> file, called
   <code class="filename">kubecf-config-values.yaml</code> in this guide, provides an
   example of a SUSE Cloud Application Platform configuration.
  </p><div id="id-1.3.4.4.8.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: kubecf-config-values.yaml changes</h6><p>
    The format of the <code class="filename">kubecf-config-values.yaml</code> file has been restructured completely in
    Cloud Application Platform 2.x. Do not re-use the Cloud Application Platform 1.x version of the file. Instead, see the
    default file in the appendix in
    <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a> and pick parameters according to
    your needs.
  </p></div><p>
   Ensure <code class="literal">system_domain</code> maps to the load balancer configured for
   your SUSE CaaS Platform cluster (see
   <a class="link" href="https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-deployment/#loadbalancer" target="_blank">https://documentation.suse.com/suse-caasp/4.5/single-html/caasp-deployment/#loadbalancer</a>).
  </p><div id="id-1.3.4.4.8.5" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: Supported Domains</h6><p>
   When selecting a domain, SUSE Cloud Application Platform expects <code class="literal">system_domain</code> to
   be either a subdomain or a root domain. Setting <code class="literal">system_domain</code> to
   a top-level domain, such as <code class="literal">suse</code>, is not supported.
  </p></div><div class="verbatim-wrap"><pre class="screen">### Example deployment configuration file
### kubecf-config-values.yaml

system_domain: example.com

credentials:
  cf_admin_password: <em class="replaceable ">changeme</em>
  uaa_admin_client_secret: <em class="replaceable ">alsochangeme</em>

### This block is required due to the log-cache issue described below
properties:
  log-cache:
    log-cache:
      memory_limit_percent: 3

### This block is required due to the log-cache issue described below
###
### The value for <code class="literal">key</code> may need to be replaced depending on
### how notes in your cluster are labeled
###
### The value(s) listed under <code class="literal">values</code> may need to be
### replaced depending on how notes in your cluster are labeled
operations:
  inline:
  - type: replace
    path: /instance_groups/name=log-cache/env?/bosh/agent/settings/affinity
    value:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: <em class="replaceable ">kubernetes.io/hostname</em>
              operator: In
              values:
              - <em class="replaceable ">LABEL_VALUE_OF_NODE</em></pre></div><div class="sect2 " id="id-1.3.4.4.8.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Log-cache Memory Allocation</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.8.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  The log-cache component currently has a memory allocation issue where the node
  memory available is reported instead of the one assigned to the container under
  cgroups. In such a situation, log-cache would start allocating memory based on
  these values, causing a varying range of issues (OOMKills, performance
  degradation, etc.). To address this issue, node affinity must be used to tie
  log-cache to nodes of a uniform size, and then declaring the cache percentage
  based on that number. A limit of 3% has been identified as sufficient.
 </p><p>
  In the node affinity configuration, the values for <code class="literal">key</code> and
  <code class="literal">values</code> may need to be changed depending on how notes in your
  cluster are labeled. For more information on labels, see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels</a>.
 </p></div><div class="sect2 " id="id-1.3.4.4.8.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Diego Cell Affinities and Tainted Nodes</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.8.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  Note that the <code class="literal">diego-cell</code> pods used by the Diego standard
  scheduler are
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    privileged
   </p></li><li class="listitem "><p>
    use large local emptyDir volumes (i.e. require node disk storage)
   </p></li><li class="listitem "><p>
    and set kernel parameters on the node
   </p></li></ul></div><p>
  These things all mean that these pods should not live next to other Kubernetes
  workloads. They should all be placed on their own
  <span class="bold"><strong>dedicated nodes</strong></span> instead where possible.
 </p><p>
  This can be done by setting affinities and tolerations, as explained in
the associated tutorial at <a class="link" href="https://kubecf.io/docs/deployment/affinities-and-tolerations/" target="_blank">https://kubecf.io/docs/deployment/affinities-and-tolerations/</a>.
 </p></div></div><div class="sect1 " id="sec-cap-caasp-certificates"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Certificates
 </span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-certificates">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-certificates</li></ul></div></div></div></div><p>
  This section describes the process to secure traffic passing through your
  SUSE Cloud Application Platform deployment. This is achieved by using certificates to set up
  Transport Layer Security (TLS) for the router component. Providing
  certificates for the router traffic is optional. In a default deployment,
  without operator-provided certificates, generated certificates will be used.
 </p><div class="sect2 " id="id-1.3.4.4.9.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Certificate Characteristics</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.9.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Ensure the certificates you use have the following characteristics:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The certificate is encoded in the PEM format.
    </p></li><li class="listitem "><p>
     The certificate is signed by an external Certificate Authority (CA).
    </p></li><li class="listitem "><p>
     The certificate's Subject Alternative Names (SAN) include the domain
     <em class="replaceable ">*.example.com</em>, where <em class="replaceable ">example.com</em>
     is replaced with the <code class="literal">system_domain</code> in your
     <code class="filename">kubecf-config-values.yaml</code>.
    </p></li></ul></div></div><div class="sect2 " id="id-1.3.4.4.9.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.9.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The certificate used to secure your deployment is passed through the
   <code class="filename">kubecf-config-values.yaml</code> configuration file. To specify
   a certificate, set the value of the certificate and its corresponding private
   key using the <code class="literal">router.tls.crt</code> and
   <code class="literal">router.tls.key</code> Helm values in the
   <code class="literal">settings:</code> section.
  </p><div class="verbatim-wrap"><pre class="screen">settings:
  router:
    tls:
      crt: |
        -----BEGIN CERTIFICATE-----
        MIIEEjCCAfoCCQCWC4NErLzy3jANBgkqhkiG9w0BAQsFADBGMQswCQYDVQQGEwJD
        QTETMBEGA1UECAwKU29tZS1TdGF0ZTEOMAwGA1UECgwFTXlPcmcxEjAQBgNVBAMM
        CU15Q0Euc2l0ZTAeFw0xODA5MDYxNzA1MTRaFw0yMDAxMTkxNzA1MTRaMFAxCzAJ
        ...
        xtNNDwl2rnA+U0Q48uZIPSy6UzSmiNaP3PDR+cOak/mV8s1/7oUXM5ivqkz8pEJo
        M3KrIxZ7+MbdTvDOh8lQplvFTeGgjmUDd587Gs4JsormqOsGwKd1BLzQbGELryV9
        1usMOVbUuL8mSKVvgqhbz7vJlW1+zwmrpMV3qgTMoHoJWGx2n5g=
        -----END CERTIFICATE-----
      key: |
        -----BEGIN RSA PRIVATE KEY-----
        MIIEpAIBAAKCAQEAm4JMchGSqbZuqc4LdryJpX2HnarWPOW0hUkm60DL53f6ehPK
        T5Dtb2s+CoDX9A0iTjGZWRD7WwjpiiuXUcyszm8y9bJjP3sIcTnHWSgL/6Bb3KN5
        G5D8GHz7eMYkZBviFvygCqEs1hmfGCVNtgiTbAwgBTNsrmyx2NygnF5uy4KlkgwI
        ...
        GORpbQKBgQDB1/nLPjKxBqJmZ/JymBl6iBnhIgVkuUMuvmqES2nqqMI+r60EAKpX
        M5CD+pq71TuBtbo9hbjy5Buh0+QSIbJaNIOdJxU7idEf200+4anzdaipyCWXdZU+
        MPdJf40awgSWpGdiSv6hoj0AOm+lf4AsH6yAqw/eIHXNzhWLRvnqgA==
        -----END RSA PRIVATE KEY----</pre></div></div></div><div class="sect1 " id="sec-cap-caasp-ingress"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Using an Ingress Controller
 </span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-ingress">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-ingress</li></ul></div></div></div></div><p>
  This section describes how to use an ingress controller
  (see <a class="link" href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank">https://kubernetes.io/docs/concepts/services-networking/ingress/</a>)
  to manage access to the services in the cluster. Using an ingress controller
  is optional. In a default deployment, load balancers are used instead.
 </p><p>
  Note that only the NGINX Ingress Controller has been verified to be
  compatible with Cloud Application Platform. Other Ingress controller alternatives may work, but
  compatibility with Cloud Application Platform is not supported.
 </p><div class="sect2 " id="id-1.3.4.4.10.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install and Configure the NGINX Ingress Controller</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.10.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Create a configuration file with the section below. The file is called
     <code class="filename">nginx-ingress.yaml</code> in this example. When using
     Eirini instead of Diego, replace the first line with
     <code class="literal">2222: "kubecf/eirinix-ssh-proxy:2222"</code>.
    </p><div class="verbatim-wrap"><pre class="screen">tcp:
  2222: "kubecf/scheduler:2222"
  20000: "kubecf/tcp-router:20000"
  20001: "kubecf/tcp-router:20001"
  20002: "kubecf/tcp-router:20002"
  20003: "kubecf/tcp-router:20003"
  20004: "kubecf/tcp-router:20004"
  20005: "kubecf/tcp-router:20005"
  20006: "kubecf/tcp-router:20006"
  20007: "kubecf/tcp-router:20007"
  20008: "kubecf/tcp-router:20008"</pre></div></li><li class="step "><p>
     Create the namespace.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">nginx-ingress</em></pre></div></li><li class="step "><p>
     Install the NGINX Ingress Controller.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">nginx-ingress</em> suse/nginx-ingress \
--namespace <em class="replaceable ">nginx-ingress</em> \
--values <em class="replaceable ">nginx-ingress.yaml</em></pre></div></li><li class="step "><p>
     Monitor the progess of the deployment:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">nginx-ingress</em>'</pre></div></li><li class="step "><p>
     After the deployment completes, the Ingress controller service will be deployed
     with either an external IP or a hostname. 
    </p><p>
     Find the external IP or hostname.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get services nginx-ingress-controller --namespace nginx-ingress</pre></div><p>
     You will get output similar to the following.
    </p><div class="verbatim-wrap"><pre class="screen">NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)
nginx-ingress-controller   LoadBalancer   <em class="replaceable ">10.63.248.70</em>   <em class="replaceable ">35.233.191.177</em>   80:30344/TCP,443:31386/TCP</pre></div></li><li class="step "><p>
     Set up DNS records corresponding to the controller service IP or hostname
     and map it to the <code class="literal">system_domain</code> defined in your
     <code class="filename">kubecf-config-values.yaml</code>.
    </p></li><li class="step "><p>
     Obtain a PEM formatted certificate that is associated with the
     <code class="literal">system_domain</code> defined in your <code class="filename">kubecf-config-values.yaml</code>
    </p></li><li class="step "><p>
     In your <code class="filename">kubecf-config-values.yaml</code> configuration file, enable the ingress feature and
     set the <code class="literal">tls.crt</code> and <code class="literal">tls.key</code> for the
     certificate from the previous step.
    </p><div class="verbatim-wrap"><pre class="screen">features:
  ingress:
    enabled: true
    tls:
      crt: |
        -----BEGIN CERTIFICATE-----
        MIIE8jCCAtqgAwIBAgIUT/Yu/Sv8AUl5zHXXEKCy5RKJqmYwDQYJKoZIhvcMOQMM
        [...]
        xC8x/+zB7XlvcRJRio6kk670+25ABP==
        -----END CERTIFICATE-----
      key: |
        -----BEGIN RSA PRIVATE KEY-----
        MIIE8jCCAtqgAwIBAgIUSI02lj2b2ImLy/zMrjNgW5d8EygwQSVJKoZIhvcYEGAW
        [...]
        to2WV7rPMb9W9fd2vVUXKKHTc+PiNg==
        -----END RSA PRIVATE KEY-----</pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-caasp-affinity"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Affinity and Anti-affinity
 </span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-affinity">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-affinity</li></ul></div></div></div></div><div id="id-1.3.4.4.11.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
   This feature requires SUSE Cloud Application Platform 2.0.1 or newer.
  </p></div><p>
  Operators can set affinity/anti-affinity rules to restrict how the scheduler
  determines the placement of a given pod on a given node. This can be
  achieved through node affinity/anti-affinity, where placement is determined
  by node labels (see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity</a>),
  or pod affinity/anti-affinity, where pod placement is determined by labels
  on pods that are already running on the node (see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity</a>). 
 </p><p>
  In SUSE Cloud Application Platform, a default configuration will have following
  affinity/anti-affinity rules already in place:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Instance groups have anti-affinity against themselves. This applies to all
    instance groups, including <code class="literal">database</code>, but not to the
    <code class="literal">bits</code>, <code class="literal">eirini</code>, and
    <code class="literal">eirini-extensions</code> subcharts.
   </p></li><li class="listitem "><p>
    The <code class="literal">diego-cell</code> and <code class="literal">router</code> instance
    groups have anti-affinity against each other.
   </p></li></ul></div><p>
  Note that to ensure an optimal spread of the pods across worker nodes we
  recommend running 5 or more worker nodes to satisfy both of the default
  anti-affinity constraints. An operator can also specify custom affinity rules
  via the
  <code class="literal">sizing.<em class="replaceable ">instance-group</em>.affinity</code>
  helm parameter and any affinity rules specified here will overwrite the
  default rule, not merge with it.
 </p><div class="sect2 " id="id-1.3.4.4.11.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring Rules</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.11.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   To add or override affinity/anti-affinity settings, add a
   <code class="literal">sizing.INSTANCE_GROUP.affinity</code> block to your
   <code class="filename">kubecf-config-values.yaml</code>. Repeat as necessary for each instance group where
   affinity/anti-affinity settings need to be applied. For information on
   the available fields and valid values within the <code class="literal">affinity:</code>
   block, see
   <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity</a>.
   Repeat as necessary for each instance group where affinity/anti-affinity
   settings need to be applied.
  </p><p>
   Example 1, node affinity.
  </p><p>
   Using this configuration, the Kubernetes scheduler would place both the
   <code class="literal">asactors</code> and <code class="literal">asapi</code> instance groups on a
   node with a label where the key is
   <code class="literal">topology.kubernetes.io/zone</code> and the value is
   <code class="literal">0</code>.
  </p><div class="verbatim-wrap"><pre class="screen">sizing:
   asactors:
     affinity:
       nodeAffinity:
         requiredDuringSchedulingIgnoredDuringExecution:
           nodeSelectorTerms:
           - matchExpressions:
             - key: topology.kubernetes.io/zone
               operator: In
               values:
               - 0
   asapi:
     affinity:
       nodeAffinity:
         requiredDuringSchedulingIgnoredDuringExecution:
           nodeSelectorTerms:
           - matchExpressions:
             - key: topology.kubernetes.io/zone
               operator: In
               values:
               - 0</pre></div><p>
   Example 2, pod anti-affinity.
  </p><div class="verbatim-wrap"><pre class="screen">sizing:
  api:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: quarks.cloudfoundry.org/quarks-statefulset-name
                operator: In
                values:
                - sample_group
            topologyKey: kubernetes.io/hostname
  database:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: quarks.cloudfoundry.org/quarks-statefulset-name
                operator: In
                values:
                - sample_group
            topologyKey: kubernetes.io/hostname</pre></div><p>
   Example 1 above uses <code class="literal">topology.kubernetes.io/zone</code> as its
   label, which is one of the standard labels that get attached to nodes by
   default. The list of standard labels can be found at
   <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels</a>. 
  </p><p>
   In addition to the standard labels, custom labels can be specified as in
   Example 2. To use custom labels, following the process described in this
   section <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector</a>.
  </p></div></div><div class="sect1 " id="sec-cap-caasp-high-availability"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  High Availability
 </span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-high-availability">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-high-availability</li></ul></div></div></div></div><div class="sect2 " id="id-1.3.4.4.12.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring Cloud Application Platform for High Availability</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.12.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   High availability mode is optional. In a default deployment, SUSE Cloud Application Platform is
   deployed in single availability mode.
  </p><p>
   There are two ways to make your SUSE Cloud Application Platform deployment highly available.
   The first method is to set the <code class="literal">high_availability</code> parameter
   in your deployment configuration file to <code class="literal">true</code>. The second
   method is to create custom configuration files with your own sizing values.
  </p><div class="sect3 " id="id-1.3.4.4.12.2.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.9.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Finding Default and Allowable Sizing Values</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.12.2.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    The <code class="literal">sizing:</code> section in the Helm
    <code class="filename">values.yaml</code> files for the <code class="literal">kubecf</code> chart
    describes which roles can be scaled, and the scaling options for each role.
    You may use <code class="command">helm inspect</code> to read the
    <code class="literal">sizing:</code> section in the Helm chart:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm show suse/kubecf | less +/sizing:</pre></div><p>
    Another way is to use Perl to extract the information for each role from
    the <code class="literal">sizing:</code> section.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm inspect values suse/kubecf | \
perl -ne '/^sizing/..0 and do { print $.,":",$_ if /^ [a-z]/ || /high avail|scale|count/ }'</pre></div><p>
    The default <code class="filename">values.yaml</code> files are also included in
    this guide at <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a>.
   </p></div><div class="sect3 " id="id-1.3.4.4.12.2.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.9.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the <code class="literal">high_availability</code> Helm Property</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.12.2.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    One way to make your SUSE Cloud Application Platform deployment highly available is
    to use the <code class="literal">high_availability</code> Helm property. In your
    <code class="filename">kubecf-config-values.yaml</code>, set this property to
    <code class="literal">true</code>. This changes the size of all roles to the minimum
    required for a highly available deployment. Your configuration file,
    <code class="filename">kubecf-config-values.yaml</code>, should include the following.
   </p><div class="verbatim-wrap"><pre class="screen">high_availability: true</pre></div><div id="id-1.3.4.4.12.2.5.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Sizing Priority</h6><p>
   When sizing values are specified, it takes precedence over the <code class="literal">high_availability</code> property.
  </p></div></div><div class="sect3 " id="id-1.3.4.4.12.2.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.9.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Custom Sizing Configurations</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.12.2.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    Another method to make your SUSE Cloud Application Platform deployment highly available is           
    to explicitly configure the instance count of an instance group.
   </p><div id="id-1.3.4.4.12.2.6.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Sizing Priority</h6><p>
   When sizing values are specified, it takes precedence over the <code class="literal">high_availability</code> property.
  </p></div><p>
    To see the full list of configurable instance groups, refer to default
    KubeCF <code class="filename">values.yaml</code> file in the appendix at
    <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a>.
   </p><p>
    The following is an example High Availability configuration. The example values are not meant to be
    copied, as these depend on your particular deployment and requirements.
   </p><div class="verbatim-wrap"><pre class="screen">sizing:
  adapter:
    instances: 2
  api:
    instances: 2
  asactors:
    instances: 2
  asapi:
    instances: 2
  asmetrics:
    instances: 2
  asnozzle:
    instances: 2
  auctioneer:
    instances: 2
  bits:
    instances: 2
  cc_worker:
    instances: 2
  credhub:
    instances: 2
  database:
    instances: 1
  diego_api:
    instances: 2
  diego_cell:
    instances: 2
  doppler:
    instances: 2
  eirini:
    instances: 3
  log_api:
    instances: 2
  nats:
    instances: 2
  router:
    instances: 2
  routing_api:
    instances: 2
  scheduler:
    instances: 2
  uaa:
    instances: 2
  tcp_router:
    instances: 2</pre></div></div></div></div><div class="sect1 " id="sec-cap-caasp-external-blobstore"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  External Blobstore
 </span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-external-blobstore">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-external-blobstore</li></ul></div></div></div></div><p>
  Cloud Foundry Application Runtime (CFAR) uses a blobstore (see
  <a class="link" href="https://docs.cloudfoundry.org/concepts/cc-blobstore.html" target="_blank">https://docs.cloudfoundry.org/concepts/cc-blobstore.html</a>)
  to store the source code that developers push, stage, and run. This section
  explains how to configure an external blobstore for the Cloud Controller
  component of your SUSE Cloud Application Platform deployment. Using an external blobstore is
  optional. In a default deployment, an internal blobstore is used.
 </p><p>
  SUSE Cloud Application Platform relies on <code class="filename">ops files</code> (see
  <a class="link" href="https://github.com/cloudfoundry/cf-deployment/blob/master/operations/README.md" target="_blank">https://github.com/cloudfoundry/cf-deployment/blob/master/operations/README.md</a>)
  provided by cf-deployment (see <a class="link" href="https://github.com/cloudfoundry/cf-deployment" target="_blank">https://github.com/cloudfoundry/cf-deployment</a>)
  releases for external blobstore configurations. The default configuration for
  the blobstore is <code class="literal">singleton</code>.
 </p><div class="sect2 " id="id-1.3.4.4.13.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.13.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Currently SUSE Cloud Application Platform supports Amazon Simple Storage Service (Amazon S3,
   see <a class="link" href="https://aws.amazon.com/s3/" target="_blank">https://aws.amazon.com/s3/</a>) as an external blobstore. 
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Using the Amazon S3 service, create four buckets. A bucket should be
     created for app packages, buildpacks, droplets, and resources. For
     instructions on how to create Amazone S3 buckets, see
     <a class="link" href="https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html" target="_blank">https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html</a>.
    </p></li><li class="step "><p>
     To grant proper access to the create buckets, configure an additional IAM
     role as described in the first step of <a class="link" href="https://docs.cloudfoundry.org/deploying/common/cc-blobstore-config.html#fog-aws-iam" target="_blank">https://docs.cloudfoundry.org/deploying/common/cc-blobstore-config.html#fog-aws-iam</a>.
    </p></li><li class="step "><p>
     Set the following in your <code class="filename">kubecf-config-values.yaml</code> file and replace the
     example values.
    </p><div class="verbatim-wrap"><pre class="screen">features:
  blobstore:
    provider: s3
    s3:
      aws_region: <em class="replaceable ">"us-east-1"</em>
      blobstore_access_key_id:  <em class="replaceable ">AWS-ACCESS-KEY-ID</em>
      blobstore_secret_access_key: <em class="replaceable ">AWS-SECRET-ACCESS-KEY&gt;</em>
      # User provided value for the blobstore admin password.
      blobstore_admin_users_password: <em class="replaceable ">PASSWORD</em>
      # The following values are used as S3 bucket names. The buckets are automatically created if not present.
      app_package_directory_key: <em class="replaceable ">APP-BUCKET-NAME</em>
      buildpack_directory_key: <em class="replaceable ">BUILDPACK-BUCKET-NAME</em>
      droplet_directory_key: <em class="replaceable ">DROPLET-BUCKET-NAME</em>
      resource_directory_key: <em class="replaceable ">RESOURCE-BUCKET-NAME</em></pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-caasp-external-database"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  External Database
 </span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-external-database">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-external-database</li></ul></div></div></div></div><p>
  SUSE Cloud Application Platform can be configured to use an external database system, such as a
  data service offered by a cloud service provider or an existing high
  availability database server. In a default deployment, an internal single
  availability database is used.
 </p><p>
  To configure your deployment to use an external database, please follow the
  instructions below.
 </p><p>
  The current SUSE Cloud Application Platform release is compatible with the following types and
  versions of external databases:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    MySQL 5.7
   </p></li></ul></div><div class="sect2 " id="id-1.3.4.4.14.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.14.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   This section describes how to enable and configure your deployment to connect
   to an external database. The configuration options are specified through
   Helm values inside the <code class="filename">kubecf-config-values.yaml</code>. The
   deployment and configuration of the external database itself is the
   responsibility of the operator and beyond the scope of this documentation. It
   is assumed the external database has been deployed and accessible.
  </p><div id="id-1.3.4.4.14.6.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Configuration during Initial Install Only</h6><p>
    Configuration of SUSE Cloud Application Platform to use an external database
    <span class="bold"><strong>must</strong></span> be done during the initial
    installation and cannot be changed afterwards.
   </p></div><p>
    All the databases listed in the config snippet below need to exist before
    installing KubeCF. One way of doing that is manually running
    <code class="literal">CREATE DATABASE IF NOT EXISTS
    <em class="replaceable ">database-name</em></code> for each database.
  </p><p>
   The following snippet of the <code class="filename">kubecf-config-values.yaml</code>
   contains an example of an external database configuration.
  </p><div class="verbatim-wrap"><pre class="screen">features:
  embedded_database:
    enabled: false
  external_database:
    enabled: true
    require_ssl: false
    ca_cert: ~
    type: mysql
    host: <em class="replaceable ">hostname</em>
    port: <em class="replaceable ">3306</em>
    databases:
      uaa:
        name: uaa
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      cc:
        name: cloud_controller
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      bbs:
        name: diego
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      routing_api:
        name: routing-api
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      policy_server:
        name: network_policy
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      silk_controller:
        name: network_connectivity
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      locket: 
        name: locket
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      credhub:        
        name: credhub
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em></pre></div></div></div><div class="sect1 " id="sec-cap-addrepo-caasp"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add the Kubernetes Charts Repository</span> <a title="Permalink" class="permalink" href="#sec-cap-addrepo-caasp">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-addrepo-caasp</li></ul></div></div></div></div><p>
   Download the SUSE Kubernetes charts repository with Helm:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm repo add <em class="replaceable ">suse</em> https://kubernetes-charts.suse.com/</pre></div><p>
   You may replace the example <em class="replaceable ">suse</em> name with any
   name. Verify with <code class="command">helm</code>:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm repo list
NAME       URL
stable     https://kubernetes-charts.storage.googleapis.com
local      http://127.0.0.1:8879/charts
suse       https://kubernetes-charts.suse.com/</pre></div><p>
   List your chart names, as you will need these for some operations:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm search repo <em class="replaceable ">suse</em>
NAME                            CHART VERSION        APP VERSION    DESCRIPTION
suse/cf-operator                6.1.17+0.gec409fd7    2.1.0          A Helm chart for cf-operator, the k8s operator ....
suse/console                    4.2.0                2.1.0          A Helm chart for deploying SUSE Stratos Console
suse/kubecf                     2.5.8                2.1.0          A Helm chart for KubeCF
suse/metrics                    1.3.0                2.1.0          A Helm chart for Stratos Metrics
suse/minibroker                 1.1.0                               A minibroker for your minikube
suse/nginx-ingress              0.28.4               0.15.0         An nginx Ingress controller that uses ConfigMap to store ...
...</pre></div></div><div class="sect1 " id="sec-cap-cap-on-caasp"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#sec-cap-cap-on-caasp">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-cap-on-caasp</li></ul></div></div></div></div><div id="id-1.3.4.4.16.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: KubeCF and cf-operator versions</h6><p>
   KubeCF and cf-operator interoperate closely. Before you deploy a
   specific version combination, make sure they were confirmed to work. For more
   information see <a class="xref" href="#cha-cap-depl-notes-releases" title="3.4. Releases and Associated Versions">Section 3.4, “Releases and Associated Versions”</a>.
  </p></div><div class="sect2 " id="sec-cap-caasp-deploy-operator"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Deploy the Operator
 </span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-deploy-operator">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-deploy-operator</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    First, create the namespace for the operator.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">cf-operator</em></pre></div></li><li class="step "><p>
    Install the operator.
   </p><p>
    The value of <code class="literal">global.operator.watchNamespace</code> indicates the
    namespace the operator will monitor for a KubeCF deployment. This
    namespace should be separate from the namespace used by the operator. In
    this example, this means KubeCF will be deployed into a namespace called
    <code class="literal">kubecf</code>.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">cf-operator</em> suse/cf-operator \
--namespace <em class="replaceable ">cf-operator</em> \
--set "global.singleNamespace.name=<em class="replaceable ">kubecf</em>" \
--version 6.1.17+0.gec409fd7</pre></div></li><li class="step "><p>
    Wait until cf-operator is successfully deployed before proceeding. Monitor
    the status of your cf-operator deployment using the
    <code class="command">watch</code> command.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">cf-operator</em>'</pre></div></li></ol></div></div></div><div class="sect2 " id="sec-cap-caasp-deploy-kubecf"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy KubeCF</span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-deploy-kubecf">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-deploy-kubecf</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
   Use Helm to deploy KubeCF.
  </p><p>
   Note that you <span class="bold"><strong>do not</strong></span> need to manually create
   the namespace for KubeCF.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">kubecf</em> suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values <em class="replaceable ">kubecf-config-values.yaml</em> \
--version 2.5.8</pre></div></li><li class="step "><p>
  Monitor the status of your KubeCF deployment using the
  <code class="command">watch</code> command.
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace kubecf'</pre></div></li><li class="step "><p>
   Find the value of <code class="literal">EXTERNAL-IP</code> for each of the public
   services.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> router-public

<code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> tcp-router-public

<code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> ssh-proxy-public</pre></div></li><li class="step "><p>
      Create DNS A records for the public services.
     </p><ol type="a" class="substeps "><li class="step "><p>
    For the <code class="literal">router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">*.&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">tcp-router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">tcp.&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">ssh-proxy-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">ssh.&lt;system_domain&gt;</code>.
   </p></li></ol></li><li class="step "><p>
      When all pods are fully ready, verify your deployment. See <a class="xref" href="#sec-pod-status" title="3.2. Status of Pods during Deployment">Section 3.2, “Status of Pods during Deployment”</a> for more information.
     </p><p>
  Connect and authenticate to the cluster.
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation "https://api.&lt;system_domain&gt;"

# Use the cf_admin_password set in kubecf-config-values.yaml
<code class="prompt user">tux &gt; </code>cf auth admin <em class="replaceable ">changeme</em></pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-caasp-ldap"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  LDAP Integration
 </span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-ldap">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-ldap</li></ul></div></div></div></div><p>
  SUSE Cloud Application Platform can be integrated with
  <a class="link" href="https://docs.cloudfoundry.org/uaa/identity-providers.html" target="_blank">identity
  providers</a> to help manage authentication of users. Integrating
  SUSE Cloud Application Platform with other identity providers is optional. In a default
  deployment, a built-in UAA server (<a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-overview.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-overview.html</a>)
  is used to manage user accounts and authentication.
 </p><p>
  The Lightweight Directory Access Protocol (LDAP) is an example of an identity provider that
  Cloud Application Platform integrates with. This section describes the necessary components and
  steps in order to configure the integration. See
  <a class="link" href="https://github.com/cloudfoundry/uaa/blob/master/docs/UAA-LDAP.md" target="_blank">User
  Account and Authentication LDAP Integration</a> for more information. 
 </p><div class="sect2 " id="id-1.3.4.4.17.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.17.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The following prerequisites are required in order to complete an LDAP
   integration with SUSE Cloud Application Platform.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">uaac</code>, the Cloud Foundry <code class="literal">uaa</code> command line client
 (UAAC). See
 <a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-user-management.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-user-management.html</a>
 for more information and installation instructions.
</p><p>
 On SUSE Linux Enterprise systems, ensure the <code class="literal">ruby-devel</code> and <code class="literal">gcc-c++</code>
 packages have been installed before installing the <code class="literal">cf-uaac</code> gem.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install ruby-devel gcc-c++</pre></div></li><li class="listitem "><p>
     An LDAP server and the credentials for a user/service account with
     permissions to search the directory.
    </p></li></ul></div></div><div class="sect2 " id="id-1.3.4.4.17.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.14.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example LDAP Integration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.4.17.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Run the following commands to complete the integration of your Cloud Application Platform
   deployment and LDAP server.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
 Use UAAC to target your <code class="literal">uaa</code> server.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac target --skip-ssl-validation <em class="replaceable ">https://uaa.example.com</em></pre></div></li><li class="step "><p>
 Authenticate to the <code class="literal">uaa</code> server as
 <code class="literal">admin</code> using the
 <code class="literal">uaa_admin_client_secret</code> set in your
 <code class="filename">kubecf-config-values.yaml</code> file.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac token client get admin --secret <em class="replaceable ">PASSWORD</em></pre></div></li><li class="step "><p>
     List the current identity providers.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers --insecure</pre></div></li><li class="step "><p>
     From the output, locate the default <code class="literal">ldap</code> entry and take
     note of its <code class="literal">id</code>. The entry will be similar to the
     following.
    </p><div class="verbatim-wrap"><pre class="screen">{
  "type": "ldap",
  "config": "{\"emailDomain\":null,\"additionalConfiguration\":null,\"providerDescription\":null,\"externalGroupsWhitelist\":[],\"attributeMappings\":{},\"addShadowUserOnLogin\":true,\"storeCustomAttributes\":true,\"ldapProfileFile\":\"ldap/ldap-search-and-bind.xml\",\"baseUrl\":\"ldap://localhost:389/\",\"referral\":null,\"skipSSLVerification\":false,\"userDNPattern\":null,\"userDNPatternDelimiter\":null,\"bindUserDn\":\"cn=admin,dc=test,dc=com\",\"userSearchBase\":\"dc=test,dc=com\",\"userSearchFilter\":\"cn={0}\",\"passwordAttributeName\":null,\"passwordEncoder\":null,\"localPasswordCompare\":null,\"mailAttributeName\":\"mail\",\"mailSubstitute\":null,\"mailSubstituteOverridesLdap\":false,\"ldapGroupFile\":null,\"groupSearchBase\":null,\"groupSearchFilter\":null,\"groupsIgnorePartialResults\":null,\"autoAddGroups\":true,\"groupSearchSubTree\":true,\"maxGroupSearchDepth\":10,\"groupRoleAttribute\":null,\"tlsConfiguration\":\"none\"}",
  "id": "53gc6671-2996-407k-b085-2346e216a1p0",
  "originKey": "ldap",
  "name": "UAA LDAP Provider",
  "version": 3,
  "created": 946684800000,
  "last_modified": 1602208214000,
  "active": false,
  "identityZoneId": "uaa"
},</pre></div></li><li class="step "><p>
     Delete the default <code class="literal">ldap</code> identity provider. If the
     default entry is not removed, adding another identity provider of type
     <code class="literal">ldap</code> will result in a <code class="literal">409 Conflict</code>
     response. Replace the example <code class="literal">id</code> with one found in the
     previous step.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers/<em class="replaceable ">53gc6671-2996-407k-b085-2346e216a1p0</em> \
    --request DELETE \
    --insecure</pre></div></li><li class="step "><p>
     Create your own LDAP identity provider. A <code class="literal">201 Created</code>
     response will be returned when the identity provider is successfully
     created. See the
     <a class="link" href="http://docs.cloudfoundry.org/api/uaa/version/4.21.0/index.html#ldap" target="_blank">UAA
     API Reference</a> and
     <a class="link" href="https://github.com/cloudfoundry/uaa/blob/4.21.0/docs/UAA-LDAP.md" target="_blank">Cloud Foundry
     UAA-LDAP Documentation</a>for information regarding the request
     parameters and additional options available to configure your identity
     provider.
    </p><p>
     The following is an example of a <code class="literal">uaac curl</code> command and
     its request parameters used to create an identity provider. Specify the
     parameters according to your LDAP server's credentials and directory
     structure. Ensure the user specifed in the <code class="literal">bindUserDn</code>
     has permissions to search the directory.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers?rawConfig=true \
    --request POST \
    --insecure \
    --header 'Content-Type: application/json' \
    --data '{
  "type" : "ldap",
  "config" : {
    "ldapProfileFile" : "ldap/ldap-search-and-bind.xml",
    "baseUrl" : "<em class="replaceable ">ldap://ldap.example.com:389</em>",
    "bindUserDn" : "<em class="replaceable ">cn=admin,dc=example,dc=com</em>",
    "bindPassword" : "<em class="replaceable ">password</em>",
    "userSearchBase" : "<em class="replaceable ">dc=example,dc=com</em>",
    "userSearchFilter" : "<em class="replaceable ">uid</em>={0}",
    "ldapGroupFile" : "ldap/ldap-groups-map-to-scopes.xml",
    "groupSearchBase" : "<em class="replaceable ">dc=example,dc=com</em>",
    "groupSearchFilter" : "<em class="replaceable ">member</em>={0}"
  },
  "originKey" : "ldap",
  "name" : "<em class="replaceable ">My LDAP Server</em>",
  "active" : true
  }'</pre></div></li><li class="step "><p>
     Verify the LDAP identify provider has been created. The output should now
     contain an entry for the <code class="literal">ldap</code> type you created.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers --insecure</pre></div></li><li class="step "><p>
     Use the cf CLI to target your SUSE Cloud Application Platform deployment.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation https://api.example.com</pre></div></li><li class="step "><p>
     Log in as an administrator.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login
API endpoint: https://api.example.com

Email&gt; admin

Password&gt;
Authenticating...
OK</pre></div></li><li class="step "><p>
     Create users associated with your LDAP identity provider.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-user <em class="replaceable ">username</em> --origin ldap
Creating user username...
OK

TIP: Assign roles with 'cf set-org-role' and 'cf set-space-role'.</pre></div></li><li class="step "><p>
     Assign the user a role. Roles define the permissions a user has for a
     given org or space and a user can be assigned multiple roles. See
     <a class="link" href="https://docs.cloudfoundry.org/concepts/roles.html" target="_blank">Orgs,
     Spaces, Roles, and Permissions</a> for available roles and their
     corresponding permissions. The following example assumes that an org named
     <em class="replaceable ">Org</em> and a space named
     <em class="replaceable ">Space</em> have already been created.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf set-space-role <em class="replaceable ">username</em> <em class="replaceable ">Org</em> <em class="replaceable ">Space</em> <em class="replaceable ">SpaceDeveloper</em>
Assigning role RoleSpaceDeveloper to user username in org Org / space Space as admin...
OK
<code class="prompt user">tux &gt; </code>cf set-org-role <em class="replaceable ">username</em> Org OrgManager
Assigning role OrgManager to user username in org Org as admin...
OK</pre></div></li><li class="step "><p>
     Verify the user can log into your SUSE Cloud Application Platform deployment using their
     associated LDAP server credentials.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login
API endpoint: https://api.example.com

Email&gt; username

Password&gt;
Authenticating...
OK



API endpoint:   https://api.example.com (API version: 2.115.0)
User:           username@ldap.example.com</pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-caasp-add-capacity"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Expanding Capacity of a Cloud Application Platform Deployment on SUSE® CaaS Platform</span> <a title="Permalink" class="permalink" href="#sec-cap-caasp-add-capacity">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_caasp.xml</li><li><span class="ds-label">ID: </span>sec-cap-caasp-add-capacity</li></ul></div></div></div></div><p>
   If the current capacity of your Cloud Application Platform deployment is insufficient for your
   workloads, you can expand the capacity using the procedure in this section.
  </p><p>
   These instructions assume you have followed the procedure in
   <a class="xref" href="#cha-cap-depl-caasp" title="Chapter 4. Deploying SUSE Cloud Application Platform on SUSE CaaS Platform">Chapter 4, <em>Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</em></a> and have a running Cloud Application Platform
   deployment on SUSE® CaaS Platform.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Add additional nodes to your SUSE® CaaS Platform cluster as described in
     <a class="link" href="https://documentation.suse.com/suse-caasp/4.5/html/caasp-admin/#adding_nodes" target="_blank">https://documentation.suse.com/suse-caasp/4.5/html/caasp-admin/#adding_nodes</a>.
    </p></li><li class="step "><p>
     Verify the new nodes are in a <code class="literal">Ready</code> state before proceeding.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get nodes</pre></div></li><li class="step "><p>
     Add or update the following in your
     <code class="filename">kubecf-config-values.yaml</code> file to increase the number of
     <code class="literal">diego-cell</code> in your Cloud Application Platform deployment. Replace the
     example value with the number required by your workflow.
    </p><div class="verbatim-wrap"><pre class="screen">sizing:
  diego_cell:
    instances: <em class="replaceable ">5</em></pre></div></li><li class="step "><p>
     Perform a <code class="command">helm upgrade</code> to apply the change.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade kubecf suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values kubecf-config-values.yaml \
--version 2.5.8</pre></div></li><li class="step "><p>
     Monitor progress of the additional <code class="literal">diego-cell</code> pods:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace kubecf'</pre></div></li></ol></div></div></div></div><div class="chapter " id="cha-cap-depl-aks"><div class="titlepage"><div><div><h2 class="title"><span class="number">5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-aks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-prereqs-aks"><span class="number">5.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-aks-instance"><span class="number">5.2 </span><span class="name">Create Resource Group and AKS Instance</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.5.7"><span class="number">5.3 </span><span class="name">Install the Helm Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-storage"><span class="number">5.4 </span><span class="name">
  Storage Class
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-config"><span class="number">5.5 </span><span class="name">Deployment Configuration</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-certificates"><span class="number">5.6 </span><span class="name">
  Certificates
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-ingress"><span class="number">5.7 </span><span class="name">
  Using an Ingress Controller
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-affinity"><span class="number">5.8 </span><span class="name">
  Affinity and Anti-affinity
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-high-availability"><span class="number">5.9 </span><span class="name">
  High Availability
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-external-blobstore"><span class="number">5.10 </span><span class="name">
  External Blobstore
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-external-database"><span class="number">5.11 </span><span class="name">
  External Database
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-addrepo-aks"><span class="number">5.12 </span><span class="name">Add the Kubernetes Charts Repository</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-cap-on-aks"><span class="number">5.13 </span><span class="name">Deploying SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-ldap"><span class="number">5.14 </span><span class="name">
  LDAP Integration
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-aks-add-capacity"><span class="number">5.15 </span><span class="name">Expanding Capacity of a Cloud Application Platform Deployment on Microsoft AKS</span></a></span></dt></dl></div></div><div id="id-1.3.4.5.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        <a class="link" href="https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2.0/" target="_blank">
        SUSE Cloud Application Platform Release Notes</a>
      </p></li><li class="listitem "><p>
        <a class="xref" href="#cha-cap-depl-notes" title="Chapter 3. Deployment and Administration Notes">Chapter 3, <em>Deployment and Administration Notes</em></a>
      </p></li></ul></div></div><p>
  SUSE Cloud Application Platform supports deployment on Microsoft Azure Kubernetes Service
  (AKS), Microsoft's managed Kubernetes service. This chapter describes the steps
  for preparing Azure for a SUSE Cloud Application Platform deployment, deployed with the default
  Azure Standard SKU load balancer (see
  <a class="link" href="https://docs.microsoft.com/en-us/azure/aks/load-balancer-standard" target="_blank">https://docs.microsoft.com/en-us/azure/aks/load-balancer-standard</a>).
 </p><p>
  In Kubernetes terminology a node used to be a minion, which was the name for a
  worker node. Now the correct term is simply node (see
  <a class="link" href="https://kubernetes.io/docs/concepts/architecture/nodes/" target="_blank">https://kubernetes.io/docs/concepts/architecture/nodes/</a>).
  This can be confusing, as computing nodes have traditionally been defined as
  any device in a network that has an IP address. In Azure they are called
  agent nodes. In this chapter we call them agent nodes or Kubernetes nodes.
 </p><div class="sect1 " id="sec-cap-prereqs-aks"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#sec-cap-prereqs-aks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-prereqs-aks</li></ul></div></div></div></div><p>
   The following are required to deploy and use SUSE Cloud Application Platform on AKS:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     <code class="command">az</code>, the Azure command line client. See
     <a class="link" href="https://docs.microsoft.com/en-us/cli/azure/?view=azure-cli-latest" target="_blank">https://docs.microsoft.com/en-us/cli/azure/?view=azure-cli-latest</a>
     for more information and installation instructions.
    </p></li><li class="listitem "><p>
     A Microsoft Azure account. For details, refer to
     <a class="link" href="https://azure.microsoft.com" target="_blank">https://azure.microsoft.com</a>.
    </p></li><li class="listitem "><p>
     Your Azure account as sufficient quota. The minimal installation described
     in this chapter require 24 vCPUs. If your account has insufficient quota,
     you can request a quota increase by going to
     <a class="link" href="https://docs.microsoft.com/en-us/azure/azure-supportability/resource-manager-core-quotas-request" target="_blank">https://docs.microsoft.com/en-us/azure/azure-supportability/resource-manager-core-quotas-request</a>.
    </p></li><li class="listitem "><p>
     A SSH key that can be used for access to the nodes of the cluster. 
    </p></li><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">kubectl</code>, the Kubernetes command line tool. For more
 information, refer to
 <a class="link" href="https://kubernetes.io/docs/reference/kubectl/overview/" target="_blank">https://kubernetes.io/docs/reference/kubectl/overview/</a>.
</p><p>
 For SLE 12 SP3 or 15 SP1 systems, install the package
 <span class="package ">kubernetes-client</span> from the <span class="emphasis"><em>Public Cloud</em></span>
 module.
</p><p>
 For other systems, follow the instructions at
 <a class="link" href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a>.
</p></li><li class="listitem "><p>
 <code class="command">jq</code>, a command line JSON processor. See
 <a class="link" href="https://stedolan.github.io/jq/" target="_blank">https://stedolan.github.io/jq/</a> for more information and
 installation instructions.
</p></li><li class="listitem "><p>
 <code class="command">curl</code>, the Client URL (cURL) command line tool.
</p></li><li class="listitem "><p>
 <code class="command">sed</code>, the stream editor.
</p></li></ul></div></div><div class="sect1 " id="sec-cap-create-aks-instance"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create Resource Group and AKS Instance</span> <a title="Permalink" class="permalink" href="#sec-cap-create-aks-instance">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-create-aks-instance</li></ul></div></div></div></div><p>
   Log in to your Azure account, which should have the
   <code class="literal">Contributor</code> role.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>az login</pre></div><p>
   You can set up an AKS cluster with an automatically generated service
   principal. Note that to be be able to create a service principal your user
   account must have permissions to register an application with your Azure
   Active Directory tenant, and to assign the application to a role in your
   subscription. For details, see <a class="link" href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#automatically-create-and-use-a-service-principal" target="_blank">https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#automatically-create-and-use-a-service-principal</a>.
  </p><p>
   Alternatively, you can specify an existing service principal but the service
   principal must have sufficient rights to be able to create resources at the
   appropriate level, for example resource group, subscription etc. For more
   details please see:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      Create a service principal: <a class="link" href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#manually-create-a-service-principal" target="_blank">https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#manually-create-a-service-principal</a>
    </p></li><li class="listitem "><p>
     Create a role assignment for the service principal, at the subscription or
     resource group level: <a class="link" href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#delegate-access-to-other-azure-resources" target="_blank">https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#delegate-access-to-other-azure-resources</a>
    </p></li><li class="listitem "><p>
     Create the cluster with the service principal: <a class="link" href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#specify-a-service-principal-for-an-aks-cluster" target="_blank">https://docs.microsoft.com/en-us/azure/aks/kubernetes-service-principal#specify-a-service-principal-for-an-aks-cluster</a>
    </p></li></ul></div><p>
   Specify the following additional parameters for creating the cluster: node
   count, a username for SSH access to the nodes, SSH key, VM type, VM disk size
   and optionally, the Kubernetes version and a nodepool name.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>az aks create --resource-group <em class="replaceable ">my-resource-group</em> --name <em class="replaceable ">cap-aks</em> \
 --node-count <em class="replaceable ">3</em> --admin-username <em class="replaceable ">cap-user</em> \
 --ssh-key-value <em class="replaceable ">/path/to/some_key.pub</em> --node-vm-size <em class="replaceable ">Standard_DS4_v2</em> \
 --node-osdisk-size <em class="replaceable ">100</em> --nodepool-name <em class="replaceable ">mypool</em></pre></div><p>
   For more <code class="command">az aks create</code> options see
   <a class="link" href="https://docs.microsoft.com/en-us/cli/azure/aks?view=azure-cli-latest#az-aks-create" target="_blank">https://docs.microsoft.com/en-us/cli/azure/aks?view=azure-cli-latest#az-aks-create</a>.
  </p><p>
   This takes a few minutes. When it is completed, fetch your
   <code class="command">kubectl</code> credentials. The default behavior for <code class="command">az
   aks get-credentials</code> is to merge the new credentials with the
   existing default configuration, and to set the new credentials as as the
   current Kubernetes context. The context name is your AKS_NAME value. You should
   first backup your current configuration, or move it to a different location,
   then fetch the new credentials:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>az aks get-credentials --resource-group $RG_NAME --name $AKS_NAME
 Merged "cap-aks" as current context in /home/tux/.kube/config</pre></div><p>
   Verify that you can connect to your cluster:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get nodes</pre></div><p>
   When all nodes are in a ready state and all pods are running, proceed to the
   next steps.
  </p></div><div class="sect1 " id="id-1.3.4.5.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the Helm Client</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Helm is a Kubernetes package manager used to install and manage SUSE Cloud Application Platform.
   This requires installing the Helm client, <code class="command">helm</code>, on your
   remote management workstation. Cloud Application Platform requires Helm 3.
   For more information regarding Helm, refer to the documentation at
   <a class="link" href="https://helm.sh/docs/" target="_blank">https://helm.sh/docs/</a>.
  </p><div id="id-1.3.4.5.7.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Make sure that you are installing and using Helm 3 and not Helm 2.</p></div><p>
   If your remote management workstation has the SUSE CaaS Platform package repository,
   install <code class="command">helm</code> by running
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install helm3
<code class="prompt user">tux &gt; </code>sudo update-alternatives --set helm /usr/bin/helm3</pre></div><p>
   Otherwise, <code class="command">helm</code> can be installed  by referring to the
   documentation at <a class="link" href="https://helm.sh/docs/intro/install/" target="_blank">https://helm.sh/docs/intro/install/</a>.
  </p></div><div class="sect1 " id="sec-cap-aks-storage"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Storage Class
 </span> <a title="Permalink" class="permalink" href="#sec-cap-aks-storage">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-storage</li></ul></div></div></div></div><p>
  In some SUSE Cloud Application Platform instance groups, such as <code class="literal">bits</code>,
  <code class="literal">database</code>, <code class="literal">diego-cell</code>, and
  <code class="literal">singleton-blobstore</code> require a storage class for persistent
  data. To learn more about storage classes, see
  <a class="link" href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank">https://kubernetes.io/docs/concepts/storage/storage-classes/</a>. 
 </p><p>
  By default, SUSE Cloud Application Platform will use the cluster's default storage class. 
  To designate or change the default storage class, refer to
  <a class="link" href="https://kubernetes.io/docs/tasks/administer-cluster/change-default-storage-class/" target="_blank">https://kubernetes.io/docs/tasks/administer-cluster/change-default-storage-class/</a>
  for instructions.
 </p><p>
  In some cases, the default and predefined storage classes may not be suitable
  for certain workloads. If this is the case, operators can define their own
  custom StorageClass resource according to the specification at 
  <a class="link" href="https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource" target="_blank">https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource</a>.
 </p><p>
  With the storage class defined, run:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create --filename <em class="replaceable ">my-storage-class.yaml</em></pre></div><p>
  Then verify the storage class is available by running
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get storageclass</pre></div><p>
  If operators do no want to use the default storage class or one does not
  exist, a storage class <span class="bold"><strong>must</strong></span> be specified by
  setting the <code class="literal">kube.storage_class</code> value in your
  <code class="filename">kubecf-config-values.yaml</code> configuration file to the name of the storage class as seen
  in this example. 
 </p><div class="verbatim-wrap"><pre class="screen">kube:
  storage_class: <em class="replaceable ">my-storage-class</em></pre></div></div><div class="sect1 " id="sec-cap-aks-config"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment Configuration</span> <a title="Permalink" class="permalink" href="#sec-cap-aks-config">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-config</li></ul></div></div></div></div><p>
   The following file, <code class="filename">kubecf-config-values.yaml</code>, provides a
   minimal example deployment configuration.
  </p><div id="id-1.3.4.5.9.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: kubecf-config-values.yaml changes</h6><p>
    The format of the <code class="filename">kubecf-config-values.yaml</code> file has been restructured completely in
    Cloud Application Platform 2.x. Do not re-use the Cloud Application Platform 1.x version of the file. Instead, see the
    default file in the appendix in
    <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a> and pick parameters according to
    your needs.
  </p></div><div id="id-1.3.4.5.9.4" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: Supported Domains</h6><p>
   When selecting a domain, SUSE Cloud Application Platform expects <code class="literal">system_domain</code> to
   be either a subdomain or a root domain. Setting <code class="literal">system_domain</code> to
   a top-level domain, such as <code class="literal">suse</code>, is not supported.
  </p></div><div class="verbatim-wrap"><pre class="screen">### Example deployment configuration file
### kubecf-config-values.yaml

system_domain: example.com

credentials:
  cf_admin_password: <em class="replaceable ">changeme</em>
  uaa_admin_client_secret: <em class="replaceable ">alsochangeme</em>

### This block is required due to the log-cache issue described below
properties:
  log-cache:
    log-cache:
      memory_limit_percent: 3

### This block is required due to the log-cache issue described below
###
### The value for <code class="literal">key</code> may need to be replaced depending on
### how notes in your cluster are labeled
###
### The value(s) listed under <code class="literal">values</code> may need to be
### replaced depending on how notes in your cluster are labeled
operations:
  inline:
  - type: replace
    path: /instance_groups/name=log-cache/env?/bosh/agent/settings/affinity
    value:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: <em class="replaceable ">kubernetes.io/hostname</em>
              operator: In
              values:
              - <em class="replaceable ">LABEL_VALUE_OF_NODE</em></pre></div><div class="sect2 " id="id-1.3.4.5.9.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Log-cache Memory Allocation</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.9.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  The log-cache component currently has a memory allocation issue where the node
  memory available is reported instead of the one assigned to the container under
  cgroups. In such a situation, log-cache would start allocating memory based on
  these values, causing a varying range of issues (OOMKills, performance
  degradation, etc.). To address this issue, node affinity must be used to tie
  log-cache to nodes of a uniform size, and then declaring the cache percentage
  based on that number. A limit of 3% has been identified as sufficient.
 </p><p>
  In the node affinity configuration, the values for <code class="literal">key</code> and
  <code class="literal">values</code> may need to be changed depending on how notes in your
  cluster are labeled. For more information on labels, see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels</a>.
 </p></div><div class="sect2 " id="id-1.3.4.5.9.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Diego Cell Affinities and Tainted Nodes</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.9.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  Note that the <code class="literal">diego-cell</code> pods used by the Diego standard
  scheduler are
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    privileged
   </p></li><li class="listitem "><p>
    use large local emptyDir volumes (i.e. require node disk storage)
   </p></li><li class="listitem "><p>
    and set kernel parameters on the node
   </p></li></ul></div><p>
  These things all mean that these pods should not live next to other Kubernetes
  workloads. They should all be placed on their own
  <span class="bold"><strong>dedicated nodes</strong></span> instead where possible.
 </p><p>
  This can be done by setting affinities and tolerations, as explained in
the associated tutorial at <a class="link" href="https://kubecf.io/docs/deployment/affinities-and-tolerations/" target="_blank">https://kubecf.io/docs/deployment/affinities-and-tolerations/</a>.
 </p></div></div><div class="sect1 " id="sec-cap-aks-certificates"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Certificates
 </span> <a title="Permalink" class="permalink" href="#sec-cap-aks-certificates">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-certificates</li></ul></div></div></div></div><p>
  This section describes the process to secure traffic passing through your
  SUSE Cloud Application Platform deployment. This is achieved by using certificates to set up
  Transport Layer Security (TLS) for the router component. Providing
  certificates for the router traffic is optional. In a default deployment,
  without operator-provided certificates, generated certificates will be used.
 </p><div class="sect2 " id="id-1.3.4.5.10.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Certificate Characteristics</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.10.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Ensure the certificates you use have the following characteristics:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The certificate is encoded in the PEM format.
    </p></li><li class="listitem "><p>
     The certificate is signed by an external Certificate Authority (CA).
    </p></li><li class="listitem "><p>
     The certificate's Subject Alternative Names (SAN) include the domain
     <em class="replaceable ">*.example.com</em>, where <em class="replaceable ">example.com</em>
     is replaced with the <code class="literal">system_domain</code> in your
     <code class="filename">kubecf-config-values.yaml</code>.
    </p></li></ul></div></div><div class="sect2 " id="id-1.3.4.5.10.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.10.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The certificate used to secure your deployment is passed through the
   <code class="filename">kubecf-config-values.yaml</code> configuration file. To specify
   a certificate, set the value of the certificate and its corresponding private
   key using the <code class="literal">router.tls.crt</code> and
   <code class="literal">router.tls.key</code> Helm values in the
   <code class="literal">settings:</code> section.
  </p><div class="verbatim-wrap"><pre class="screen">settings:
  router:
    tls:
      crt: |
        -----BEGIN CERTIFICATE-----
        MIIEEjCCAfoCCQCWC4NErLzy3jANBgkqhkiG9w0BAQsFADBGMQswCQYDVQQGEwJD
        QTETMBEGA1UECAwKU29tZS1TdGF0ZTEOMAwGA1UECgwFTXlPcmcxEjAQBgNVBAMM
        CU15Q0Euc2l0ZTAeFw0xODA5MDYxNzA1MTRaFw0yMDAxMTkxNzA1MTRaMFAxCzAJ
        ...
        xtNNDwl2rnA+U0Q48uZIPSy6UzSmiNaP3PDR+cOak/mV8s1/7oUXM5ivqkz8pEJo
        M3KrIxZ7+MbdTvDOh8lQplvFTeGgjmUDd587Gs4JsormqOsGwKd1BLzQbGELryV9
        1usMOVbUuL8mSKVvgqhbz7vJlW1+zwmrpMV3qgTMoHoJWGx2n5g=
        -----END CERTIFICATE-----
      key: |
        -----BEGIN RSA PRIVATE KEY-----
        MIIEpAIBAAKCAQEAm4JMchGSqbZuqc4LdryJpX2HnarWPOW0hUkm60DL53f6ehPK
        T5Dtb2s+CoDX9A0iTjGZWRD7WwjpiiuXUcyszm8y9bJjP3sIcTnHWSgL/6Bb3KN5
        G5D8GHz7eMYkZBviFvygCqEs1hmfGCVNtgiTbAwgBTNsrmyx2NygnF5uy4KlkgwI
        ...
        GORpbQKBgQDB1/nLPjKxBqJmZ/JymBl6iBnhIgVkuUMuvmqES2nqqMI+r60EAKpX
        M5CD+pq71TuBtbo9hbjy5Buh0+QSIbJaNIOdJxU7idEf200+4anzdaipyCWXdZU+
        MPdJf40awgSWpGdiSv6hoj0AOm+lf4AsH6yAqw/eIHXNzhWLRvnqgA==
        -----END RSA PRIVATE KEY----</pre></div></div></div><div class="sect1 " id="sec-cap-aks-ingress"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Using an Ingress Controller
 </span> <a title="Permalink" class="permalink" href="#sec-cap-aks-ingress">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-ingress</li></ul></div></div></div></div><p>
  This section describes how to use an ingress controller
  (see <a class="link" href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank">https://kubernetes.io/docs/concepts/services-networking/ingress/</a>)
  to manage access to the services in the cluster. Using an ingress controller
  is optional. In a default deployment, load balancers are used instead.
 </p><p>
  Note that only the NGINX Ingress Controller has been verified to be
  compatible with Cloud Application Platform. Other Ingress controller alternatives may work, but
  compatibility with Cloud Application Platform is not supported.
 </p><div class="sect2 " id="id-1.3.4.5.11.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install and Configure the NGINX Ingress Controller</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.11.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Create a configuration file with the section below. The file is called
     <code class="filename">nginx-ingress.yaml</code> in this example. When using
     Eirini instead of Diego, replace the first line with
     <code class="literal">2222: "kubecf/eirinix-ssh-proxy:2222"</code>.
    </p><div class="verbatim-wrap"><pre class="screen">tcp:
  2222: "kubecf/scheduler:2222"
  20000: "kubecf/tcp-router:20000"
  20001: "kubecf/tcp-router:20001"
  20002: "kubecf/tcp-router:20002"
  20003: "kubecf/tcp-router:20003"
  20004: "kubecf/tcp-router:20004"
  20005: "kubecf/tcp-router:20005"
  20006: "kubecf/tcp-router:20006"
  20007: "kubecf/tcp-router:20007"
  20008: "kubecf/tcp-router:20008"</pre></div></li><li class="step "><p>
     Create the namespace.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">nginx-ingress</em></pre></div></li><li class="step "><p>
     Install the NGINX Ingress Controller.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">nginx-ingress</em> suse/nginx-ingress \
--namespace <em class="replaceable ">nginx-ingress</em> \
--values <em class="replaceable ">nginx-ingress.yaml</em></pre></div></li><li class="step "><p>
     Monitor the progess of the deployment:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">nginx-ingress</em>'</pre></div></li><li class="step "><p>
     After the deployment completes, the Ingress controller service will be deployed
     with either an external IP or a hostname. 
    </p><p>
     Find the external IP or hostname.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get services nginx-ingress-controller --namespace nginx-ingress</pre></div><p>
     You will get output similar to the following.
    </p><div class="verbatim-wrap"><pre class="screen">NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)
nginx-ingress-controller   LoadBalancer   <em class="replaceable ">10.63.248.70</em>   <em class="replaceable ">35.233.191.177</em>   80:30344/TCP,443:31386/TCP</pre></div></li><li class="step "><p>
     Set up DNS records corresponding to the controller service IP or hostname
     and map it to the <code class="literal">system_domain</code> defined in your
     <code class="filename">kubecf-config-values.yaml</code>.
    </p></li><li class="step "><p>
     Obtain a PEM formatted certificate that is associated with the
     <code class="literal">system_domain</code> defined in your <code class="filename">kubecf-config-values.yaml</code>
    </p></li><li class="step "><p>
     In your <code class="filename">kubecf-config-values.yaml</code> configuration file, enable the ingress feature and
     set the <code class="literal">tls.crt</code> and <code class="literal">tls.key</code> for the
     certificate from the previous step.
    </p><div class="verbatim-wrap"><pre class="screen">features:
  ingress:
    enabled: true
    tls:
      crt: |
        -----BEGIN CERTIFICATE-----
        MIIE8jCCAtqgAwIBAgIUT/Yu/Sv8AUl5zHXXEKCy5RKJqmYwDQYJKoZIhvcMOQMM
        [...]
        xC8x/+zB7XlvcRJRio6kk670+25ABP==
        -----END CERTIFICATE-----
      key: |
        -----BEGIN RSA PRIVATE KEY-----
        MIIE8jCCAtqgAwIBAgIUSI02lj2b2ImLy/zMrjNgW5d8EygwQSVJKoZIhvcYEGAW
        [...]
        to2WV7rPMb9W9fd2vVUXKKHTc+PiNg==
        -----END RSA PRIVATE KEY-----</pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-aks-affinity"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Affinity and Anti-affinity
 </span> <a title="Permalink" class="permalink" href="#sec-cap-aks-affinity">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-affinity</li></ul></div></div></div></div><div id="id-1.3.4.5.12.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
   This feature requires SUSE Cloud Application Platform 2.0.1 or newer.
  </p></div><p>
  Operators can set affinity/anti-affinity rules to restrict how the scheduler
  determines the placement of a given pod on a given node. This can be
  achieved through node affinity/anti-affinity, where placement is determined
  by node labels (see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity</a>),
  or pod affinity/anti-affinity, where pod placement is determined by labels
  on pods that are already running on the node (see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity</a>). 
 </p><p>
  In SUSE Cloud Application Platform, a default configuration will have following
  affinity/anti-affinity rules already in place:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Instance groups have anti-affinity against themselves. This applies to all
    instance groups, including <code class="literal">database</code>, but not to the
    <code class="literal">bits</code>, <code class="literal">eirini</code>, and
    <code class="literal">eirini-extensions</code> subcharts.
   </p></li><li class="listitem "><p>
    The <code class="literal">diego-cell</code> and <code class="literal">router</code> instance
    groups have anti-affinity against each other.
   </p></li></ul></div><p>
  Note that to ensure an optimal spread of the pods across worker nodes we
  recommend running 5 or more worker nodes to satisfy both of the default
  anti-affinity constraints. An operator can also specify custom affinity rules
  via the
  <code class="literal">sizing.<em class="replaceable ">instance-group</em>.affinity</code>
  helm parameter and any affinity rules specified here will overwrite the
  default rule, not merge with it.
 </p><div class="sect2 " id="id-1.3.4.5.12.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring Rules</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.12.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   To add or override affinity/anti-affinity settings, add a
   <code class="literal">sizing.INSTANCE_GROUP.affinity</code> block to your
   <code class="filename">kubecf-config-values.yaml</code>. Repeat as necessary for each instance group where
   affinity/anti-affinity settings need to be applied. For information on
   the available fields and valid values within the <code class="literal">affinity:</code>
   block, see
   <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity</a>.
   Repeat as necessary for each instance group where affinity/anti-affinity
   settings need to be applied.
  </p><p>
   Example 1, node affinity.
  </p><p>
   Using this configuration, the Kubernetes scheduler would place both the
   <code class="literal">asactors</code> and <code class="literal">asapi</code> instance groups on a
   node with a label where the key is
   <code class="literal">topology.kubernetes.io/zone</code> and the value is
   <code class="literal">0</code>.
  </p><div class="verbatim-wrap"><pre class="screen">sizing:
   asactors:
     affinity:
       nodeAffinity:
         requiredDuringSchedulingIgnoredDuringExecution:
           nodeSelectorTerms:
           - matchExpressions:
             - key: topology.kubernetes.io/zone
               operator: In
               values:
               - 0
   asapi:
     affinity:
       nodeAffinity:
         requiredDuringSchedulingIgnoredDuringExecution:
           nodeSelectorTerms:
           - matchExpressions:
             - key: topology.kubernetes.io/zone
               operator: In
               values:
               - 0</pre></div><p>
   Example 2, pod anti-affinity.
  </p><div class="verbatim-wrap"><pre class="screen">sizing:
  api:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: quarks.cloudfoundry.org/quarks-statefulset-name
                operator: In
                values:
                - sample_group
            topologyKey: kubernetes.io/hostname
  database:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: quarks.cloudfoundry.org/quarks-statefulset-name
                operator: In
                values:
                - sample_group
            topologyKey: kubernetes.io/hostname</pre></div><p>
   Example 1 above uses <code class="literal">topology.kubernetes.io/zone</code> as its
   label, which is one of the standard labels that get attached to nodes by
   default. The list of standard labels can be found at
   <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels</a>. 
  </p><p>
   In addition to the standard labels, custom labels can be specified as in
   Example 2. To use custom labels, following the process described in this
   section <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector</a>.
  </p></div></div><div class="sect1 " id="sec-cap-aks-high-availability"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  High Availability
 </span> <a title="Permalink" class="permalink" href="#sec-cap-aks-high-availability">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-high-availability</li></ul></div></div></div></div><div class="sect2 " id="id-1.3.4.5.13.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring Cloud Application Platform for High Availability</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.13.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   High availability mode is optional. In a default deployment, SUSE Cloud Application Platform is
   deployed in single availability mode.
  </p><p>
   There are two ways to make your SUSE Cloud Application Platform deployment highly available.
   The first method is to set the <code class="literal">high_availability</code> parameter
   in your deployment configuration file to <code class="literal">true</code>. The second
   method is to create custom configuration files with your own sizing values.
  </p><div class="sect3 " id="id-1.3.4.5.13.2.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.9.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Finding Default and Allowable Sizing Values</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.13.2.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    The <code class="literal">sizing:</code> section in the Helm
    <code class="filename">values.yaml</code> files for the <code class="literal">kubecf</code> chart
    describes which roles can be scaled, and the scaling options for each role.
    You may use <code class="command">helm inspect</code> to read the
    <code class="literal">sizing:</code> section in the Helm chart:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm show suse/kubecf | less +/sizing:</pre></div><p>
    Another way is to use Perl to extract the information for each role from
    the <code class="literal">sizing:</code> section.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm inspect values suse/kubecf | \
perl -ne '/^sizing/..0 and do { print $.,":",$_ if /^ [a-z]/ || /high avail|scale|count/ }'</pre></div><p>
    The default <code class="filename">values.yaml</code> files are also included in
    this guide at <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a>.
   </p></div><div class="sect3 " id="id-1.3.4.5.13.2.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.9.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the <code class="literal">high_availability</code> Helm Property</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.13.2.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    One way to make your SUSE Cloud Application Platform deployment highly available is
    to use the <code class="literal">high_availability</code> Helm property. In your
    <code class="filename">kubecf-config-values.yaml</code>, set this property to
    <code class="literal">true</code>. This changes the size of all roles to the minimum
    required for a highly available deployment. Your configuration file,
    <code class="filename">kubecf-config-values.yaml</code>, should include the following.
   </p><div class="verbatim-wrap"><pre class="screen">high_availability: true</pre></div><div id="id-1.3.4.5.13.2.5.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Sizing Priority</h6><p>
   When sizing values are specified, it takes precedence over the <code class="literal">high_availability</code> property.
  </p></div></div><div class="sect3 " id="id-1.3.4.5.13.2.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.9.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Custom Sizing Configurations</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.13.2.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    Another method to make your SUSE Cloud Application Platform deployment highly available is           
    to explicitly configure the instance count of an instance group.
   </p><div id="id-1.3.4.5.13.2.6.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Sizing Priority</h6><p>
   When sizing values are specified, it takes precedence over the <code class="literal">high_availability</code> property.
  </p></div><p>
    To see the full list of configurable instance groups, refer to default
    KubeCF <code class="filename">values.yaml</code> file in the appendix at
    <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a>.
   </p><p>
    The following is an example High Availability configuration. The example values are not meant to be
    copied, as these depend on your particular deployment and requirements.
   </p><div class="verbatim-wrap"><pre class="screen">sizing:
  adapter:
    instances: 2
  api:
    instances: 2
  asactors:
    instances: 2
  asapi:
    instances: 2
  asmetrics:
    instances: 2
  asnozzle:
    instances: 2
  auctioneer:
    instances: 2
  bits:
    instances: 2
  cc_worker:
    instances: 2
  credhub:
    instances: 2
  database:
    instances: 1
  diego_api:
    instances: 2
  diego_cell:
    instances: 2
  doppler:
    instances: 2
  eirini:
    instances: 3
  log_api:
    instances: 2
  nats:
    instances: 2
  router:
    instances: 2
  routing_api:
    instances: 2
  scheduler:
    instances: 2
  uaa:
    instances: 2
  tcp_router:
    instances: 2</pre></div></div></div></div><div class="sect1 " id="sec-cap-aks-external-blobstore"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  External Blobstore
 </span> <a title="Permalink" class="permalink" href="#sec-cap-aks-external-blobstore">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-external-blobstore</li></ul></div></div></div></div><p>
  Cloud Foundry Application Runtime (CFAR) uses a blobstore (see
  <a class="link" href="https://docs.cloudfoundry.org/concepts/cc-blobstore.html" target="_blank">https://docs.cloudfoundry.org/concepts/cc-blobstore.html</a>)
  to store the source code that developers push, stage, and run. This section
  explains how to configure an external blobstore for the Cloud Controller
  component of your SUSE Cloud Application Platform deployment. Using an external blobstore is
  optional. In a default deployment, an internal blobstore is used.
 </p><p>
  SUSE Cloud Application Platform relies on <code class="filename">ops files</code> (see
  <a class="link" href="https://github.com/cloudfoundry/cf-deployment/blob/master/operations/README.md" target="_blank">https://github.com/cloudfoundry/cf-deployment/blob/master/operations/README.md</a>)
  provided by cf-deployment (see <a class="link" href="https://github.com/cloudfoundry/cf-deployment" target="_blank">https://github.com/cloudfoundry/cf-deployment</a>)
  releases for external blobstore configurations. The default configuration for
  the blobstore is <code class="literal">singleton</code>.
 </p><div class="sect2 " id="id-1.3.4.5.14.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.14.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Currently SUSE Cloud Application Platform supports Amazon Simple Storage Service (Amazon S3,
   see <a class="link" href="https://aws.amazon.com/s3/" target="_blank">https://aws.amazon.com/s3/</a>) as an external blobstore. 
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Using the Amazon S3 service, create four buckets. A bucket should be
     created for app packages, buildpacks, droplets, and resources. For
     instructions on how to create Amazone S3 buckets, see
     <a class="link" href="https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html" target="_blank">https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html</a>.
    </p></li><li class="step "><p>
     To grant proper access to the create buckets, configure an additional IAM
     role as described in the first step of <a class="link" href="https://docs.cloudfoundry.org/deploying/common/cc-blobstore-config.html#fog-aws-iam" target="_blank">https://docs.cloudfoundry.org/deploying/common/cc-blobstore-config.html#fog-aws-iam</a>.
    </p></li><li class="step "><p>
     Set the following in your <code class="filename">kubecf-config-values.yaml</code> file and replace the
     example values.
    </p><div class="verbatim-wrap"><pre class="screen">features:
  blobstore:
    provider: s3
    s3:
      aws_region: <em class="replaceable ">"us-east-1"</em>
      blobstore_access_key_id:  <em class="replaceable ">AWS-ACCESS-KEY-ID</em>
      blobstore_secret_access_key: <em class="replaceable ">AWS-SECRET-ACCESS-KEY&gt;</em>
      # User provided value for the blobstore admin password.
      blobstore_admin_users_password: <em class="replaceable ">PASSWORD</em>
      # The following values are used as S3 bucket names. The buckets are automatically created if not present.
      app_package_directory_key: <em class="replaceable ">APP-BUCKET-NAME</em>
      buildpack_directory_key: <em class="replaceable ">BUILDPACK-BUCKET-NAME</em>
      droplet_directory_key: <em class="replaceable ">DROPLET-BUCKET-NAME</em>
      resource_directory_key: <em class="replaceable ">RESOURCE-BUCKET-NAME</em></pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-aks-external-database"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  External Database
 </span> <a title="Permalink" class="permalink" href="#sec-cap-aks-external-database">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-external-database</li></ul></div></div></div></div><p>
  SUSE Cloud Application Platform can be configured to use an external database system, such as a
  data service offered by a cloud service provider or an existing high
  availability database server. In a default deployment, an internal single
  availability database is used.
 </p><p>
  To configure your deployment to use an external database, please follow the
  instructions below.
 </p><p>
  The current SUSE Cloud Application Platform release is compatible with the following types and
  versions of external databases:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    MySQL 5.7
   </p></li></ul></div><div class="sect2 " id="id-1.3.4.5.15.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.15.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   This section describes how to enable and configure your deployment to connect
   to an external database. The configuration options are specified through
   Helm values inside the <code class="filename">kubecf-config-values.yaml</code>. The
   deployment and configuration of the external database itself is the
   responsibility of the operator and beyond the scope of this documentation. It
   is assumed the external database has been deployed and accessible.
  </p><div id="id-1.3.4.5.15.6.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Configuration during Initial Install Only</h6><p>
    Configuration of SUSE Cloud Application Platform to use an external database
    <span class="bold"><strong>must</strong></span> be done during the initial
    installation and cannot be changed afterwards.
   </p></div><p>
    All the databases listed in the config snippet below need to exist before
    installing KubeCF. One way of doing that is manually running
    <code class="literal">CREATE DATABASE IF NOT EXISTS
    <em class="replaceable ">database-name</em></code> for each database.
  </p><p>
   The following snippet of the <code class="filename">kubecf-config-values.yaml</code>
   contains an example of an external database configuration.
  </p><div class="verbatim-wrap"><pre class="screen">features:
  embedded_database:
    enabled: false
  external_database:
    enabled: true
    require_ssl: false
    ca_cert: ~
    type: mysql
    host: <em class="replaceable ">hostname</em>
    port: <em class="replaceable ">3306</em>
    databases:
      uaa:
        name: uaa
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      cc:
        name: cloud_controller
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      bbs:
        name: diego
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      routing_api:
        name: routing-api
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      policy_server:
        name: network_policy
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      silk_controller:
        name: network_connectivity
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      locket: 
        name: locket
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      credhub:        
        name: credhub
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em></pre></div></div></div><div class="sect1 " id="sec-cap-addrepo-aks"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add the Kubernetes Charts Repository</span> <a title="Permalink" class="permalink" href="#sec-cap-addrepo-aks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-addrepo-aks</li></ul></div></div></div></div><p>
   Download the SUSE Kubernetes charts repository with Helm:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm repo add <em class="replaceable ">suse</em> https://kubernetes-charts.suse.com/</pre></div><p>
   You may replace the example <em class="replaceable ">suse</em> name with any
   name. Verify with <code class="command">helm</code>:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm repo list
NAME       URL
stable     https://kubernetes-charts.storage.googleapis.com
local      http://127.0.0.1:8879/charts
suse       https://kubernetes-charts.suse.com/</pre></div><p>
   List your chart names, as you will need these for some operations:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm search repo <em class="replaceable ">suse</em>
NAME                            CHART VERSION        APP VERSION    DESCRIPTION
suse/cf-operator                6.1.17+0.gec409fd7    2.1.0          A Helm chart for cf-operator, the k8s operator ....
suse/console                    4.2.0                2.1.0          A Helm chart for deploying SUSE Stratos Console
suse/kubecf                     2.5.8                2.1.0          A Helm chart for KubeCF
suse/metrics                    1.3.0                2.1.0          A Helm chart for Stratos Metrics
suse/minibroker                 1.1.0                               A minibroker for your minikube
suse/nginx-ingress              0.28.4               0.15.0         An nginx Ingress controller that uses ConfigMap to store ...
...</pre></div></div><div class="sect1 " id="sec-cap-cap-on-aks"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#sec-cap-cap-on-aks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-cap-on-aks</li></ul></div></div></div></div><p>
   This section describes how to deploy SUSE Cloud Application Platform with a Azure Standard SKU
   load balancer.
  </p><div id="id-1.3.4.5.17.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: KubeCF and cf-operator versions</h6><p>
   KubeCF and cf-operator interoperate closely. Before you deploy a
   specific version combination, make sure they were confirmed to work. For more
   information see <a class="xref" href="#cha-cap-depl-notes-releases" title="3.4. Releases and Associated Versions">Section 3.4, “Releases and Associated Versions”</a>.
  </p></div><div class="sect2 " id="sec-cap-aks-deploy-operator"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Deploy the Operator
 </span> <a title="Permalink" class="permalink" href="#sec-cap-aks-deploy-operator">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-deploy-operator</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    First, create the namespace for the operator.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">cf-operator</em></pre></div></li><li class="step "><p>
    Install the operator.
   </p><p>
    The value of <code class="literal">global.operator.watchNamespace</code> indicates the
    namespace the operator will monitor for a KubeCF deployment. This
    namespace should be separate from the namespace used by the operator. In
    this example, this means KubeCF will be deployed into a namespace called
    <code class="literal">kubecf</code>.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">cf-operator</em> suse/cf-operator \
--namespace <em class="replaceable ">cf-operator</em> \
--set "global.singleNamespace.name=<em class="replaceable ">kubecf</em>" \
--version 6.1.17+0.gec409fd7</pre></div></li><li class="step "><p>
    Wait until cf-operator is successfully deployed before proceeding. Monitor
    the status of your cf-operator deployment using the
    <code class="command">watch</code> command.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">cf-operator</em>'</pre></div></li></ol></div></div></div><div class="sect2 " id="sec-cap-aks-deploy-kubecf"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy KubeCF</span> <a title="Permalink" class="permalink" href="#sec-cap-aks-deploy-kubecf">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-deploy-kubecf</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
   Use Helm to deploy KubeCF.
  </p><p>
   Note that you <span class="bold"><strong>do not</strong></span> need to manually create
   the namespace for KubeCF.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">kubecf</em> suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values <em class="replaceable ">kubecf-config-values.yaml</em> \
--version 2.5.8</pre></div></li><li class="step "><p>
  Monitor the status of your KubeCF deployment using the
  <code class="command">watch</code> command.
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace kubecf'</pre></div></li><li class="step "><p>
   Find the value of <code class="literal">EXTERNAL-IP</code> for each of the public
   services.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> router-public

<code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> tcp-router-public

<code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> ssh-proxy-public</pre></div></li><li class="step "><p>
      Create DNS A records for the public services.
     </p><ol type="a" class="substeps "><li class="step "><p>
    For the <code class="literal">router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">*.&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">tcp-router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">tcp.&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">ssh-proxy-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">ssh.&lt;system_domain&gt;</code>.
   </p></li></ol></li><li class="step "><p>
      When all pods are fully ready, verify your deployment. See <a class="xref" href="#sec-pod-status" title="3.2. Status of Pods during Deployment">Section 3.2, “Status of Pods during Deployment”</a> for more information.
     </p><p>
  Connect and authenticate to the cluster.
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation "https://api.&lt;system_domain&gt;"

# Use the cf_admin_password set in kubecf-config-values.yaml
<code class="prompt user">tux &gt; </code>cf auth admin <em class="replaceable ">changeme</em></pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-aks-ldap"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  LDAP Integration
 </span> <a title="Permalink" class="permalink" href="#sec-cap-aks-ldap">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-ldap</li></ul></div></div></div></div><p>
  SUSE Cloud Application Platform can be integrated with
  <a class="link" href="https://docs.cloudfoundry.org/uaa/identity-providers.html" target="_blank">identity
  providers</a> to help manage authentication of users. Integrating
  SUSE Cloud Application Platform with other identity providers is optional. In a default
  deployment, a built-in UAA server (<a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-overview.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-overview.html</a>)
  is used to manage user accounts and authentication.
 </p><p>
  The Lightweight Directory Access Protocol (LDAP) is an example of an identity provider that
  Cloud Application Platform integrates with. This section describes the necessary components and
  steps in order to configure the integration. See
  <a class="link" href="https://github.com/cloudfoundry/uaa/blob/master/docs/UAA-LDAP.md" target="_blank">User
  Account and Authentication LDAP Integration</a> for more information. 
 </p><div class="sect2 " id="id-1.3.4.5.18.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.18.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The following prerequisites are required in order to complete an LDAP
   integration with SUSE Cloud Application Platform.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">uaac</code>, the Cloud Foundry <code class="literal">uaa</code> command line client
 (UAAC). See
 <a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-user-management.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-user-management.html</a>
 for more information and installation instructions.
</p><p>
 On SUSE Linux Enterprise systems, ensure the <code class="literal">ruby-devel</code> and <code class="literal">gcc-c++</code>
 packages have been installed before installing the <code class="literal">cf-uaac</code> gem.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install ruby-devel gcc-c++</pre></div></li><li class="listitem "><p>
     An LDAP server and the credentials for a user/service account with
     permissions to search the directory.
    </p></li></ul></div></div><div class="sect2 " id="id-1.3.4.5.18.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.14.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example LDAP Integration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.5.18.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Run the following commands to complete the integration of your Cloud Application Platform
   deployment and LDAP server.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
 Use UAAC to target your <code class="literal">uaa</code> server.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac target --skip-ssl-validation <em class="replaceable ">https://uaa.example.com</em></pre></div></li><li class="step "><p>
 Authenticate to the <code class="literal">uaa</code> server as
 <code class="literal">admin</code> using the
 <code class="literal">uaa_admin_client_secret</code> set in your
 <code class="filename">kubecf-config-values.yaml</code> file.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac token client get admin --secret <em class="replaceable ">PASSWORD</em></pre></div></li><li class="step "><p>
     List the current identity providers.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers --insecure</pre></div></li><li class="step "><p>
     From the output, locate the default <code class="literal">ldap</code> entry and take
     note of its <code class="literal">id</code>. The entry will be similar to the
     following.
    </p><div class="verbatim-wrap"><pre class="screen">{
  "type": "ldap",
  "config": "{\"emailDomain\":null,\"additionalConfiguration\":null,\"providerDescription\":null,\"externalGroupsWhitelist\":[],\"attributeMappings\":{},\"addShadowUserOnLogin\":true,\"storeCustomAttributes\":true,\"ldapProfileFile\":\"ldap/ldap-search-and-bind.xml\",\"baseUrl\":\"ldap://localhost:389/\",\"referral\":null,\"skipSSLVerification\":false,\"userDNPattern\":null,\"userDNPatternDelimiter\":null,\"bindUserDn\":\"cn=admin,dc=test,dc=com\",\"userSearchBase\":\"dc=test,dc=com\",\"userSearchFilter\":\"cn={0}\",\"passwordAttributeName\":null,\"passwordEncoder\":null,\"localPasswordCompare\":null,\"mailAttributeName\":\"mail\",\"mailSubstitute\":null,\"mailSubstituteOverridesLdap\":false,\"ldapGroupFile\":null,\"groupSearchBase\":null,\"groupSearchFilter\":null,\"groupsIgnorePartialResults\":null,\"autoAddGroups\":true,\"groupSearchSubTree\":true,\"maxGroupSearchDepth\":10,\"groupRoleAttribute\":null,\"tlsConfiguration\":\"none\"}",
  "id": "53gc6671-2996-407k-b085-2346e216a1p0",
  "originKey": "ldap",
  "name": "UAA LDAP Provider",
  "version": 3,
  "created": 946684800000,
  "last_modified": 1602208214000,
  "active": false,
  "identityZoneId": "uaa"
},</pre></div></li><li class="step "><p>
     Delete the default <code class="literal">ldap</code> identity provider. If the
     default entry is not removed, adding another identity provider of type
     <code class="literal">ldap</code> will result in a <code class="literal">409 Conflict</code>
     response. Replace the example <code class="literal">id</code> with one found in the
     previous step.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers/<em class="replaceable ">53gc6671-2996-407k-b085-2346e216a1p0</em> \
    --request DELETE \
    --insecure</pre></div></li><li class="step "><p>
     Create your own LDAP identity provider. A <code class="literal">201 Created</code>
     response will be returned when the identity provider is successfully
     created. See the
     <a class="link" href="http://docs.cloudfoundry.org/api/uaa/version/4.21.0/index.html#ldap" target="_blank">UAA
     API Reference</a> and
     <a class="link" href="https://github.com/cloudfoundry/uaa/blob/4.21.0/docs/UAA-LDAP.md" target="_blank">Cloud Foundry
     UAA-LDAP Documentation</a>for information regarding the request
     parameters and additional options available to configure your identity
     provider.
    </p><p>
     The following is an example of a <code class="literal">uaac curl</code> command and
     its request parameters used to create an identity provider. Specify the
     parameters according to your LDAP server's credentials and directory
     structure. Ensure the user specifed in the <code class="literal">bindUserDn</code>
     has permissions to search the directory.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers?rawConfig=true \
    --request POST \
    --insecure \
    --header 'Content-Type: application/json' \
    --data '{
  "type" : "ldap",
  "config" : {
    "ldapProfileFile" : "ldap/ldap-search-and-bind.xml",
    "baseUrl" : "<em class="replaceable ">ldap://ldap.example.com:389</em>",
    "bindUserDn" : "<em class="replaceable ">cn=admin,dc=example,dc=com</em>",
    "bindPassword" : "<em class="replaceable ">password</em>",
    "userSearchBase" : "<em class="replaceable ">dc=example,dc=com</em>",
    "userSearchFilter" : "<em class="replaceable ">uid</em>={0}",
    "ldapGroupFile" : "ldap/ldap-groups-map-to-scopes.xml",
    "groupSearchBase" : "<em class="replaceable ">dc=example,dc=com</em>",
    "groupSearchFilter" : "<em class="replaceable ">member</em>={0}"
  },
  "originKey" : "ldap",
  "name" : "<em class="replaceable ">My LDAP Server</em>",
  "active" : true
  }'</pre></div></li><li class="step "><p>
     Verify the LDAP identify provider has been created. The output should now
     contain an entry for the <code class="literal">ldap</code> type you created.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers --insecure</pre></div></li><li class="step "><p>
     Use the cf CLI to target your SUSE Cloud Application Platform deployment.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation https://api.example.com</pre></div></li><li class="step "><p>
     Log in as an administrator.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login
API endpoint: https://api.example.com

Email&gt; admin

Password&gt;
Authenticating...
OK</pre></div></li><li class="step "><p>
     Create users associated with your LDAP identity provider.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-user <em class="replaceable ">username</em> --origin ldap
Creating user username...
OK

TIP: Assign roles with 'cf set-org-role' and 'cf set-space-role'.</pre></div></li><li class="step "><p>
     Assign the user a role. Roles define the permissions a user has for a
     given org or space and a user can be assigned multiple roles. See
     <a class="link" href="https://docs.cloudfoundry.org/concepts/roles.html" target="_blank">Orgs,
     Spaces, Roles, and Permissions</a> for available roles and their
     corresponding permissions. The following example assumes that an org named
     <em class="replaceable ">Org</em> and a space named
     <em class="replaceable ">Space</em> have already been created.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf set-space-role <em class="replaceable ">username</em> <em class="replaceable ">Org</em> <em class="replaceable ">Space</em> <em class="replaceable ">SpaceDeveloper</em>
Assigning role RoleSpaceDeveloper to user username in org Org / space Space as admin...
OK
<code class="prompt user">tux &gt; </code>cf set-org-role <em class="replaceable ">username</em> Org OrgManager
Assigning role OrgManager to user username in org Org as admin...
OK</pre></div></li><li class="step "><p>
     Verify the user can log into your SUSE Cloud Application Platform deployment using their
     associated LDAP server credentials.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login
API endpoint: https://api.example.com

Email&gt; username

Password&gt;
Authenticating...
OK



API endpoint:   https://api.example.com (API version: 2.115.0)
User:           username@ldap.example.com</pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-aks-add-capacity"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Expanding Capacity of a Cloud Application Platform Deployment on Microsoft AKS</span> <a title="Permalink" class="permalink" href="#sec-cap-aks-add-capacity">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_aks.xml</li><li><span class="ds-label">ID: </span>sec-cap-aks-add-capacity</li></ul></div></div></div></div><p>
   If the current capacity of your Cloud Application Platform deployment is insufficient for your
   workloads, you can expand the capacity using the procedure in this section.
  </p><p>
   These instructions assume you have followed the procedure in
   <a class="xref" href="#cha-cap-depl-aks" title="Chapter 5. Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)">Chapter 5, <em>Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</em></a> and have a running Cloud Application Platform deployment on
   Microsoft AKS. The instructions below will use environment variables defined in
   <a class="xref" href="#sec-cap-create-aks-instance" title="5.2. Create Resource Group and AKS Instance">Section 5.2, “Create Resource Group and AKS Instance”</a>.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Get the current number of Kubernetes nodes in the cluster.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>export OLD_NODE_COUNT=$(kubectl get nodes --output json | jq '.items | length')</pre></div></li><li class="step "><p>
     Set the number of Kubernetes nodes the cluster will be expanded to. Replace the
     example value with the number of nodes required for your workload.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>export NEW_NODE_COUNT=<em class="replaceable ">5</em></pre></div></li><li class="step "><p>
     
     Increase the Kubernetes node count in the cluster.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>az aks scale --resource-group $RG_NAME --name $AKS_NAME \
--node-count $NEW_NODE_COUNT \
--nodepool-name $NODEPOOL_NAME</pre></div></li><li class="step "><p>
     Verify the new nodes are in a <code class="literal">Ready</code> state before proceeding.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get nodes</pre></div></li><li class="step "><p>
     Add or update the following in your
     <code class="filename">kubecf-config-values.yaml</code> file to increase the number of
     <code class="literal">diego-cell</code> in your Cloud Application Platform deployment. Replace the
     example value with the number required by your workflow.
    </p><div class="verbatim-wrap"><pre class="screen">sizing:
  diego_cell:
    instances: <em class="replaceable ">5</em></pre></div></li><li class="step "><p>
     Perform a <code class="command">helm upgrade</code> to apply the change.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade kubecf suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values kubecf-config-values.yaml \
--version 2.5.8</pre></div></li><li class="step "><p>
     Monitor progress of the additional <code class="literal">diego-cell</code> pods:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace kubecf'</pre></div></li></ol></div></div></div></div><div class="chapter " id="cha-cap-depl-eks"><div class="titlepage"><div><div><h2 class="title"><span class="number">6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-eks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-eks-prereqs"><span class="number">6.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-eks-cluster"><span class="number">6.2 </span><span class="name">Create an EKS Cluster</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.6.6"><span class="number">6.3 </span><span class="name">Install the Helm Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-storage-class"><span class="number">6.4 </span><span class="name">
  Storage Class
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-configuration"><span class="number">6.5 </span><span class="name">Deployment Configuration</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-certificates"><span class="number">6.6 </span><span class="name">
  Certificates
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-ingress"><span class="number">6.7 </span><span class="name">
  Using an Ingress Controller
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-affinity"><span class="number">6.8 </span><span class="name">
  Affinity and Anti-affinity
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-high-availability"><span class="number">6.9 </span><span class="name">
  High Availability
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-external-blobstore"><span class="number">6.10 </span><span class="name">
  External Blobstore
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-external-database"><span class="number">6.11 </span><span class="name">
  External Database
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-addrepo-eks"><span class="number">6.12 </span><span class="name">Add the Kubernetes Charts Repository</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-cap-on-eks"><span class="number">6.13 </span><span class="name">Deploying SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-ldap"><span class="number">6.14 </span><span class="name">
  LDAP Integration
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eks-add-capacity"><span class="number">6.15 </span><span class="name">Expanding Capacity of a Cloud Application Platform Deployment on Amazon EKS</span></a></span></dt></dl></div></div><div id="id-1.3.4.6.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><div id="id-1.3.4.6.2.1" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        <a class="link" href="https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2.0/" target="_blank">
        SUSE Cloud Application Platform Release Notes</a>
      </p></li><li class="listitem "><p>
        <a class="xref" href="#cha-cap-depl-notes" title="Chapter 3. Deployment and Administration Notes">Chapter 3, <em>Deployment and Administration Notes</em></a>
      </p></li></ul></div></div></div><p>
  This chapter describes how to deploy SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS), using
  Amazon's Elastic Load Balancer to provide fault-tolerant access to your
  cluster.
 </p><div class="sect1 " id="sec-cap-eks-prereqs"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#sec-cap-eks-prereqs">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-prereqs</li></ul></div></div></div></div><p>
   The following are required to deploy and use SUSE Cloud Application Platform on EKS:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     An Amazon AWS account with sufficient permissions. For details, refer to
     <a class="link" href="https://docs.aws.com/eks/latest/userguide/security-iam.html" target="_blank">https://docs.aws.com/eks/latest/userguide/security-iam.html</a>.
    </p></li><li class="listitem "><p>
     <code class="command">eksctl</code>, a command line client to create and manage
     Kubernetes clusters on Amazon EKS. See
     <a class="link" href="https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html" target="_blank">https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html</a>
     for more information and installation instructions.
    </p></li><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">kubectl</code>, the Kubernetes command line tool. For more
 information, refer to
 <a class="link" href="https://kubernetes.io/docs/reference/kubectl/overview/" target="_blank">https://kubernetes.io/docs/reference/kubectl/overview/</a>.
</p><p>
 For SLE 12 SP3 or 15 SP1 systems, install the package
 <span class="package ">kubernetes-client</span> from the <span class="emphasis"><em>Public Cloud</em></span>
 module.
</p><p>
 For other systems, follow the instructions at
 <a class="link" href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a>.
</p></li><li class="listitem "><p>
 <code class="command">curl</code>, the Client URL (cURL) command line tool.
</p></li></ul></div></div><div class="sect1 " id="sec-cap-create-eks-cluster"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create an EKS Cluster</span> <a title="Permalink" class="permalink" href="#sec-cap-create-eks-cluster">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-create-eks-cluster</li></ul></div></div></div></div><p>
   Now you can create an EKS cluster using <code class="command">eksctl</code>. Be sure to
   keep in mind the following minimum requirements of the cluster.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Node sizes are at least <code class="literal">t3.xlarge</code>.
    </p></li><li class="listitem "><p>
     The <code class="literal">NodeVolumeSize</code> must be a minimum of 100 GB.
    </p></li><li class="listitem "><p>
     The Kubernetes version is at least 1.14.
    </p></li></ul></div><p>
   As a minimal example, the following command will create an EKS cluster. To
   see additional configuration parameters, see <code class="command">eksctl create cluster --help</code>.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>eksctl create cluster --name <em class="replaceable ">kubecf</em> --version <em class="replaceable ">1.14</em> \
--nodegroup-name <em class="replaceable ">standard-workers</em> --node-type <em class="replaceable ">t3.xlarge</em> \
--nodes <em class="replaceable ">3</em> --node-volume-size <em class="replaceable ">100</em> \
--region <em class="replaceable ">us-east-2</em> --managed \
--ssh-access --ssh-public-key <em class="replaceable ">/path/to/some_key.pub</em></pre></div></div><div class="sect1 " id="id-1.3.4.6.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the Helm Client</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Helm is a Kubernetes package manager used to install and manage SUSE Cloud Application Platform.
   This requires installing the Helm client, <code class="command">helm</code>, on your
   remote management workstation. Cloud Application Platform requires Helm 3.
   For more information regarding Helm, refer to the documentation at
   <a class="link" href="https://helm.sh/docs/" target="_blank">https://helm.sh/docs/</a>.
  </p><div id="id-1.3.4.6.6.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Make sure that you are installing and using Helm 3 and not Helm 2.</p></div><p>
   If your remote management workstation has the SUSE CaaS Platform package repository,
   install <code class="command">helm</code> by running
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install helm3
<code class="prompt user">tux &gt; </code>sudo update-alternatives --set helm /usr/bin/helm3</pre></div><p>
   Otherwise, <code class="command">helm</code> can be installed  by referring to the
   documentation at <a class="link" href="https://helm.sh/docs/intro/install/" target="_blank">https://helm.sh/docs/intro/install/</a>.
  </p></div><div class="sect1 " id="sec-cap-eks-storage-class"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Storage Class
 </span> <a title="Permalink" class="permalink" href="#sec-cap-eks-storage-class">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-storage-class</li></ul></div></div></div></div><p>
  In some SUSE Cloud Application Platform instance groups, such as <code class="literal">bits</code>,
  <code class="literal">database</code>, <code class="literal">diego-cell</code>, and
  <code class="literal">singleton-blobstore</code> require a storage class for persistent
  data. To learn more about storage classes, see
  <a class="link" href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank">https://kubernetes.io/docs/concepts/storage/storage-classes/</a>. 
 </p><p>
  By default, SUSE Cloud Application Platform will use the cluster's default storage class. 
  To designate or change the default storage class, refer to
  <a class="link" href="https://kubernetes.io/docs/tasks/administer-cluster/change-default-storage-class/" target="_blank">https://kubernetes.io/docs/tasks/administer-cluster/change-default-storage-class/</a>
  for instructions.
 </p><p>
  In some cases, the default and predefined storage classes may not be suitable
  for certain workloads. If this is the case, operators can define their own
  custom StorageClass resource according to the specification at 
  <a class="link" href="https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource" target="_blank">https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource</a>.
 </p><p>
  With the storage class defined, run:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create --filename <em class="replaceable ">my-storage-class.yaml</em></pre></div><p>
  Then verify the storage class is available by running
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get storageclass</pre></div><p>
  If operators do no want to use the default storage class or one does not
  exist, a storage class <span class="bold"><strong>must</strong></span> be specified by
  setting the <code class="literal">kube.storage_class</code> value in your
  <code class="filename">kubecf-config-values.yaml</code> configuration file to the name of the storage class as seen
  in this example. 
 </p><div class="verbatim-wrap"><pre class="screen">kube:
  storage_class: <em class="replaceable ">my-storage-class</em></pre></div></div><div class="sect1 " id="sec-cap-eks-configuration"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment Configuration</span> <a title="Permalink" class="permalink" href="#sec-cap-eks-configuration">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-configuration</li></ul></div></div></div></div><p>
   Use this example <code class="filename">kubecf-config-values.yaml</code> as a template
   for your configuration.
  </p><div id="id-1.3.4.6.8.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: kubecf-config-values.yaml changes</h6><p>
    The format of the <code class="filename">kubecf-config-values.yaml</code> file has been restructured completely in
    Cloud Application Platform 2.x. Do not re-use the Cloud Application Platform 1.x version of the file. Instead, see the
    default file in the appendix in
    <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a> and pick parameters according to
    your needs.
  </p></div><div id="id-1.3.4.6.8.4" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: Supported Domains</h6><p>
   When selecting a domain, SUSE Cloud Application Platform expects <code class="literal">system_domain</code> to
   be either a subdomain or a root domain. Setting <code class="literal">system_domain</code> to
   a top-level domain, such as <code class="literal">suse</code>, is not supported.
  </p></div><div class="verbatim-wrap"><pre class="screen">### Example deployment configuration file
### kubecf-config-values.yaml

system_domain: example.com

credentials:
  cf_admin_password: <em class="replaceable ">changeme</em>
  uaa_admin_client_secret: <em class="replaceable ">alsochangeme</em>

### This block is required due to the log-cache issue described below
properties:
  log-cache:
    log-cache:
      memory_limit_percent: 3

### This block is required due to the log-cache issue described below
###
### The value for <code class="literal">key</code> may need to be replaced depending on
### how notes in your cluster are labeled
###
### The value(s) listed under <code class="literal">values</code> may need to be
### replaced depending on how notes in your cluster are labeled
operations:
  inline:
  - type: replace
    path: /instance_groups/name=log-cache/env?/bosh/agent/settings/affinity
    value:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: <em class="replaceable ">kubernetes.io/hostname</em>
              operator: In
              values:
              - <em class="replaceable ">LABEL_VALUE_OF_NODE</em></pre></div><div class="sect2 " id="id-1.3.4.6.8.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Log-cache Memory Allocation</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.8.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  The log-cache component currently has a memory allocation issue where the node
  memory available is reported instead of the one assigned to the container under
  cgroups. In such a situation, log-cache would start allocating memory based on
  these values, causing a varying range of issues (OOMKills, performance
  degradation, etc.). To address this issue, node affinity must be used to tie
  log-cache to nodes of a uniform size, and then declaring the cache percentage
  based on that number. A limit of 3% has been identified as sufficient.
 </p><p>
  In the node affinity configuration, the values for <code class="literal">key</code> and
  <code class="literal">values</code> may need to be changed depending on how notes in your
  cluster are labeled. For more information on labels, see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels</a>.
 </p></div><div class="sect2 " id="id-1.3.4.6.8.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Diego Cell Affinities and Tainted Nodes</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.8.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  Note that the <code class="literal">diego-cell</code> pods used by the Diego standard
  scheduler are
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    privileged
   </p></li><li class="listitem "><p>
    use large local emptyDir volumes (i.e. require node disk storage)
   </p></li><li class="listitem "><p>
    and set kernel parameters on the node
   </p></li></ul></div><p>
  These things all mean that these pods should not live next to other Kubernetes
  workloads. They should all be placed on their own
  <span class="bold"><strong>dedicated nodes</strong></span> instead where possible.
 </p><p>
  This can be done by setting affinities and tolerations, as explained in
the associated tutorial at <a class="link" href="https://kubecf.io/docs/deployment/affinities-and-tolerations/" target="_blank">https://kubecf.io/docs/deployment/affinities-and-tolerations/</a>.
 </p></div></div><div class="sect1 " id="sec-cap-eks-certificates"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Certificates
 </span> <a title="Permalink" class="permalink" href="#sec-cap-eks-certificates">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-certificates</li></ul></div></div></div></div><p>
  This section describes the process to secure traffic passing through your
  SUSE Cloud Application Platform deployment. This is achieved by using certificates to set up
  Transport Layer Security (TLS) for the router component. Providing
  certificates for the router traffic is optional. In a default deployment,
  without operator-provided certificates, generated certificates will be used.
 </p><div class="sect2 " id="id-1.3.4.6.9.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Certificate Characteristics</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.9.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Ensure the certificates you use have the following characteristics:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The certificate is encoded in the PEM format.
    </p></li><li class="listitem "><p>
     The certificate is signed by an external Certificate Authority (CA).
    </p></li><li class="listitem "><p>
     The certificate's Subject Alternative Names (SAN) include the domain
     <em class="replaceable ">*.example.com</em>, where <em class="replaceable ">example.com</em>
     is replaced with the <code class="literal">system_domain</code> in your
     <code class="filename">kubecf-config-values.yaml</code>.
    </p></li></ul></div></div><div class="sect2 " id="id-1.3.4.6.9.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.9.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The certificate used to secure your deployment is passed through the
   <code class="filename">kubecf-config-values.yaml</code> configuration file. To specify
   a certificate, set the value of the certificate and its corresponding private
   key using the <code class="literal">router.tls.crt</code> and
   <code class="literal">router.tls.key</code> Helm values in the
   <code class="literal">settings:</code> section.
  </p><div class="verbatim-wrap"><pre class="screen">settings:
  router:
    tls:
      crt: |
        -----BEGIN CERTIFICATE-----
        MIIEEjCCAfoCCQCWC4NErLzy3jANBgkqhkiG9w0BAQsFADBGMQswCQYDVQQGEwJD
        QTETMBEGA1UECAwKU29tZS1TdGF0ZTEOMAwGA1UECgwFTXlPcmcxEjAQBgNVBAMM
        CU15Q0Euc2l0ZTAeFw0xODA5MDYxNzA1MTRaFw0yMDAxMTkxNzA1MTRaMFAxCzAJ
        ...
        xtNNDwl2rnA+U0Q48uZIPSy6UzSmiNaP3PDR+cOak/mV8s1/7oUXM5ivqkz8pEJo
        M3KrIxZ7+MbdTvDOh8lQplvFTeGgjmUDd587Gs4JsormqOsGwKd1BLzQbGELryV9
        1usMOVbUuL8mSKVvgqhbz7vJlW1+zwmrpMV3qgTMoHoJWGx2n5g=
        -----END CERTIFICATE-----
      key: |
        -----BEGIN RSA PRIVATE KEY-----
        MIIEpAIBAAKCAQEAm4JMchGSqbZuqc4LdryJpX2HnarWPOW0hUkm60DL53f6ehPK
        T5Dtb2s+CoDX9A0iTjGZWRD7WwjpiiuXUcyszm8y9bJjP3sIcTnHWSgL/6Bb3KN5
        G5D8GHz7eMYkZBviFvygCqEs1hmfGCVNtgiTbAwgBTNsrmyx2NygnF5uy4KlkgwI
        ...
        GORpbQKBgQDB1/nLPjKxBqJmZ/JymBl6iBnhIgVkuUMuvmqES2nqqMI+r60EAKpX
        M5CD+pq71TuBtbo9hbjy5Buh0+QSIbJaNIOdJxU7idEf200+4anzdaipyCWXdZU+
        MPdJf40awgSWpGdiSv6hoj0AOm+lf4AsH6yAqw/eIHXNzhWLRvnqgA==
        -----END RSA PRIVATE KEY----</pre></div></div></div><div class="sect1 " id="sec-cap-eks-ingress"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Using an Ingress Controller
 </span> <a title="Permalink" class="permalink" href="#sec-cap-eks-ingress">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-ingress</li></ul></div></div></div></div><p>
  This section describes how to use an ingress controller
  (see <a class="link" href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank">https://kubernetes.io/docs/concepts/services-networking/ingress/</a>)
  to manage access to the services in the cluster. Using an ingress controller
  is optional. In a default deployment, load balancers are used instead.
 </p><p>
  Note that only the NGINX Ingress Controller has been verified to be
  compatible with Cloud Application Platform. Other Ingress controller alternatives may work, but
  compatibility with Cloud Application Platform is not supported.
 </p><div class="sect2 " id="id-1.3.4.6.10.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install and Configure the NGINX Ingress Controller</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.10.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Create a configuration file with the section below. The file is called
     <code class="filename">nginx-ingress.yaml</code> in this example. When using
     Eirini instead of Diego, replace the first line with
     <code class="literal">2222: "kubecf/eirinix-ssh-proxy:2222"</code>.
    </p><div class="verbatim-wrap"><pre class="screen">tcp:
  2222: "kubecf/scheduler:2222"
  20000: "kubecf/tcp-router:20000"
  20001: "kubecf/tcp-router:20001"
  20002: "kubecf/tcp-router:20002"
  20003: "kubecf/tcp-router:20003"
  20004: "kubecf/tcp-router:20004"
  20005: "kubecf/tcp-router:20005"
  20006: "kubecf/tcp-router:20006"
  20007: "kubecf/tcp-router:20007"
  20008: "kubecf/tcp-router:20008"</pre></div></li><li class="step "><p>
     Create the namespace.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">nginx-ingress</em></pre></div></li><li class="step "><p>
     Install the NGINX Ingress Controller.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">nginx-ingress</em> suse/nginx-ingress \
--namespace <em class="replaceable ">nginx-ingress</em> \
--values <em class="replaceable ">nginx-ingress.yaml</em></pre></div></li><li class="step "><p>
     Monitor the progess of the deployment:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">nginx-ingress</em>'</pre></div></li><li class="step "><p>
     After the deployment completes, the Ingress controller service will be deployed
     with either an external IP or a hostname. 
    </p><p>
     Find the external IP or hostname.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get services nginx-ingress-controller --namespace nginx-ingress</pre></div><p>
     You will get output similar to the following.
    </p><div class="verbatim-wrap"><pre class="screen">NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)
nginx-ingress-controller   LoadBalancer   <em class="replaceable ">10.63.248.70</em>   <em class="replaceable ">35.233.191.177</em>   80:30344/TCP,443:31386/TCP</pre></div></li><li class="step "><p>
     Set up DNS records corresponding to the controller service IP or hostname
     and map it to the <code class="literal">system_domain</code> defined in your
     <code class="filename">kubecf-config-values.yaml</code>.
    </p></li><li class="step "><p>
     Obtain a PEM formatted certificate that is associated with the
     <code class="literal">system_domain</code> defined in your <code class="filename">kubecf-config-values.yaml</code>
    </p></li><li class="step "><p>
     In your <code class="filename">kubecf-config-values.yaml</code> configuration file, enable the ingress feature and
     set the <code class="literal">tls.crt</code> and <code class="literal">tls.key</code> for the
     certificate from the previous step.
    </p><div class="verbatim-wrap"><pre class="screen">features:
  ingress:
    enabled: true
    tls:
      crt: |
        -----BEGIN CERTIFICATE-----
        MIIE8jCCAtqgAwIBAgIUT/Yu/Sv8AUl5zHXXEKCy5RKJqmYwDQYJKoZIhvcMOQMM
        [...]
        xC8x/+zB7XlvcRJRio6kk670+25ABP==
        -----END CERTIFICATE-----
      key: |
        -----BEGIN RSA PRIVATE KEY-----
        MIIE8jCCAtqgAwIBAgIUSI02lj2b2ImLy/zMrjNgW5d8EygwQSVJKoZIhvcYEGAW
        [...]
        to2WV7rPMb9W9fd2vVUXKKHTc+PiNg==
        -----END RSA PRIVATE KEY-----</pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-eks-affinity"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Affinity and Anti-affinity
 </span> <a title="Permalink" class="permalink" href="#sec-cap-eks-affinity">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-affinity</li></ul></div></div></div></div><div id="id-1.3.4.6.11.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
   This feature requires SUSE Cloud Application Platform 2.0.1 or newer.
  </p></div><p>
  Operators can set affinity/anti-affinity rules to restrict how the scheduler
  determines the placement of a given pod on a given node. This can be
  achieved through node affinity/anti-affinity, where placement is determined
  by node labels (see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity</a>),
  or pod affinity/anti-affinity, where pod placement is determined by labels
  on pods that are already running on the node (see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity</a>). 
 </p><p>
  In SUSE Cloud Application Platform, a default configuration will have following
  affinity/anti-affinity rules already in place:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Instance groups have anti-affinity against themselves. This applies to all
    instance groups, including <code class="literal">database</code>, but not to the
    <code class="literal">bits</code>, <code class="literal">eirini</code>, and
    <code class="literal">eirini-extensions</code> subcharts.
   </p></li><li class="listitem "><p>
    The <code class="literal">diego-cell</code> and <code class="literal">router</code> instance
    groups have anti-affinity against each other.
   </p></li></ul></div><p>
  Note that to ensure an optimal spread of the pods across worker nodes we
  recommend running 5 or more worker nodes to satisfy both of the default
  anti-affinity constraints. An operator can also specify custom affinity rules
  via the
  <code class="literal">sizing.<em class="replaceable ">instance-group</em>.affinity</code>
  helm parameter and any affinity rules specified here will overwrite the
  default rule, not merge with it.
 </p><div class="sect2 " id="id-1.3.4.6.11.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring Rules</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.11.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   To add or override affinity/anti-affinity settings, add a
   <code class="literal">sizing.INSTANCE_GROUP.affinity</code> block to your
   <code class="filename">kubecf-config-values.yaml</code>. Repeat as necessary for each instance group where
   affinity/anti-affinity settings need to be applied. For information on
   the available fields and valid values within the <code class="literal">affinity:</code>
   block, see
   <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity</a>.
   Repeat as necessary for each instance group where affinity/anti-affinity
   settings need to be applied.
  </p><p>
   Example 1, node affinity.
  </p><p>
   Using this configuration, the Kubernetes scheduler would place both the
   <code class="literal">asactors</code> and <code class="literal">asapi</code> instance groups on a
   node with a label where the key is
   <code class="literal">topology.kubernetes.io/zone</code> and the value is
   <code class="literal">0</code>.
  </p><div class="verbatim-wrap"><pre class="screen">sizing:
   asactors:
     affinity:
       nodeAffinity:
         requiredDuringSchedulingIgnoredDuringExecution:
           nodeSelectorTerms:
           - matchExpressions:
             - key: topology.kubernetes.io/zone
               operator: In
               values:
               - 0
   asapi:
     affinity:
       nodeAffinity:
         requiredDuringSchedulingIgnoredDuringExecution:
           nodeSelectorTerms:
           - matchExpressions:
             - key: topology.kubernetes.io/zone
               operator: In
               values:
               - 0</pre></div><p>
   Example 2, pod anti-affinity.
  </p><div class="verbatim-wrap"><pre class="screen">sizing:
  api:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: quarks.cloudfoundry.org/quarks-statefulset-name
                operator: In
                values:
                - sample_group
            topologyKey: kubernetes.io/hostname
  database:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: quarks.cloudfoundry.org/quarks-statefulset-name
                operator: In
                values:
                - sample_group
            topologyKey: kubernetes.io/hostname</pre></div><p>
   Example 1 above uses <code class="literal">topology.kubernetes.io/zone</code> as its
   label, which is one of the standard labels that get attached to nodes by
   default. The list of standard labels can be found at
   <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels</a>. 
  </p><p>
   In addition to the standard labels, custom labels can be specified as in
   Example 2. To use custom labels, following the process described in this
   section <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector</a>.
  </p></div></div><div class="sect1 " id="sec-cap-eks-high-availability"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  High Availability
 </span> <a title="Permalink" class="permalink" href="#sec-cap-eks-high-availability">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-high-availability</li></ul></div></div></div></div><div class="sect2 " id="id-1.3.4.6.12.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring Cloud Application Platform for High Availability</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.12.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   High availability mode is optional. In a default deployment, SUSE Cloud Application Platform is
   deployed in single availability mode.
  </p><p>
   There are two ways to make your SUSE Cloud Application Platform deployment highly available.
   The first method is to set the <code class="literal">high_availability</code> parameter
   in your deployment configuration file to <code class="literal">true</code>. The second
   method is to create custom configuration files with your own sizing values.
  </p><div class="sect3 " id="id-1.3.4.6.12.2.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.9.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Finding Default and Allowable Sizing Values</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.12.2.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    The <code class="literal">sizing:</code> section in the Helm
    <code class="filename">values.yaml</code> files for the <code class="literal">kubecf</code> chart
    describes which roles can be scaled, and the scaling options for each role.
    You may use <code class="command">helm inspect</code> to read the
    <code class="literal">sizing:</code> section in the Helm chart:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm show suse/kubecf | less +/sizing:</pre></div><p>
    Another way is to use Perl to extract the information for each role from
    the <code class="literal">sizing:</code> section.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm inspect values suse/kubecf | \
perl -ne '/^sizing/..0 and do { print $.,":",$_ if /^ [a-z]/ || /high avail|scale|count/ }'</pre></div><p>
    The default <code class="filename">values.yaml</code> files are also included in
    this guide at <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a>.
   </p></div><div class="sect3 " id="id-1.3.4.6.12.2.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.9.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the <code class="literal">high_availability</code> Helm Property</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.12.2.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    One way to make your SUSE Cloud Application Platform deployment highly available is
    to use the <code class="literal">high_availability</code> Helm property. In your
    <code class="filename">kubecf-config-values.yaml</code>, set this property to
    <code class="literal">true</code>. This changes the size of all roles to the minimum
    required for a highly available deployment. Your configuration file,
    <code class="filename">kubecf-config-values.yaml</code>, should include the following.
   </p><div class="verbatim-wrap"><pre class="screen">high_availability: true</pre></div><div id="id-1.3.4.6.12.2.5.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Sizing Priority</h6><p>
   When sizing values are specified, it takes precedence over the <code class="literal">high_availability</code> property.
  </p></div></div><div class="sect3 " id="id-1.3.4.6.12.2.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.9.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Custom Sizing Configurations</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.12.2.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    Another method to make your SUSE Cloud Application Platform deployment highly available is           
    to explicitly configure the instance count of an instance group.
   </p><div id="id-1.3.4.6.12.2.6.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Sizing Priority</h6><p>
   When sizing values are specified, it takes precedence over the <code class="literal">high_availability</code> property.
  </p></div><p>
    To see the full list of configurable instance groups, refer to default
    KubeCF <code class="filename">values.yaml</code> file in the appendix at
    <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a>.
   </p><p>
    The following is an example High Availability configuration. The example values are not meant to be
    copied, as these depend on your particular deployment and requirements.
   </p><div class="verbatim-wrap"><pre class="screen">sizing:
  adapter:
    instances: 2
  api:
    instances: 2
  asactors:
    instances: 2
  asapi:
    instances: 2
  asmetrics:
    instances: 2
  asnozzle:
    instances: 2
  auctioneer:
    instances: 2
  bits:
    instances: 2
  cc_worker:
    instances: 2
  credhub:
    instances: 2
  database:
    instances: 1
  diego_api:
    instances: 2
  diego_cell:
    instances: 2
  doppler:
    instances: 2
  eirini:
    instances: 3
  log_api:
    instances: 2
  nats:
    instances: 2
  router:
    instances: 2
  routing_api:
    instances: 2
  scheduler:
    instances: 2
  uaa:
    instances: 2
  tcp_router:
    instances: 2</pre></div></div></div></div><div class="sect1 " id="sec-cap-eks-external-blobstore"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  External Blobstore
 </span> <a title="Permalink" class="permalink" href="#sec-cap-eks-external-blobstore">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-external-blobstore</li></ul></div></div></div></div><p>
  Cloud Foundry Application Runtime (CFAR) uses a blobstore (see
  <a class="link" href="https://docs.cloudfoundry.org/concepts/cc-blobstore.html" target="_blank">https://docs.cloudfoundry.org/concepts/cc-blobstore.html</a>)
  to store the source code that developers push, stage, and run. This section
  explains how to configure an external blobstore for the Cloud Controller
  component of your SUSE Cloud Application Platform deployment. Using an external blobstore is
  optional. In a default deployment, an internal blobstore is used.
 </p><p>
  SUSE Cloud Application Platform relies on <code class="filename">ops files</code> (see
  <a class="link" href="https://github.com/cloudfoundry/cf-deployment/blob/master/operations/README.md" target="_blank">https://github.com/cloudfoundry/cf-deployment/blob/master/operations/README.md</a>)
  provided by cf-deployment (see <a class="link" href="https://github.com/cloudfoundry/cf-deployment" target="_blank">https://github.com/cloudfoundry/cf-deployment</a>)
  releases for external blobstore configurations. The default configuration for
  the blobstore is <code class="literal">singleton</code>.
 </p><div class="sect2 " id="id-1.3.4.6.13.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.13.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Currently SUSE Cloud Application Platform supports Amazon Simple Storage Service (Amazon S3,
   see <a class="link" href="https://aws.amazon.com/s3/" target="_blank">https://aws.amazon.com/s3/</a>) as an external blobstore. 
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Using the Amazon S3 service, create four buckets. A bucket should be
     created for app packages, buildpacks, droplets, and resources. For
     instructions on how to create Amazone S3 buckets, see
     <a class="link" href="https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html" target="_blank">https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html</a>.
    </p></li><li class="step "><p>
     To grant proper access to the create buckets, configure an additional IAM
     role as described in the first step of <a class="link" href="https://docs.cloudfoundry.org/deploying/common/cc-blobstore-config.html#fog-aws-iam" target="_blank">https://docs.cloudfoundry.org/deploying/common/cc-blobstore-config.html#fog-aws-iam</a>.
    </p></li><li class="step "><p>
     Set the following in your <code class="filename">kubecf-config-values.yaml</code> file and replace the
     example values.
    </p><div class="verbatim-wrap"><pre class="screen">features:
  blobstore:
    provider: s3
    s3:
      aws_region: <em class="replaceable ">"us-east-1"</em>
      blobstore_access_key_id:  <em class="replaceable ">AWS-ACCESS-KEY-ID</em>
      blobstore_secret_access_key: <em class="replaceable ">AWS-SECRET-ACCESS-KEY&gt;</em>
      # User provided value for the blobstore admin password.
      blobstore_admin_users_password: <em class="replaceable ">PASSWORD</em>
      # The following values are used as S3 bucket names. The buckets are automatically created if not present.
      app_package_directory_key: <em class="replaceable ">APP-BUCKET-NAME</em>
      buildpack_directory_key: <em class="replaceable ">BUILDPACK-BUCKET-NAME</em>
      droplet_directory_key: <em class="replaceable ">DROPLET-BUCKET-NAME</em>
      resource_directory_key: <em class="replaceable ">RESOURCE-BUCKET-NAME</em></pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-eks-external-database"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  External Database
 </span> <a title="Permalink" class="permalink" href="#sec-cap-eks-external-database">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-external-database</li></ul></div></div></div></div><p>
  SUSE Cloud Application Platform can be configured to use an external database system, such as a
  data service offered by a cloud service provider or an existing high
  availability database server. In a default deployment, an internal single
  availability database is used.
 </p><p>
  To configure your deployment to use an external database, please follow the
  instructions below.
 </p><p>
  The current SUSE Cloud Application Platform release is compatible with the following types and
  versions of external databases:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    MySQL 5.7
   </p></li></ul></div><div class="sect2 " id="id-1.3.4.6.14.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.14.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   This section describes how to enable and configure your deployment to connect
   to an external database. The configuration options are specified through
   Helm values inside the <code class="filename">kubecf-config-values.yaml</code>. The
   deployment and configuration of the external database itself is the
   responsibility of the operator and beyond the scope of this documentation. It
   is assumed the external database has been deployed and accessible.
  </p><div id="id-1.3.4.6.14.6.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Configuration during Initial Install Only</h6><p>
    Configuration of SUSE Cloud Application Platform to use an external database
    <span class="bold"><strong>must</strong></span> be done during the initial
    installation and cannot be changed afterwards.
   </p></div><p>
    All the databases listed in the config snippet below need to exist before
    installing KubeCF. One way of doing that is manually running
    <code class="literal">CREATE DATABASE IF NOT EXISTS
    <em class="replaceable ">database-name</em></code> for each database.
  </p><p>
   The following snippet of the <code class="filename">kubecf-config-values.yaml</code>
   contains an example of an external database configuration.
  </p><div class="verbatim-wrap"><pre class="screen">features:
  embedded_database:
    enabled: false
  external_database:
    enabled: true
    require_ssl: false
    ca_cert: ~
    type: mysql
    host: <em class="replaceable ">hostname</em>
    port: <em class="replaceable ">3306</em>
    databases:
      uaa:
        name: uaa
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      cc:
        name: cloud_controller
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      bbs:
        name: diego
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      routing_api:
        name: routing-api
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      policy_server:
        name: network_policy
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      silk_controller:
        name: network_connectivity
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      locket: 
        name: locket
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      credhub:        
        name: credhub
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em></pre></div></div></div><div class="sect1 " id="sec-cap-addrepo-eks"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add the Kubernetes Charts Repository</span> <a title="Permalink" class="permalink" href="#sec-cap-addrepo-eks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-addrepo-eks</li></ul></div></div></div></div><p>
   Download the SUSE Kubernetes charts repository with Helm:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm repo add <em class="replaceable ">suse</em> https://kubernetes-charts.suse.com/</pre></div><p>
   You may replace the example <em class="replaceable ">suse</em> name with any
   name. Verify with <code class="command">helm</code>:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm repo list
NAME            URL
stable          https://kubernetes-charts.storage.googleapis.com
local           http://127.0.0.1:8879/charts
suse            https://kubernetes-charts.suse.com/</pre></div><p>
   List your chart names, as you will need these for some operations:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm search repo <em class="replaceable ">suse</em>
NAME                            CHART VERSION        APP VERSION    DESCRIPTION
suse/cf-operator                6.1.17+0.gec409fd7    2.1.0          A Helm chart for cf-operator, the k8s operator ....
suse/console                    4.2.0                2.1.0          A Helm chart for deploying SUSE Stratos Console
suse/kubecf                     2.5.8                2.1.0          A Helm chart for KubeCF
suse/metrics                    1.3.0                2.1.0          A Helm chart for Stratos Metrics
suse/minibroker                 1.1.0                               A minibroker for your minikube
suse/nginx-ingress              0.28.4               0.15.0         An nginx Ingress controller that uses ConfigMap to store ...
...</pre></div></div><div class="sect1 " id="sec-cap-cap-on-eks"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#sec-cap-cap-on-eks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-cap-on-eks</li></ul></div></div></div></div><p>
   This section describes how to deploy SUSE Cloud Application Platform on Amazon EKS.
  </p><div id="id-1.3.4.6.16.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: KubeCF and cf-operator versions</h6><p>
   KubeCF and cf-operator interoperate closely. Before you deploy a
   specific version combination, make sure they were confirmed to work. For more
   information see <a class="xref" href="#cha-cap-depl-notes-releases" title="3.4. Releases and Associated Versions">Section 3.4, “Releases and Associated Versions”</a>.
  </p></div><div class="sect2 " id="sec-cap-eks-deploy-operator"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Deploy the Operator
 </span> <a title="Permalink" class="permalink" href="#sec-cap-eks-deploy-operator">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-deploy-operator</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    First, create the namespace for the operator.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">cf-operator</em></pre></div></li><li class="step "><p>
    Install the operator.
   </p><p>
    The value of <code class="literal">global.operator.watchNamespace</code> indicates the
    namespace the operator will monitor for a KubeCF deployment. This
    namespace should be separate from the namespace used by the operator. In
    this example, this means KubeCF will be deployed into a namespace called
    <code class="literal">kubecf</code>.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">cf-operator</em> suse/cf-operator \
--namespace <em class="replaceable ">cf-operator</em> \
--set "global.singleNamespace.name=<em class="replaceable ">kubecf</em>" \
--version 6.1.17+0.gec409fd7</pre></div></li><li class="step "><p>
    Wait until cf-operator is successfully deployed before proceeding. Monitor
    the status of your cf-operator deployment using the
    <code class="command">watch</code> command.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">cf-operator</em>'</pre></div></li></ol></div></div></div><div class="sect2 " id="sec-cap-eks-deploy-kubecf"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy KubeCF</span> <a title="Permalink" class="permalink" href="#sec-cap-eks-deploy-kubecf">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-deploy-kubecf</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
   Use Helm to deploy KubeCF.
  </p><p>
   Note that you <span class="bold"><strong>do not</strong></span> need to manually create
   the namespace for KubeCF.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">kubecf</em> suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values <em class="replaceable ">kubecf-config-values.yaml</em> \
--version 2.5.8</pre></div></li><li class="step "><p>
  Monitor the status of your KubeCF deployment using the
  <code class="command">watch</code> command.
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace kubecf'</pre></div></li><li class="step "><p>
   Find the value of <code class="literal">EXTERNAL-IP</code> for each of the public
   services.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> router-public

<code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> tcp-router-public

<code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> ssh-proxy-public</pre></div></li><li class="step "><p>
      Create DNS CNAME records for the public services.
     </p><ol type="a" class="substeps "><li class="step "><p>
    For the <code class="literal">router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">*.&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">tcp-router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">tcp.&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">ssh-proxy-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">ssh.&lt;system_domain&gt;</code>.
   </p></li></ol></li><li class="step "><p>
      When all pods are fully ready, verify your deployment. See <a class="xref" href="#sec-pod-status" title="3.2. Status of Pods during Deployment">Section 3.2, “Status of Pods during Deployment”</a> for more information.
     </p><p>
  Connect and authenticate to the cluster.
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation "https://api.&lt;system_domain&gt;"

# Use the cf_admin_password set in kubecf-config-values.yaml
<code class="prompt user">tux &gt; </code>cf auth admin <em class="replaceable ">changeme</em></pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-eks-ldap"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  LDAP Integration
 </span> <a title="Permalink" class="permalink" href="#sec-cap-eks-ldap">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-ldap</li></ul></div></div></div></div><p>
  SUSE Cloud Application Platform can be integrated with
  <a class="link" href="https://docs.cloudfoundry.org/uaa/identity-providers.html" target="_blank">identity
  providers</a> to help manage authentication of users. Integrating
  SUSE Cloud Application Platform with other identity providers is optional. In a default
  deployment, a built-in UAA server (<a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-overview.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-overview.html</a>)
  is used to manage user accounts and authentication.
 </p><p>
  The Lightweight Directory Access Protocol (LDAP) is an example of an identity provider that
  Cloud Application Platform integrates with. This section describes the necessary components and
  steps in order to configure the integration. See
  <a class="link" href="https://github.com/cloudfoundry/uaa/blob/master/docs/UAA-LDAP.md" target="_blank">User
  Account and Authentication LDAP Integration</a> for more information. 
 </p><div class="sect2 " id="id-1.3.4.6.17.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.17.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The following prerequisites are required in order to complete an LDAP
   integration with SUSE Cloud Application Platform.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">uaac</code>, the Cloud Foundry <code class="literal">uaa</code> command line client
 (UAAC). See
 <a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-user-management.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-user-management.html</a>
 for more information and installation instructions.
</p><p>
 On SUSE Linux Enterprise systems, ensure the <code class="literal">ruby-devel</code> and <code class="literal">gcc-c++</code>
 packages have been installed before installing the <code class="literal">cf-uaac</code> gem.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install ruby-devel gcc-c++</pre></div></li><li class="listitem "><p>
     An LDAP server and the credentials for a user/service account with
     permissions to search the directory.
    </p></li></ul></div></div><div class="sect2 " id="id-1.3.4.6.17.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.14.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example LDAP Integration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.6.17.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Run the following commands to complete the integration of your Cloud Application Platform
   deployment and LDAP server.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
 Use UAAC to target your <code class="literal">uaa</code> server.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac target --skip-ssl-validation <em class="replaceable ">https://uaa.example.com</em></pre></div></li><li class="step "><p>
 Authenticate to the <code class="literal">uaa</code> server as
 <code class="literal">admin</code> using the
 <code class="literal">uaa_admin_client_secret</code> set in your
 <code class="filename">kubecf-config-values.yaml</code> file.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac token client get admin --secret <em class="replaceable ">PASSWORD</em></pre></div></li><li class="step "><p>
     List the current identity providers.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers --insecure</pre></div></li><li class="step "><p>
     From the output, locate the default <code class="literal">ldap</code> entry and take
     note of its <code class="literal">id</code>. The entry will be similar to the
     following.
    </p><div class="verbatim-wrap"><pre class="screen">{
  "type": "ldap",
  "config": "{\"emailDomain\":null,\"additionalConfiguration\":null,\"providerDescription\":null,\"externalGroupsWhitelist\":[],\"attributeMappings\":{},\"addShadowUserOnLogin\":true,\"storeCustomAttributes\":true,\"ldapProfileFile\":\"ldap/ldap-search-and-bind.xml\",\"baseUrl\":\"ldap://localhost:389/\",\"referral\":null,\"skipSSLVerification\":false,\"userDNPattern\":null,\"userDNPatternDelimiter\":null,\"bindUserDn\":\"cn=admin,dc=test,dc=com\",\"userSearchBase\":\"dc=test,dc=com\",\"userSearchFilter\":\"cn={0}\",\"passwordAttributeName\":null,\"passwordEncoder\":null,\"localPasswordCompare\":null,\"mailAttributeName\":\"mail\",\"mailSubstitute\":null,\"mailSubstituteOverridesLdap\":false,\"ldapGroupFile\":null,\"groupSearchBase\":null,\"groupSearchFilter\":null,\"groupsIgnorePartialResults\":null,\"autoAddGroups\":true,\"groupSearchSubTree\":true,\"maxGroupSearchDepth\":10,\"groupRoleAttribute\":null,\"tlsConfiguration\":\"none\"}",
  "id": "53gc6671-2996-407k-b085-2346e216a1p0",
  "originKey": "ldap",
  "name": "UAA LDAP Provider",
  "version": 3,
  "created": 946684800000,
  "last_modified": 1602208214000,
  "active": false,
  "identityZoneId": "uaa"
},</pre></div></li><li class="step "><p>
     Delete the default <code class="literal">ldap</code> identity provider. If the
     default entry is not removed, adding another identity provider of type
     <code class="literal">ldap</code> will result in a <code class="literal">409 Conflict</code>
     response. Replace the example <code class="literal">id</code> with one found in the
     previous step.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers/<em class="replaceable ">53gc6671-2996-407k-b085-2346e216a1p0</em> \
    --request DELETE \
    --insecure</pre></div></li><li class="step "><p>
     Create your own LDAP identity provider. A <code class="literal">201 Created</code>
     response will be returned when the identity provider is successfully
     created. See the
     <a class="link" href="http://docs.cloudfoundry.org/api/uaa/version/4.21.0/index.html#ldap" target="_blank">UAA
     API Reference</a> and
     <a class="link" href="https://github.com/cloudfoundry/uaa/blob/4.21.0/docs/UAA-LDAP.md" target="_blank">Cloud Foundry
     UAA-LDAP Documentation</a>for information regarding the request
     parameters and additional options available to configure your identity
     provider.
    </p><p>
     The following is an example of a <code class="literal">uaac curl</code> command and
     its request parameters used to create an identity provider. Specify the
     parameters according to your LDAP server's credentials and directory
     structure. Ensure the user specifed in the <code class="literal">bindUserDn</code>
     has permissions to search the directory.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers?rawConfig=true \
    --request POST \
    --insecure \
    --header 'Content-Type: application/json' \
    --data '{
  "type" : "ldap",
  "config" : {
    "ldapProfileFile" : "ldap/ldap-search-and-bind.xml",
    "baseUrl" : "<em class="replaceable ">ldap://ldap.example.com:389</em>",
    "bindUserDn" : "<em class="replaceable ">cn=admin,dc=example,dc=com</em>",
    "bindPassword" : "<em class="replaceable ">password</em>",
    "userSearchBase" : "<em class="replaceable ">dc=example,dc=com</em>",
    "userSearchFilter" : "<em class="replaceable ">uid</em>={0}",
    "ldapGroupFile" : "ldap/ldap-groups-map-to-scopes.xml",
    "groupSearchBase" : "<em class="replaceable ">dc=example,dc=com</em>",
    "groupSearchFilter" : "<em class="replaceable ">member</em>={0}"
  },
  "originKey" : "ldap",
  "name" : "<em class="replaceable ">My LDAP Server</em>",
  "active" : true
  }'</pre></div></li><li class="step "><p>
     Verify the LDAP identify provider has been created. The output should now
     contain an entry for the <code class="literal">ldap</code> type you created.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers --insecure</pre></div></li><li class="step "><p>
     Use the cf CLI to target your SUSE Cloud Application Platform deployment.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation https://api.example.com</pre></div></li><li class="step "><p>
     Log in as an administrator.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login
API endpoint: https://api.example.com

Email&gt; admin

Password&gt;
Authenticating...
OK</pre></div></li><li class="step "><p>
     Create users associated with your LDAP identity provider.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-user <em class="replaceable ">username</em> --origin ldap
Creating user username...
OK

TIP: Assign roles with 'cf set-org-role' and 'cf set-space-role'.</pre></div></li><li class="step "><p>
     Assign the user a role. Roles define the permissions a user has for a
     given org or space and a user can be assigned multiple roles. See
     <a class="link" href="https://docs.cloudfoundry.org/concepts/roles.html" target="_blank">Orgs,
     Spaces, Roles, and Permissions</a> for available roles and their
     corresponding permissions. The following example assumes that an org named
     <em class="replaceable ">Org</em> and a space named
     <em class="replaceable ">Space</em> have already been created.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf set-space-role <em class="replaceable ">username</em> <em class="replaceable ">Org</em> <em class="replaceable ">Space</em> <em class="replaceable ">SpaceDeveloper</em>
Assigning role RoleSpaceDeveloper to user username in org Org / space Space as admin...
OK
<code class="prompt user">tux &gt; </code>cf set-org-role <em class="replaceable ">username</em> Org OrgManager
Assigning role OrgManager to user username in org Org as admin...
OK</pre></div></li><li class="step "><p>
     Verify the user can log into your SUSE Cloud Application Platform deployment using their
     associated LDAP server credentials.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login
API endpoint: https://api.example.com

Email&gt; username

Password&gt;
Authenticating...
OK



API endpoint:   https://api.example.com (API version: 2.115.0)
User:           username@ldap.example.com</pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-eks-add-capacity"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Expanding Capacity of a Cloud Application Platform Deployment on Amazon EKS</span> <a title="Permalink" class="permalink" href="#sec-cap-eks-add-capacity">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eks.xml</li><li><span class="ds-label">ID: </span>sec-cap-eks-add-capacity</li></ul></div></div></div></div><p>
   If the current capacity of your Cloud Application Platform deployment is insufficient for your
   workloads, you can expand the capacity using the procedure in this section.
  </p><p>
   These instructions assume you have followed the procedure in
   <a class="xref" href="#cha-cap-depl-eks" title="Chapter 6. Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)">Chapter 6, <em>Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</em></a> and have a running Cloud Application Platform deployment on
   Amazon EKS.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Get the current number of Kubernetes nodes in the cluster.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>eksctl get nodegroup --name <em class="replaceable ">standard-workers</em> \
--cluster <em class="replaceable ">kubecf</em> \
--region <em class="replaceable ">us-east-2</em></pre></div></li><li class="step "><p>
     Scale the nodegroup to the desired node count.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>eksctl scale nodegroup --name <em class="replaceable ">standard-workers</em> \
--cluster <em class="replaceable ">kubecf</em> \
--nodes <em class="replaceable ">4</em> \
--region <em class="replaceable ">us-east-2</em></pre></div></li><li class="step "><p>
     Verify the new nodes are in a <code class="literal">Ready</code> state before
proceeding.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get nodes</pre></div></li><li class="step "><p>
     Add or update the following in your
     <code class="filename">kubecf-config-values.yaml</code> file to increase the number of
     <code class="literal">diego-cell</code> in your Cloud Application Platform deployment. Replace the
     example value with the number required by your workflow.
    </p><div class="verbatim-wrap"><pre class="screen">sizing:
  diego_cell:
    instances: <em class="replaceable ">5</em></pre></div></li><li class="step "><p>
     Perform a <code class="command">helm upgrade</code> to apply the change.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade kubecf suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values kubecf-config-values.yaml \
--version 2.5.8</pre></div></li><li class="step "><p>
     Monitor progress of the additional <code class="literal">diego-cell</code> pods:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace
kubecf'</pre></div></li></ol></div></div></div></div><div class="chapter " id="cha-cap-depl-gke"><div class="titlepage"><div><div><h2 class="title"><span class="number">7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-gke">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-prereqs-gke"><span class="number">7.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-gke-cluster"><span class="number">7.2 </span><span class="name">Creating a GKE cluster</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-kubeconfig"><span class="number">7.3 </span><span class="name">Get <code class="literal">kubeconfig</code> File</span></a></span></dt><dt><span class="sect1"><a href="#id-1.3.4.7.7"><span class="number">7.4 </span><span class="name">Install the Helm Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-storage"><span class="number">7.5 </span><span class="name">
  Storage Class
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-config"><span class="number">7.6 </span><span class="name">Deployment Configuration</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-certificates"><span class="number">7.7 </span><span class="name">
  Certificates
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-ingress"><span class="number">7.8 </span><span class="name">
  Using an Ingress Controller
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-affinity"><span class="number">7.9 </span><span class="name">
  Affinity and Anti-affinity
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-high-availability"><span class="number">7.10 </span><span class="name">
  High Availability
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-external-blobstore"><span class="number">7.11 </span><span class="name">
  External Blobstore
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-external-database"><span class="number">7.12 </span><span class="name">
  External Database
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-addrepo-gke"><span class="number">7.13 </span><span class="name">Add the Kubernetes charts repository</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-cap-on-gke"><span class="number">7.14 </span><span class="name">Deploying SUSE Cloud Application Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-ldap"><span class="number">7.15 </span><span class="name">
  LDAP Integration
 </span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-gke-add-capacity"><span class="number">7.16 </span><span class="name">Expanding Capacity of a Cloud Application Platform Deployment on Google GKE</span></a></span></dt></dl></div></div><div id="id-1.3.4.7.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        <a class="link" href="https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2.0/" target="_blank">
        SUSE Cloud Application Platform Release Notes</a>
      </p></li><li class="listitem "><p>
        <a class="xref" href="#cha-cap-depl-notes" title="Chapter 3. Deployment and Administration Notes">Chapter 3, <em>Deployment and Administration Notes</em></a>
      </p></li></ul></div></div><p>
  SUSE Cloud Application Platform supports deployment on Google Kubernetes Engine (GKE). This chapter describes the steps
  to prepare a SUSE Cloud Application Platform deployment on GKE using its integrated network load balancers. See
  <a class="link" href="https://cloud.google.com/kubernetes-engine/" target="_blank">https://cloud.google.com/kubernetes-engine/</a>
  for more information on GKE.
 </p><div class="sect1 " id="sec-cap-prereqs-gke"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#sec-cap-prereqs-gke">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-prereqs-gke</li></ul></div></div></div></div><p>
   The following are required to deploy and use SUSE Cloud Application Platform on GKE:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     A Google Cloud Platform (GCP) user account or a service account with the
     following IAM roles. If you do not have an account, visit
     <a class="link" href="https://console.cloud.google.com/" target="_blank">https://console.cloud.google.com/</a> to create one.
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       <code class="literal">compute.admin</code>. For details regarding this role, refer to
       <a class="link" href="https://cloud.google.com/iam/docs/understanding-roles#compute-engine-roles" target="_blank">https://cloud.google.com/iam/docs/understanding-roles#compute-engine-roles</a>.
      </p></li><li class="listitem "><p>
       <code class="literal">container.admin</code>. For details regarding this role, refer to
       <a class="link" href="https://cloud.google.com/kubernetes-engine/docs/how-to/iam#predefined" target="_blank">https://cloud.google.com/kubernetes-engine/docs/how-to/iam#predefined</a>.
      </p></li><li class="listitem "><p>
       <code class="literal">iam.serviceAccountUser</code>. For details regarding this role, refer to
       <a class="link" href="https://cloud.google.com/kubernetes-engine/docs/how-to/iam#primitive" target="_blank">https://cloud.google.com/kubernetes-engine/docs/how-to/iam#primitive</a>.
      </p></li></ul></div></li><li class="listitem "><p>
     Access to a GCP project with the Kubernetes Engine API enabled. If a
     project needs to be created, refer to
     <a class="link" href="https://cloud.google.com/apis/docs/getting-started#creating_a_google_project" target="_blank">https://cloud.google.com/apis/docs/getting-started#creating_a_google_project</a>.
     To enable access to the API, refer to
     <a class="link" href="https://cloud.google.com/apis/docs/getting-started#enabling_apis" target="_blank">https://cloud.google.com/apis/docs/getting-started#enabling_apis</a>.
    </p></li><li class="listitem "><p>
     <code class="command">gcloud</code>, the primary command line interface to Google
     Cloud Platform. See
     <a class="link" href="https://cloud.google.com/sdk/gcloud/" target="_blank">https://cloud.google.com/sdk/gcloud/</a> for more
     information and installation instructions.
    </p></li><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">kubectl</code>, the Kubernetes command line tool. For more
 information, refer to
 <a class="link" href="https://kubernetes.io/docs/reference/kubectl/overview/" target="_blank">https://kubernetes.io/docs/reference/kubectl/overview/</a>.
</p><p>
 For SLE 12 SP3 or 15 SP1 systems, install the package
 <span class="package ">kubernetes-client</span> from the <span class="emphasis"><em>Public Cloud</em></span>
 module.
</p><p>
 For other systems, follow the instructions at
 <a class="link" href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a>.
</p></li><li class="listitem "><p>
 <code class="command">jq</code>, a command line JSON processor. See
 <a class="link" href="https://stedolan.github.io/jq/" target="_blank">https://stedolan.github.io/jq/</a> for more information and
 installation instructions.
</p></li><li class="listitem "><p>
 <code class="command">curl</code>, the Client URL (cURL) command line tool.
</p></li><li class="listitem "><p>
 <code class="command">sed</code>, the stream editor.
</p></li></ul></div></div><div class="sect1 " id="sec-cap-create-gke-cluster"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a GKE cluster</span> <a title="Permalink" class="permalink" href="#sec-cap-create-gke-cluster">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-create-gke-cluster</li></ul></div></div></div></div><p>
   In order to deploy SUSE Cloud Application Platform, create a cluster that:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Is a <code class="literal">Zonal</code> or <code class="literal">Regional</code> type. Do not
     use a <code class="literal">Alpha</code> cluster.
    </p></li><li class="listitem "><p>
     Uses <code class="literal">Ubuntu</code> as the host operating system. If using the
     <code class="literal">gcloud</code> CLI, include <code class="command">--image-type=UBUNTU</code>
     during the cluster creation.
    </p></li><li class="listitem "><p>
     Allows access to all Cloud APIs (in order for storage to work correctly).
	    
    </p></li><li class="listitem "><p>
     Has at least 3 nodes of machine type <code class="literal">n1-standard-4</code>. If using the
     <code class="literal">gcloud</code> CLI, include <code class="command">--machine-type=n1-standard-4</code>
     and <code class="command">--num-nodes=3</code> during the cluster creation. For details, see
     <a class="link" href="https://cloud.google.com/compute/docs/machine-types#standard_machine_types" target="_blank">https://cloud.google.com/compute/docs/machine-types#standard_machine_types</a>.
    </p></li><li class="listitem "><p>
     Has at least 100 GB local storage per node.
    </p></li><li class="listitem "><p>
     (Optional) Uses preemptible nodes to keep costs low. For details, see
     <a class="link" href="https://cloud.google.com/kubernetes-engine/docs/how-to/preemptible-vms" target="_blank">https://cloud.google.com/kubernetes-engine/docs/how-to/preemptible-vms</a>.
    </p></li></ul></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Set a name for your cluster:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>export CLUSTER_NAME=<em class="replaceable ">"cap"</em></pre></div></li><li class="step "><p>
     Set the zone for your cluster:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>export CLUSTER_ZONE=<em class="replaceable ">"us-west1-a"</em></pre></div></li><li class="step "><p>
     Set the number of nodes for your cluster:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>export NODE_COUNT=3</pre></div></li><li class="step "><p>
     Create the cluster:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>gcloud container clusters create ${CLUSTER_NAME} \
--image-type=UBUNTU \
--machine-type=n1-standard-4 \
--zone ${CLUSTER_ZONE} \
--num-nodes=$NODE_COUNT \
--no-enable-basic-auth \
--no-issue-client-certificate \
--no-enable-autoupgrade</pre></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       Specify the <code class="command">--no-enable-basic-auth</code> and
       <code class="command">--no-issue-client-certificate</code> flags so that
       <code class="command">kubectl</code> does not use basic or client certificate
       authentication, but uses OAuth Bearer Tokens instead. Configure the
       flags to suit your desired authentication mechanism.
      </p></li><li class="listitem "><p>
       Specify <code class="command">--no-enable-autoupgrade</code> to disable
       automatic upgrades.
      </p></li><li class="listitem "><p>
       Disable legacy metadata server endpoints using
       <code class="command">--metadata disable-legacy-endpoints=true</code> as a best
       practice as indicated in
       <a class="link" href="https://cloud.google.com/compute/docs/storing-retrieving-metadata#default" target="_blank">https://cloud.google.com/compute/docs/storing-retrieving-metadata#default</a>.
      </p></li></ul></div></li></ol></div></div></div><div class="sect1 " id="sec-cap-gke-kubeconfig"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Get <code class="literal">kubeconfig</code> File</span> <a title="Permalink" class="permalink" href="#sec-cap-gke-kubeconfig">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-kubeconfig</li></ul></div></div></div></div><p>
   Get the <code class="literal">kubeconfig</code> file for your cluster.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>gcloud container clusters get-credentials --zone ${CLUSTER_ZONE:?required} ${CLUSTER_NAME:?required} --project <em class="replaceable ">example-project</em></pre></div></div><div class="sect1 " id="id-1.3.4.7.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the Helm Client</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Helm is a Kubernetes package manager used to install and manage SUSE Cloud Application Platform.
   This requires installing the Helm client, <code class="command">helm</code>, on your
   remote management workstation. Cloud Application Platform requires Helm 3.
   For more information regarding Helm, refer to the documentation at
   <a class="link" href="https://helm.sh/docs/" target="_blank">https://helm.sh/docs/</a>.
  </p><div id="id-1.3.4.7.7.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Make sure that you are installing and using Helm 3 and not Helm 2.</p></div><p>
   If your remote management workstation has the SUSE CaaS Platform package repository,
   install <code class="command">helm</code> by running
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install helm3
<code class="prompt user">tux &gt; </code>sudo update-alternatives --set helm /usr/bin/helm3</pre></div><p>
   Otherwise, <code class="command">helm</code> can be installed  by referring to the
   documentation at <a class="link" href="https://helm.sh/docs/intro/install/" target="_blank">https://helm.sh/docs/intro/install/</a>.
  </p></div><div class="sect1 " id="sec-cap-gke-storage"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Storage Class
 </span> <a title="Permalink" class="permalink" href="#sec-cap-gke-storage">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-storage</li></ul></div></div></div></div><p>
  In some SUSE Cloud Application Platform instance groups, such as <code class="literal">bits</code>,
  <code class="literal">database</code>, <code class="literal">diego-cell</code>, and
  <code class="literal">singleton-blobstore</code> require a storage class for persistent
  data. To learn more about storage classes, see
  <a class="link" href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank">https://kubernetes.io/docs/concepts/storage/storage-classes/</a>. 
 </p><p>
  By default, SUSE Cloud Application Platform will use the cluster's default storage class. 
  To designate or change the default storage class, refer to
  <a class="link" href="https://kubernetes.io/docs/tasks/administer-cluster/change-default-storage-class/" target="_blank">https://kubernetes.io/docs/tasks/administer-cluster/change-default-storage-class/</a>
  for instructions.
 </p><p>
  In some cases, the default and predefined storage classes may not be suitable
  for certain workloads. If this is the case, operators can define their own
  custom StorageClass resource according to the specification at 
  <a class="link" href="https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource" target="_blank">https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource</a>.
 </p><p>
  With the storage class defined, run:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create --filename <em class="replaceable ">my-storage-class.yaml</em></pre></div><p>
  Then verify the storage class is available by running
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get storageclass</pre></div><p>
  If operators do no want to use the default storage class or one does not
  exist, a storage class <span class="bold"><strong>must</strong></span> be specified by
  setting the <code class="literal">kube.storage_class</code> value in your
  <code class="filename">kubecf-config-values.yaml</code> configuration file to the name of the storage class as seen
  in this example. 
 </p><div class="verbatim-wrap"><pre class="screen">kube:
  storage_class: <em class="replaceable ">my-storage-class</em></pre></div></div><div class="sect1 " id="sec-cap-gke-config"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment Configuration</span> <a title="Permalink" class="permalink" href="#sec-cap-gke-config">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-config</li></ul></div></div></div></div><p>
   The following file, <code class="filename">kubecf-config-values.yaml</code>, provides a
   minimal example deployment configuration.
  </p><div id="id-1.3.4.7.9.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: kubecf-config-values.yaml changes</h6><p>
    The format of the <code class="filename">kubecf-config-values.yaml</code> file has been restructured completely in
    Cloud Application Platform 2.x. Do not re-use the Cloud Application Platform 1.x version of the file. Instead, see the
    default file in the appendix in
    <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a> and pick parameters according to
    your needs.
  </p></div><div id="id-1.3.4.7.9.4" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: Supported Domains</h6><p>
   When selecting a domain, SUSE Cloud Application Platform expects <code class="literal">system_domain</code> to
   be either a subdomain or a root domain. Setting <code class="literal">system_domain</code> to
   a top-level domain, such as <code class="literal">suse</code>, is not supported.
  </p></div><div class="verbatim-wrap"><pre class="screen">### Example deployment configuration file
### kubecf-config-values.yaml

system_domain: example.com

credentials:
  cf_admin_password: <em class="replaceable ">changeme</em>
  uaa_admin_client_secret: <em class="replaceable ">alsochangeme</em>

### This block is required due to the log-cache issue described below
properties:
  log-cache:
    log-cache:
      memory_limit_percent: 3

### This block is required due to the log-cache issue described below
###
### The value for <code class="literal">key</code> may need to be replaced depending on
### how notes in your cluster are labeled
###
### The value(s) listed under <code class="literal">values</code> may need to be
### replaced depending on how notes in your cluster are labeled
operations:
  inline:
  - type: replace
    path: /instance_groups/name=log-cache/env?/bosh/agent/settings/affinity
    value:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: <em class="replaceable ">kubernetes.io/hostname</em>
              operator: In
              values:
              - <em class="replaceable ">LABEL_VALUE_OF_NODE</em></pre></div><div class="sect2 " id="id-1.3.4.7.9.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Log-cache Memory Allocation</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.9.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  The log-cache component currently has a memory allocation issue where the node
  memory available is reported instead of the one assigned to the container under
  cgroups. In such a situation, log-cache would start allocating memory based on
  these values, causing a varying range of issues (OOMKills, performance
  degradation, etc.). To address this issue, node affinity must be used to tie
  log-cache to nodes of a uniform size, and then declaring the cache percentage
  based on that number. A limit of 3% has been identified as sufficient.
 </p><p>
  In the node affinity configuration, the values for <code class="literal">key</code> and
  <code class="literal">values</code> may need to be changed depending on how notes in your
  cluster are labeled. For more information on labels, see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels</a>.
 </p></div><div class="sect2 " id="id-1.3.4.7.9.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Diego Cell Affinities and Tainted Nodes</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.9.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  Note that the <code class="literal">diego-cell</code> pods used by the Diego standard
  scheduler are
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    privileged
   </p></li><li class="listitem "><p>
    use large local emptyDir volumes (i.e. require node disk storage)
   </p></li><li class="listitem "><p>
    and set kernel parameters on the node
   </p></li></ul></div><p>
  These things all mean that these pods should not live next to other Kubernetes
  workloads. They should all be placed on their own
  <span class="bold"><strong>dedicated nodes</strong></span> instead where possible.
 </p><p>
  This can be done by setting affinities and tolerations, as explained in
the associated tutorial at <a class="link" href="https://kubecf.io/docs/deployment/affinities-and-tolerations/" target="_blank">https://kubecf.io/docs/deployment/affinities-and-tolerations/</a>.
 </p></div></div><div class="sect1 " id="sec-cap-gke-certificates"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Certificates
 </span> <a title="Permalink" class="permalink" href="#sec-cap-gke-certificates">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-certificates</li></ul></div></div></div></div><p>
  This section describes the process to secure traffic passing through your
  SUSE Cloud Application Platform deployment. This is achieved by using certificates to set up
  Transport Layer Security (TLS) for the router component. Providing
  certificates for the router traffic is optional. In a default deployment,
  without operator-provided certificates, generated certificates will be used.
 </p><div class="sect2 " id="id-1.3.4.7.10.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Certificate Characteristics</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.10.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Ensure the certificates you use have the following characteristics:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The certificate is encoded in the PEM format.
    </p></li><li class="listitem "><p>
     The certificate is signed by an external Certificate Authority (CA).
    </p></li><li class="listitem "><p>
     The certificate's Subject Alternative Names (SAN) include the domain
     <em class="replaceable ">*.example.com</em>, where <em class="replaceable ">example.com</em>
     is replaced with the <code class="literal">system_domain</code> in your
     <code class="filename">kubecf-config-values.yaml</code>.
    </p></li></ul></div></div><div class="sect2 " id="id-1.3.4.7.10.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.10.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The certificate used to secure your deployment is passed through the
   <code class="filename">kubecf-config-values.yaml</code> configuration file. To specify
   a certificate, set the value of the certificate and its corresponding private
   key using the <code class="literal">router.tls.crt</code> and
   <code class="literal">router.tls.key</code> Helm values in the
   <code class="literal">settings:</code> section.
  </p><div class="verbatim-wrap"><pre class="screen">settings:
  router:
    tls:
      crt: |
        -----BEGIN CERTIFICATE-----
        MIIEEjCCAfoCCQCWC4NErLzy3jANBgkqhkiG9w0BAQsFADBGMQswCQYDVQQGEwJD
        QTETMBEGA1UECAwKU29tZS1TdGF0ZTEOMAwGA1UECgwFTXlPcmcxEjAQBgNVBAMM
        CU15Q0Euc2l0ZTAeFw0xODA5MDYxNzA1MTRaFw0yMDAxMTkxNzA1MTRaMFAxCzAJ
        ...
        xtNNDwl2rnA+U0Q48uZIPSy6UzSmiNaP3PDR+cOak/mV8s1/7oUXM5ivqkz8pEJo
        M3KrIxZ7+MbdTvDOh8lQplvFTeGgjmUDd587Gs4JsormqOsGwKd1BLzQbGELryV9
        1usMOVbUuL8mSKVvgqhbz7vJlW1+zwmrpMV3qgTMoHoJWGx2n5g=
        -----END CERTIFICATE-----
      key: |
        -----BEGIN RSA PRIVATE KEY-----
        MIIEpAIBAAKCAQEAm4JMchGSqbZuqc4LdryJpX2HnarWPOW0hUkm60DL53f6ehPK
        T5Dtb2s+CoDX9A0iTjGZWRD7WwjpiiuXUcyszm8y9bJjP3sIcTnHWSgL/6Bb3KN5
        G5D8GHz7eMYkZBviFvygCqEs1hmfGCVNtgiTbAwgBTNsrmyx2NygnF5uy4KlkgwI
        ...
        GORpbQKBgQDB1/nLPjKxBqJmZ/JymBl6iBnhIgVkuUMuvmqES2nqqMI+r60EAKpX
        M5CD+pq71TuBtbo9hbjy5Buh0+QSIbJaNIOdJxU7idEf200+4anzdaipyCWXdZU+
        MPdJf40awgSWpGdiSv6hoj0AOm+lf4AsH6yAqw/eIHXNzhWLRvnqgA==
        -----END RSA PRIVATE KEY----</pre></div></div></div><div class="sect1 " id="sec-cap-gke-ingress"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Using an Ingress Controller
 </span> <a title="Permalink" class="permalink" href="#sec-cap-gke-ingress">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-ingress</li></ul></div></div></div></div><p>
  This section describes how to use an ingress controller
  (see <a class="link" href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank">https://kubernetes.io/docs/concepts/services-networking/ingress/</a>)
  to manage access to the services in the cluster. Using an ingress controller
  is optional. In a default deployment, load balancers are used instead.
 </p><p>
  Note that only the NGINX Ingress Controller has been verified to be
  compatible with Cloud Application Platform. Other Ingress controller alternatives may work, but
  compatibility with Cloud Application Platform is not supported.
 </p><div class="sect2 " id="id-1.3.4.7.11.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install and Configure the NGINX Ingress Controller</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.11.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Create a configuration file with the section below. The file is called
     <code class="filename">nginx-ingress.yaml</code> in this example. When using
     Eirini instead of Diego, replace the first line with
     <code class="literal">2222: "kubecf/eirinix-ssh-proxy:2222"</code>.
    </p><div class="verbatim-wrap"><pre class="screen">tcp:
  2222: "kubecf/scheduler:2222"
  20000: "kubecf/tcp-router:20000"
  20001: "kubecf/tcp-router:20001"
  20002: "kubecf/tcp-router:20002"
  20003: "kubecf/tcp-router:20003"
  20004: "kubecf/tcp-router:20004"
  20005: "kubecf/tcp-router:20005"
  20006: "kubecf/tcp-router:20006"
  20007: "kubecf/tcp-router:20007"
  20008: "kubecf/tcp-router:20008"</pre></div></li><li class="step "><p>
     Create the namespace.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">nginx-ingress</em></pre></div></li><li class="step "><p>
     Install the NGINX Ingress Controller.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">nginx-ingress</em> suse/nginx-ingress \
--namespace <em class="replaceable ">nginx-ingress</em> \
--values <em class="replaceable ">nginx-ingress.yaml</em></pre></div></li><li class="step "><p>
     Monitor the progess of the deployment:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">nginx-ingress</em>'</pre></div></li><li class="step "><p>
     After the deployment completes, the Ingress controller service will be deployed
     with either an external IP or a hostname. 
    </p><p>
     Find the external IP or hostname.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get services nginx-ingress-controller --namespace nginx-ingress</pre></div><p>
     You will get output similar to the following.
    </p><div class="verbatim-wrap"><pre class="screen">NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)
nginx-ingress-controller   LoadBalancer   <em class="replaceable ">10.63.248.70</em>   <em class="replaceable ">35.233.191.177</em>   80:30344/TCP,443:31386/TCP</pre></div></li><li class="step "><p>
     Set up DNS records corresponding to the controller service IP or hostname
     and map it to the <code class="literal">system_domain</code> defined in your
     <code class="filename">kubecf-config-values.yaml</code>.
    </p></li><li class="step "><p>
     Obtain a PEM formatted certificate that is associated with the
     <code class="literal">system_domain</code> defined in your <code class="filename">kubecf-config-values.yaml</code>
    </p></li><li class="step "><p>
     In your <code class="filename">kubecf-config-values.yaml</code> configuration file, enable the ingress feature and
     set the <code class="literal">tls.crt</code> and <code class="literal">tls.key</code> for the
     certificate from the previous step.
    </p><div class="verbatim-wrap"><pre class="screen">features:
  ingress:
    enabled: true
    tls:
      crt: |
        -----BEGIN CERTIFICATE-----
        MIIE8jCCAtqgAwIBAgIUT/Yu/Sv8AUl5zHXXEKCy5RKJqmYwDQYJKoZIhvcMOQMM
        [...]
        xC8x/+zB7XlvcRJRio6kk670+25ABP==
        -----END CERTIFICATE-----
      key: |
        -----BEGIN RSA PRIVATE KEY-----
        MIIE8jCCAtqgAwIBAgIUSI02lj2b2ImLy/zMrjNgW5d8EygwQSVJKoZIhvcYEGAW
        [...]
        to2WV7rPMb9W9fd2vVUXKKHTc+PiNg==
        -----END RSA PRIVATE KEY-----</pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-gke-affinity"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Affinity and Anti-affinity
 </span> <a title="Permalink" class="permalink" href="#sec-cap-gke-affinity">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-affinity</li></ul></div></div></div></div><div id="id-1.3.4.7.12.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
   This feature requires SUSE Cloud Application Platform 2.0.1 or newer.
  </p></div><p>
  Operators can set affinity/anti-affinity rules to restrict how the scheduler
  determines the placement of a given pod on a given node. This can be
  achieved through node affinity/anti-affinity, where placement is determined
  by node labels (see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity</a>),
  or pod affinity/anti-affinity, where pod placement is determined by labels
  on pods that are already running on the node (see
  <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity</a>). 
 </p><p>
  In SUSE Cloud Application Platform, a default configuration will have following
  affinity/anti-affinity rules already in place:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Instance groups have anti-affinity against themselves. This applies to all
    instance groups, including <code class="literal">database</code>, but not to the
    <code class="literal">bits</code>, <code class="literal">eirini</code>, and
    <code class="literal">eirini-extensions</code> subcharts.
   </p></li><li class="listitem "><p>
    The <code class="literal">diego-cell</code> and <code class="literal">router</code> instance
    groups have anti-affinity against each other.
   </p></li></ul></div><p>
  Note that to ensure an optimal spread of the pods across worker nodes we
  recommend running 5 or more worker nodes to satisfy both of the default
  anti-affinity constraints. An operator can also specify custom affinity rules
  via the
  <code class="literal">sizing.<em class="replaceable ">instance-group</em>.affinity</code>
  helm parameter and any affinity rules specified here will overwrite the
  default rule, not merge with it.
 </p><div class="sect2 " id="id-1.3.4.7.12.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring Rules</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.12.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   To add or override affinity/anti-affinity settings, add a
   <code class="literal">sizing.INSTANCE_GROUP.affinity</code> block to your
   <code class="filename">kubecf-config-values.yaml</code>. Repeat as necessary for each instance group where
   affinity/anti-affinity settings need to be applied. For information on
   the available fields and valid values within the <code class="literal">affinity:</code>
   block, see
   <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity</a>.
   Repeat as necessary for each instance group where affinity/anti-affinity
   settings need to be applied.
  </p><p>
   Example 1, node affinity.
  </p><p>
   Using this configuration, the Kubernetes scheduler would place both the
   <code class="literal">asactors</code> and <code class="literal">asapi</code> instance groups on a
   node with a label where the key is
   <code class="literal">topology.kubernetes.io/zone</code> and the value is
   <code class="literal">0</code>.
  </p><div class="verbatim-wrap"><pre class="screen">sizing:
   asactors:
     affinity:
       nodeAffinity:
         requiredDuringSchedulingIgnoredDuringExecution:
           nodeSelectorTerms:
           - matchExpressions:
             - key: topology.kubernetes.io/zone
               operator: In
               values:
               - 0
   asapi:
     affinity:
       nodeAffinity:
         requiredDuringSchedulingIgnoredDuringExecution:
           nodeSelectorTerms:
           - matchExpressions:
             - key: topology.kubernetes.io/zone
               operator: In
               values:
               - 0</pre></div><p>
   Example 2, pod anti-affinity.
  </p><div class="verbatim-wrap"><pre class="screen">sizing:
  api:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: quarks.cloudfoundry.org/quarks-statefulset-name
                operator: In
                values:
                - sample_group
            topologyKey: kubernetes.io/hostname
  database:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: quarks.cloudfoundry.org/quarks-statefulset-name
                operator: In
                values:
                - sample_group
            topologyKey: kubernetes.io/hostname</pre></div><p>
   Example 1 above uses <code class="literal">topology.kubernetes.io/zone</code> as its
   label, which is one of the standard labels that get attached to nodes by
   default. The list of standard labels can be found at
   <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels</a>. 
  </p><p>
   In addition to the standard labels, custom labels can be specified as in
   Example 2. To use custom labels, following the process described in this
   section <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector</a>.
  </p></div></div><div class="sect1 " id="sec-cap-gke-high-availability"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  High Availability
 </span> <a title="Permalink" class="permalink" href="#sec-cap-gke-high-availability">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-high-availability</li></ul></div></div></div></div><div class="sect2 " id="id-1.3.4.7.13.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring Cloud Application Platform for High Availability</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.13.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   High availability mode is optional. In a default deployment, SUSE Cloud Application Platform is
   deployed in single availability mode.
  </p><p>
   There are two ways to make your SUSE Cloud Application Platform deployment highly available.
   The first method is to set the <code class="literal">high_availability</code> parameter
   in your deployment configuration file to <code class="literal">true</code>. The second
   method is to create custom configuration files with your own sizing values.
  </p><div class="sect3 " id="id-1.3.4.7.13.2.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.10.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Finding Default and Allowable Sizing Values</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.13.2.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    The <code class="literal">sizing:</code> section in the Helm
    <code class="filename">values.yaml</code> files for the <code class="literal">kubecf</code> chart
    describes which roles can be scaled, and the scaling options for each role.
    You may use <code class="command">helm inspect</code> to read the
    <code class="literal">sizing:</code> section in the Helm chart:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm show suse/kubecf | less +/sizing:</pre></div><p>
    Another way is to use Perl to extract the information for each role from
    the <code class="literal">sizing:</code> section.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm inspect values suse/kubecf | \
perl -ne '/^sizing/..0 and do { print $.,":",$_ if /^ [a-z]/ || /high avail|scale|count/ }'</pre></div><p>
    The default <code class="filename">values.yaml</code> files are also included in
    this guide at <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a>.
   </p></div><div class="sect3 " id="id-1.3.4.7.13.2.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.10.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the <code class="literal">high_availability</code> Helm Property</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.13.2.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    One way to make your SUSE Cloud Application Platform deployment highly available is
    to use the <code class="literal">high_availability</code> Helm property. In your
    <code class="filename">kubecf-config-values.yaml</code>, set this property to
    <code class="literal">true</code>. This changes the size of all roles to the minimum
    required for a highly available deployment. Your configuration file,
    <code class="filename">kubecf-config-values.yaml</code>, should include the following.
   </p><div class="verbatim-wrap"><pre class="screen">high_availability: true</pre></div><div id="id-1.3.4.7.13.2.5.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Sizing Priority</h6><p>
   When sizing values are specified, it takes precedence over the <code class="literal">high_availability</code> property.
  </p></div></div><div class="sect3 " id="id-1.3.4.7.13.2.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.10.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Custom Sizing Configurations</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.13.2.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    Another method to make your SUSE Cloud Application Platform deployment highly available is           
    to explicitly configure the instance count of an instance group.
   </p><div id="id-1.3.4.7.13.2.6.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Sizing Priority</h6><p>
   When sizing values are specified, it takes precedence over the <code class="literal">high_availability</code> property.
  </p></div><p>
    To see the full list of configurable instance groups, refer to default
    KubeCF <code class="filename">values.yaml</code> file in the appendix at
    <a class="xref" href="#app-kubecf-values-yaml" title="A.1. Complete suse/kubecf values.yaml File">Section A.1, “Complete suse/kubecf values.yaml File”</a>.
   </p><p>
    The following is an example High Availability configuration. The example values are not meant to be
    copied, as these depend on your particular deployment and requirements.
   </p><div class="verbatim-wrap"><pre class="screen">sizing:
  adapter:
    instances: 2
  api:
    instances: 2
  asactors:
    instances: 2
  asapi:
    instances: 2
  asmetrics:
    instances: 2
  asnozzle:
    instances: 2
  auctioneer:
    instances: 2
  bits:
    instances: 2
  cc_worker:
    instances: 2
  credhub:
    instances: 2
  database:
    instances: 1
  diego_api:
    instances: 2
  diego_cell:
    instances: 2
  doppler:
    instances: 2
  eirini:
    instances: 3
  log_api:
    instances: 2
  nats:
    instances: 2
  router:
    instances: 2
  routing_api:
    instances: 2
  scheduler:
    instances: 2
  uaa:
    instances: 2
  tcp_router:
    instances: 2</pre></div></div></div></div><div class="sect1 " id="sec-cap-gke-external-blobstore"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  External Blobstore
 </span> <a title="Permalink" class="permalink" href="#sec-cap-gke-external-blobstore">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-external-blobstore</li></ul></div></div></div></div><p>
  Cloud Foundry Application Runtime (CFAR) uses a blobstore (see
  <a class="link" href="https://docs.cloudfoundry.org/concepts/cc-blobstore.html" target="_blank">https://docs.cloudfoundry.org/concepts/cc-blobstore.html</a>)
  to store the source code that developers push, stage, and run. This section
  explains how to configure an external blobstore for the Cloud Controller
  component of your SUSE Cloud Application Platform deployment. Using an external blobstore is
  optional. In a default deployment, an internal blobstore is used.
 </p><p>
  SUSE Cloud Application Platform relies on <code class="filename">ops files</code> (see
  <a class="link" href="https://github.com/cloudfoundry/cf-deployment/blob/master/operations/README.md" target="_blank">https://github.com/cloudfoundry/cf-deployment/blob/master/operations/README.md</a>)
  provided by cf-deployment (see <a class="link" href="https://github.com/cloudfoundry/cf-deployment" target="_blank">https://github.com/cloudfoundry/cf-deployment</a>)
  releases for external blobstore configurations. The default configuration for
  the blobstore is <code class="literal">singleton</code>.
 </p><div class="sect2 " id="id-1.3.4.7.14.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.14.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Currently SUSE Cloud Application Platform supports Amazon Simple Storage Service (Amazon S3,
   see <a class="link" href="https://aws.amazon.com/s3/" target="_blank">https://aws.amazon.com/s3/</a>) as an external blobstore. 
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Using the Amazon S3 service, create four buckets. A bucket should be
     created for app packages, buildpacks, droplets, and resources. For
     instructions on how to create Amazone S3 buckets, see
     <a class="link" href="https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html" target="_blank">https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html</a>.
    </p></li><li class="step "><p>
     To grant proper access to the create buckets, configure an additional IAM
     role as described in the first step of <a class="link" href="https://docs.cloudfoundry.org/deploying/common/cc-blobstore-config.html#fog-aws-iam" target="_blank">https://docs.cloudfoundry.org/deploying/common/cc-blobstore-config.html#fog-aws-iam</a>.
    </p></li><li class="step "><p>
     Set the following in your <code class="filename">kubecf-config-values.yaml</code> file and replace the
     example values.
    </p><div class="verbatim-wrap"><pre class="screen">features:
  blobstore:
    provider: s3
    s3:
      aws_region: <em class="replaceable ">"us-east-1"</em>
      blobstore_access_key_id:  <em class="replaceable ">AWS-ACCESS-KEY-ID</em>
      blobstore_secret_access_key: <em class="replaceable ">AWS-SECRET-ACCESS-KEY&gt;</em>
      # User provided value for the blobstore admin password.
      blobstore_admin_users_password: <em class="replaceable ">PASSWORD</em>
      # The following values are used as S3 bucket names. The buckets are automatically created if not present.
      app_package_directory_key: <em class="replaceable ">APP-BUCKET-NAME</em>
      buildpack_directory_key: <em class="replaceable ">BUILDPACK-BUCKET-NAME</em>
      droplet_directory_key: <em class="replaceable ">DROPLET-BUCKET-NAME</em>
      resource_directory_key: <em class="replaceable ">RESOURCE-BUCKET-NAME</em></pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-gke-external-database"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  External Database
 </span> <a title="Permalink" class="permalink" href="#sec-cap-gke-external-database">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-external-database</li></ul></div></div></div></div><p>
  SUSE Cloud Application Platform can be configured to use an external database system, such as a
  data service offered by a cloud service provider or an existing high
  availability database server. In a default deployment, an internal single
  availability database is used.
 </p><p>
  To configure your deployment to use an external database, please follow the
  instructions below.
 </p><p>
  The current SUSE Cloud Application Platform release is compatible with the following types and
  versions of external databases:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    MySQL 5.7
   </p></li></ul></div><div class="sect2 " id="id-1.3.4.7.15.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.15.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   This section describes how to enable and configure your deployment to connect
   to an external database. The configuration options are specified through
   Helm values inside the <code class="filename">kubecf-config-values.yaml</code>. The
   deployment and configuration of the external database itself is the
   responsibility of the operator and beyond the scope of this documentation. It
   is assumed the external database has been deployed and accessible.
  </p><div id="id-1.3.4.7.15.6.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Configuration during Initial Install Only</h6><p>
    Configuration of SUSE Cloud Application Platform to use an external database
    <span class="bold"><strong>must</strong></span> be done during the initial
    installation and cannot be changed afterwards.
   </p></div><p>
    All the databases listed in the config snippet below need to exist before
    installing KubeCF. One way of doing that is manually running
    <code class="literal">CREATE DATABASE IF NOT EXISTS
    <em class="replaceable ">database-name</em></code> for each database.
  </p><p>
   The following snippet of the <code class="filename">kubecf-config-values.yaml</code>
   contains an example of an external database configuration.
  </p><div class="verbatim-wrap"><pre class="screen">features:
  embedded_database:
    enabled: false
  external_database:
    enabled: true
    require_ssl: false
    ca_cert: ~
    type: mysql
    host: <em class="replaceable ">hostname</em>
    port: <em class="replaceable ">3306</em>
    databases:
      uaa:
        name: uaa
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      cc:
        name: cloud_controller
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      bbs:
        name: diego
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      routing_api:
        name: routing-api
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      policy_server:
        name: network_policy
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      silk_controller:
        name: network_connectivity
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      locket: 
        name: locket
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em>
      credhub:        
        name: credhub
        password: <em class="replaceable ">root</em>
        username: <em class="replaceable ">root</em></pre></div></div></div><div class="sect1 " id="sec-cap-addrepo-gke"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add the Kubernetes charts repository</span> <a title="Permalink" class="permalink" href="#sec-cap-addrepo-gke">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-addrepo-gke</li></ul></div></div></div></div><p>
   Download the SUSE Kubernetes charts repository with Helm:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm repo add <em class="replaceable ">suse</em> https://kubernetes-charts.suse.com/</pre></div><p>
   You may replace the example <em class="replaceable ">suse</em> name with any
   name. Verify with <code class="command">helm</code>:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm repo list
NAME       URL
stable     https://kubernetes-charts.storage.googleapis.com
local      http://127.0.0.1:8879/charts
suse       https://kubernetes-charts.suse.com/</pre></div><p>
   List your chart names, as you will need these for some operations:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm search repo <em class="replaceable ">suse</em>
NAME                            CHART VERSION        APP VERSION    DESCRIPTION
suse/cf-operator                6.1.17+0.gec409fd7    2.1.0          A Helm chart for cf-operator, the k8s operator ....
suse/console                    4.2.0                2.1.0          A Helm chart for deploying SUSE Stratos Console
suse/kubecf                     2.5.8                2.1.0          A Helm chart for KubeCF
suse/metrics                    1.3.0                2.1.0          A Helm chart for Stratos Metrics
suse/minibroker                 1.1.0                               A minibroker for your minikube
suse/nginx-ingress              0.28.4               0.15.0         An nginx Ingress controller that uses ConfigMap to store ...
...</pre></div></div><div class="sect1 " id="sec-cap-cap-on-gke"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#sec-cap-cap-on-gke">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-cap-on-gke</li></ul></div></div></div></div><p>
   This section describes how to deploy SUSE Cloud Application Platform on Google GKE, and how to
   configure your DNS records.
  </p><div id="id-1.3.4.7.17.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: KubeCF and cf-operator versions</h6><p>
   KubeCF and cf-operator interoperate closely. Before you deploy a
   specific version combination, make sure they were confirmed to work. For more
   information see <a class="xref" href="#cha-cap-depl-notes-releases" title="3.4. Releases and Associated Versions">Section 3.4, “Releases and Associated Versions”</a>.
  </p></div><div class="sect2 " id="sec-cap-gke-deploy-operator"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  Deploy the Operator
 </span> <a title="Permalink" class="permalink" href="#sec-cap-gke-deploy-operator">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-deploy-operator</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    First, create the namespace for the operator.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">cf-operator</em></pre></div></li><li class="step "><p>
    Install the operator.
   </p><p>
    The value of <code class="literal">global.operator.watchNamespace</code> indicates the
    namespace the operator will monitor for a KubeCF deployment. This
    namespace should be separate from the namespace used by the operator. In
    this example, this means KubeCF will be deployed into a namespace called
    <code class="literal">kubecf</code>.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">cf-operator</em> suse/cf-operator \
--namespace <em class="replaceable ">cf-operator</em> \
--set "global.singleNamespace.name=<em class="replaceable ">kubecf</em>" \
--version 6.1.17+0.gec409fd7</pre></div></li><li class="step "><p>
    Wait until cf-operator is successfully deployed before proceeding. Monitor
    the status of your cf-operator deployment using the
    <code class="command">watch</code> command.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">cf-operator</em>'</pre></div></li></ol></div></div></div><div class="sect2 " id="sec-cap-gke-deploy-kubecf"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.14.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy KubeCF</span> <a title="Permalink" class="permalink" href="#sec-cap-gke-deploy-kubecf">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-deploy-kubecf</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
   Use Helm to deploy KubeCF.
  </p><p>
   Note that you <span class="bold"><strong>do not</strong></span> need to manually create
   the namespace for KubeCF.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">kubecf</em> suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values <em class="replaceable ">kubecf-config-values.yaml</em> \
--version 2.5.8</pre></div></li><li class="step "><p>
  Monitor the status of your KubeCF deployment using the
  <code class="command">watch</code> command.
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace kubecf'</pre></div></li><li class="step "><p>
   Find the value of <code class="literal">EXTERNAL-IP</code> for each of the public
   services.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> router-public

<code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> tcp-router-public

<code class="prompt user">tux &gt; </code>kubectl get service --namespace <em class="replaceable ">kubecf</em> ssh-proxy-public</pre></div></li><li class="step "><p>
      Create DNS A records for the public services.
     </p><ol type="a" class="substeps "><li class="step "><p>
    For the <code class="literal">router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">*.&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">tcp-router-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">tcp.&lt;system_domain&gt;</code>.
   </p></li><li class="step "><p>
    For the <code class="literal">ssh-proxy-public</code> service, create a record
    mapping the <code class="literal">EXTERNAL-IP</code> value to <code class="literal">ssh.&lt;system_domain&gt;</code>.
   </p></li></ol></li><li class="step "><p>
      When all pods are fully ready, verify your deployment. See <a class="xref" href="#sec-pod-status" title="3.2. Status of Pods during Deployment">Section 3.2, “Status of Pods during Deployment”</a> for more information.
     </p><p>
  Connect and authenticate to the cluster.
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation "https://api.&lt;system_domain&gt;"

# Use the cf_admin_password set in kubecf-config-values.yaml
<code class="prompt user">tux &gt; </code>cf auth admin <em class="replaceable ">changeme</em></pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-gke-ldap"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
  LDAP Integration
 </span> <a title="Permalink" class="permalink" href="#sec-cap-gke-ldap">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-ldap</li></ul></div></div></div></div><p>
  SUSE Cloud Application Platform can be integrated with
  <a class="link" href="https://docs.cloudfoundry.org/uaa/identity-providers.html" target="_blank">identity
  providers</a> to help manage authentication of users. Integrating
  SUSE Cloud Application Platform with other identity providers is optional. In a default
  deployment, a built-in UAA server (<a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-overview.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-overview.html</a>)
  is used to manage user accounts and authentication.
 </p><p>
  The Lightweight Directory Access Protocol (LDAP) is an example of an identity provider that
  Cloud Application Platform integrates with. This section describes the necessary components and
  steps in order to configure the integration. See
  <a class="link" href="https://github.com/cloudfoundry/uaa/blob/master/docs/UAA-LDAP.md" target="_blank">User
  Account and Authentication LDAP Integration</a> for more information. 
 </p><div class="sect2 " id="id-1.3.4.7.18.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.18.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The following prerequisites are required in order to complete an LDAP
   integration with SUSE Cloud Application Platform.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">uaac</code>, the Cloud Foundry <code class="literal">uaa</code> command line client
 (UAAC). See
 <a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-user-management.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-user-management.html</a>
 for more information and installation instructions.
</p><p>
 On SUSE Linux Enterprise systems, ensure the <code class="literal">ruby-devel</code> and <code class="literal">gcc-c++</code>
 packages have been installed before installing the <code class="literal">cf-uaac</code> gem.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install ruby-devel gcc-c++</pre></div></li><li class="listitem "><p>
     An LDAP server and the credentials for a user/service account with
     permissions to search the directory.
    </p></li></ul></div></div><div class="sect2 " id="id-1.3.4.7.18.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.15.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example LDAP Integration</span> <a title="Permalink" class="permalink" href="#id-1.3.4.7.18.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Run the following commands to complete the integration of your Cloud Application Platform
   deployment and LDAP server.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
 Use UAAC to target your <code class="literal">uaa</code> server.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac target --skip-ssl-validation <em class="replaceable ">https://uaa.example.com</em></pre></div></li><li class="step "><p>
 Authenticate to the <code class="literal">uaa</code> server as
 <code class="literal">admin</code> using the
 <code class="literal">uaa_admin_client_secret</code> set in your
 <code class="filename">kubecf-config-values.yaml</code> file.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac token client get admin --secret <em class="replaceable ">PASSWORD</em></pre></div></li><li class="step "><p>
     List the current identity providers.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers --insecure</pre></div></li><li class="step "><p>
     From the output, locate the default <code class="literal">ldap</code> entry and take
     note of its <code class="literal">id</code>. The entry will be similar to the
     following.
    </p><div class="verbatim-wrap"><pre class="screen">{
  "type": "ldap",
  "config": "{\"emailDomain\":null,\"additionalConfiguration\":null,\"providerDescription\":null,\"externalGroupsWhitelist\":[],\"attributeMappings\":{},\"addShadowUserOnLogin\":true,\"storeCustomAttributes\":true,\"ldapProfileFile\":\"ldap/ldap-search-and-bind.xml\",\"baseUrl\":\"ldap://localhost:389/\",\"referral\":null,\"skipSSLVerification\":false,\"userDNPattern\":null,\"userDNPatternDelimiter\":null,\"bindUserDn\":\"cn=admin,dc=test,dc=com\",\"userSearchBase\":\"dc=test,dc=com\",\"userSearchFilter\":\"cn={0}\",\"passwordAttributeName\":null,\"passwordEncoder\":null,\"localPasswordCompare\":null,\"mailAttributeName\":\"mail\",\"mailSubstitute\":null,\"mailSubstituteOverridesLdap\":false,\"ldapGroupFile\":null,\"groupSearchBase\":null,\"groupSearchFilter\":null,\"groupsIgnorePartialResults\":null,\"autoAddGroups\":true,\"groupSearchSubTree\":true,\"maxGroupSearchDepth\":10,\"groupRoleAttribute\":null,\"tlsConfiguration\":\"none\"}",
  "id": "53gc6671-2996-407k-b085-2346e216a1p0",
  "originKey": "ldap",
  "name": "UAA LDAP Provider",
  "version": 3,
  "created": 946684800000,
  "last_modified": 1602208214000,
  "active": false,
  "identityZoneId": "uaa"
},</pre></div></li><li class="step "><p>
     Delete the default <code class="literal">ldap</code> identity provider. If the
     default entry is not removed, adding another identity provider of type
     <code class="literal">ldap</code> will result in a <code class="literal">409 Conflict</code>
     response. Replace the example <code class="literal">id</code> with one found in the
     previous step.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers/<em class="replaceable ">53gc6671-2996-407k-b085-2346e216a1p0</em> \
    --request DELETE \
    --insecure</pre></div></li><li class="step "><p>
     Create your own LDAP identity provider. A <code class="literal">201 Created</code>
     response will be returned when the identity provider is successfully
     created. See the
     <a class="link" href="http://docs.cloudfoundry.org/api/uaa/version/4.21.0/index.html#ldap" target="_blank">UAA
     API Reference</a> and
     <a class="link" href="https://github.com/cloudfoundry/uaa/blob/4.21.0/docs/UAA-LDAP.md" target="_blank">Cloud Foundry
     UAA-LDAP Documentation</a>for information regarding the request
     parameters and additional options available to configure your identity
     provider.
    </p><p>
     The following is an example of a <code class="literal">uaac curl</code> command and
     its request parameters used to create an identity provider. Specify the
     parameters according to your LDAP server's credentials and directory
     structure. Ensure the user specifed in the <code class="literal">bindUserDn</code>
     has permissions to search the directory.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers?rawConfig=true \
    --request POST \
    --insecure \
    --header 'Content-Type: application/json' \
    --data '{
  "type" : "ldap",
  "config" : {
    "ldapProfileFile" : "ldap/ldap-search-and-bind.xml",
    "baseUrl" : "<em class="replaceable ">ldap://ldap.example.com:389</em>",
    "bindUserDn" : "<em class="replaceable ">cn=admin,dc=example,dc=com</em>",
    "bindPassword" : "<em class="replaceable ">password</em>",
    "userSearchBase" : "<em class="replaceable ">dc=example,dc=com</em>",
    "userSearchFilter" : "<em class="replaceable ">uid</em>={0}",
    "ldapGroupFile" : "ldap/ldap-groups-map-to-scopes.xml",
    "groupSearchBase" : "<em class="replaceable ">dc=example,dc=com</em>",
    "groupSearchFilter" : "<em class="replaceable ">member</em>={0}"
  },
  "originKey" : "ldap",
  "name" : "<em class="replaceable ">My LDAP Server</em>",
  "active" : true
  }'</pre></div></li><li class="step "><p>
     Verify the LDAP identify provider has been created. The output should now
     contain an entry for the <code class="literal">ldap</code> type you created.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac curl /identity-providers --insecure</pre></div></li><li class="step "><p>
     Use the cf CLI to target your SUSE Cloud Application Platform deployment.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation https://api.example.com</pre></div></li><li class="step "><p>
     Log in as an administrator.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login
API endpoint: https://api.example.com

Email&gt; admin

Password&gt;
Authenticating...
OK</pre></div></li><li class="step "><p>
     Create users associated with your LDAP identity provider.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-user <em class="replaceable ">username</em> --origin ldap
Creating user username...
OK

TIP: Assign roles with 'cf set-org-role' and 'cf set-space-role'.</pre></div></li><li class="step "><p>
     Assign the user a role. Roles define the permissions a user has for a
     given org or space and a user can be assigned multiple roles. See
     <a class="link" href="https://docs.cloudfoundry.org/concepts/roles.html" target="_blank">Orgs,
     Spaces, Roles, and Permissions</a> for available roles and their
     corresponding permissions. The following example assumes that an org named
     <em class="replaceable ">Org</em> and a space named
     <em class="replaceable ">Space</em> have already been created.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf set-space-role <em class="replaceable ">username</em> <em class="replaceable ">Org</em> <em class="replaceable ">Space</em> <em class="replaceable ">SpaceDeveloper</em>
Assigning role RoleSpaceDeveloper to user username in org Org / space Space as admin...
OK
<code class="prompt user">tux &gt; </code>cf set-org-role <em class="replaceable ">username</em> Org OrgManager
Assigning role OrgManager to user username in org Org as admin...
OK</pre></div></li><li class="step "><p>
     Verify the user can log into your SUSE Cloud Application Platform deployment using their
     associated LDAP server credentials.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login
API endpoint: https://api.example.com

Email&gt; username

Password&gt;
Authenticating...
OK



API endpoint:   https://api.example.com (API version: 2.115.0)
User:           username@ldap.example.com</pre></div></li></ol></div></div></div></div><div class="sect1 " id="sec-cap-gke-add-capacity"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.16 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Expanding Capacity of a Cloud Application Platform Deployment on Google GKE</span> <a title="Permalink" class="permalink" href="#sec-cap-gke-add-capacity">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_gke.xml</li><li><span class="ds-label">ID: </span>sec-cap-gke-add-capacity</li></ul></div></div></div></div><p>
   If the current capacity of your Cloud Application Platform deployment is insufficient for your
   workloads, you can expand the capacity using the procedure in this section.
  </p><p>
   These instructions assume you have followed the procedure in
   <a class="xref" href="#cha-cap-depl-gke" title="Chapter 7. Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)">Chapter 7, <em>Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</em></a> and have a running Cloud Application Platform deployment on
   Microsoft AKS. The instructions below will use environment variables defined in
   <a class="xref" href="#sec-cap-create-gke-cluster" title="7.2. Creating a GKE cluster">Section 7.2, “Creating a GKE cluster”</a>.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Get the most recently created node in the cluster.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>RECENT_VM_NODE=$(gcloud compute instances list --filter=name~${CLUSTER_NAME:?required} --format json | jq --raw-output '[sort_by(.creationTimestamp) | .[].creationTimestamp ] | last | .[0:19] | strptime("%Y-%m-%dT%H:%M:%S") | mktime')</pre></div></li><li class="step "><p>
     
     Increase the Kubernetes node count in the cluster. Replace the example value
     with the number of nodes required for your workload.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>gcloud container clusters resize $CLUSTER_NAME \
--num-nodes <em class="replaceable ">5</em></pre></div></li><li class="step "><p>
     Verify the new nodes are in a <code class="literal">Ready</code> state before proceeding.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get nodes</pre></div></li><li class="step "><p>
     Add or update the following in your
     <code class="filename">kubecf-config-values.yaml</code> file to increase the number of
     <code class="literal">diego-cell</code> in your Cloud Application Platform deployment. Replace the
     example value with the number required by your workflow.
    </p><div class="verbatim-wrap"><pre class="screen">sizing:
  diego_cell:
    instances: <em class="replaceable ">5</em></pre></div></li><li class="step "><p>
     Perform a <code class="command">helm upgrade</code> to apply the change.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade kubecf suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values kubecf-config-values.yaml \
--version 2.5.8</pre></div></li><li class="step "><p>
     Monitor progress of the additional <code class="literal">diego-cell</code> pods:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace kubecf'</pre></div></li></ol></div></div></div></div><div class="chapter " id="cha-cap-install-stratos"><div class="titlepage"><div><div><h2 class="title"><span class="number">8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing the Stratos Web Console</span> <a title="Permalink" class="permalink" href="#cha-cap-install-stratos">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-stratos-prod"><span class="number">8.1 </span><span class="name">Deploy Stratos on SUSE® CaaS Platform</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-eks"><span class="number">8.2 </span><span class="name">Deploy Stratos on Amazon EKS</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-aks"><span class="number">8.3 </span><span class="name">Deploy Stratos on Microsoft AKS</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-gke"><span class="number">8.4 </span><span class="name">Deploy Stratos on Google GKE</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-upgrade"><span class="number">8.5 </span><span class="name">Upgrading Stratos</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-stratos-metrics"><span class="number">8.6 </span><span class="name">Stratos Metrics</span></a></span></dt></dl></div></div><p>
   The Stratos user interface (UI) is a modern web-based management application
   for Cloud Foundry. It provides a graphical management console for both
   developers and system administrators.
  </p><div class="sect1 " id="sec-cap-stratos-prod"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy Stratos on SUSE® CaaS Platform</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-prod">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-prod</li></ul></div></div></div></div><p>
      The steps in this section describe how to install Stratos on SUSE® CaaS Platform
      without an external load balancer, instead mapping a worker node to your
      SUSE Cloud Application Platform domain as described in
      <a class="xref" href="#sec-cap-caasp-config" title="4.5. Deployment Configuration">Section 4.5, “Deployment Configuration”</a>. These instructions assume you
      have followed the procedure in <a class="xref" href="#cha-cap-depl-caasp" title="Chapter 4. Deploying SUSE Cloud Application Platform on SUSE CaaS Platform">Chapter 4, <em>Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</em></a>,
      have deployed <code class="literal">kubecf</code> successfully, and have created a
      default storage class.
 </p><p>
   If you are using SUSE Enterprise Storage as your storage back-end, copy the secret into the
   Stratos namespace:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get secret ceph-secret-admin --output json --namespace default | \
sed 's/"namespace": "default"/"namespace": "stratos"/' | kubectl create --filename -</pre></div><p>
   You should already have the Stratos charts when you downloaded the SUSE
   charts repository (see <a class="xref" href="#sec-cap-addrepo-caasp" title="4.12. Add the Kubernetes Charts Repository">Section 4.12, “Add the Kubernetes Charts Repository”</a>). Search your
   Helm repository to verify that you have the <code class="literal">suse/console</code>
   chart:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm search repo <em class="replaceable ">suse</em>
NAME                            CHART VERSION        APP VERSION    DESCRIPTION
suse/cf-operator                6.1.17+0.gec409fd7    2.1.0          A Helm chart for cf-operator, the k8s operator ....
suse/console                    4.2.0                2.1.0          A Helm chart for deploying SUSE Stratos Console
suse/kubecf                     2.5.8                2.1.0          A Helm chart for KubeCF
suse/metrics                    1.3.0                2.1.0          A Helm chart for Stratos Metrics
suse/minibroker                 1.1.0                               A minibroker for your minikube
suse/nginx-ingress              0.28.4               0.15.0         An nginx Ingress controller that uses ConfigMap to store ...
...</pre></div><p>
   Create a YAML file, called <code class="filename">stratos-config-values.yaml</code> in this
   example, and use it to make configurations to the Stratos Helm chart.
  </p><div class="verbatim-wrap"><pre class="screen">### example Stratos deployment configuration file
### stratos-config-values.yaml

console:
  # Use local admin user instead of UAA
  localAdminPassword: <em class="replaceable ">changeme</em></pre></div><div id="id-1.3.4.8.3.9" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note: Technology Preview Features</h6><p>
  Some Stratos releases may include features as part of a technology preview.
  Technology preview features are for evaluation purposes only and
  <span class="bold"><strong>not</strong></span> supported for production use. To see the
  technology preview features available for a given release, refer to
  <a class="link" href="https://github.com/SUSE/stratos/blob/master/CHANGELOG.md" target="_blank">https://github.com/SUSE/stratos/blob/master/CHANGELOG.md</a>.
 </p><p>
  To enable technology preview features, add the
  <code class="literal">console.techPreview</code> Helm value to your
  <code class="filename">stratos-config-values.yaml</code> and set it to
  <code class="literal">true</code>.
 </p><div class="verbatim-wrap"><pre class="screen">### example Stratos deployment configuration file                        
### stratos-config-values.yaml
                                                                                 
console:
  techPreview: true</pre></div></div><p>
   Create a namespace for your Stratos deployment.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">stratos</em></pre></div><p>
   Deploy Stratos using Helm.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">susecf-console</em> suse/console \
--namespace <em class="replaceable ">stratos</em> \
--values stratos-config-values.yaml</pre></div><p>
  You can monitor the status of your <code class="literal">stratos</code> deployment with
  the <code class="command">watch</code> command:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace stratos'</pre></div><p>
  When <code class="literal">stratos</code> is successfully deployed, the following is
  observed:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    For the <code class="literal">volume-migration</code> pod, the
    <code class="literal">STATUS</code> is <code class="literal">Completed</code> and the
    <code class="literal">READY</code> column is at <code class="literal">0/1</code>.
   </p></li><li class="listitem "><p>
    All other pods have a <code class="literal">Running</code> <code class="literal">STATUS</code>
    and a <code class="literal">READY</code> value of <code class="literal">n/n</code>.
   </p></li></ul></div><p>
  Press <span class="keycap">Ctrl</span><span class="key-connector">–</span><span class="keycap">C</span> to
  exit the <code class="command">watch</code> command.
 </p><p>
   When the <code class="literal">stratos</code> deployment completes, query with Helm
   to view your release information:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm status susecf-console
LAST DEPLOYED: Wed Mar 27 06:51:36 2019
NAMESPACE: stratos
STATUS: DEPLOYED

RESOURCES:
==&gt; v1/Secret
NAME                           TYPE    DATA  AGE
susecf-console-secret          Opaque  2     3h
susecf-console-mariadb-secret  Opaque  2     3h

==&gt; v1/PersistentVolumeClaim
NAME                                  STATUS  VOLUME                                    CAPACITY  ACCESSMODES  STORAGECLASS  AGE
susecf-console-upgrade-volume         Bound   pvc-711380d4-5097-11e9-89eb-fa163e15acf0  20Mi      RWO          persistent    3h
susecf-console-encryption-key-volume  Bound   pvc-711b5275-5097-11e9-89eb-fa163e15acf0  20Mi      RWO          persistent    3h
console-mariadb                       Bound   pvc-7122200c-5097-11e9-89eb-fa163e15acf0  1Gi       RWO          persistent    3h

==&gt; v1/Service
NAME                    CLUSTER-IP      EXTERNAL-IP                                                PORT(S)   AGE
susecf-console-mariadb  172.24.137.195  &lt;none&gt;                                                     3306/TCP  3h
susecf-console-ui-ext   172.24.80.22    10.86.101.115,172.28.0.31,172.28.0.36,172.28.0.7,172.28.0.22  8443/TCP  3h

==&gt; v1beta1/Deployment
NAME        DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
stratos-db  1        1        1           1          3h

==&gt; v1beta1/StatefulSet
NAME     DESIRED  CURRENT  AGE
stratos  1        1        3h</pre></div><p>
  Find the external IP address with
  <code class="command">kubectl get service susecf-console-ui-ext --namespace stratos</code> to access your new Stratos Web console, for example https://10.86.101.115:8443, or use the
          domain you created for it, and its port, for example
          https://example.com:8443. Proceed past the warnings about the self-signed
   certificates and log in as <code class="literal">admin</code> with the password you
   created in stratos-config-values.yaml
  </p><div class="figure" id="id-1.3.4.8.3.22"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos.png" target="_blank"><img src="images/stratos.png" width="" alt="Stratos UI Cloud Foundry Console" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.1: </span><span class="name">Stratos UI Cloud Foundry Console </span><a title="Permalink" class="permalink" href="#id-1.3.4.8.3.22">#</a></h6></div></div><div class="sect2 " id="sec-cap-stratos-caasp-connect"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Connecting SUSE® CaaS Platform to Stratos</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-caasp-connect">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-caasp-connect</li></ul></div></div></div></div><p>
    Stratos can show information from your SUSE® CaaS Platform environment.
   </p><p>
    To enable this, you must register and connect your SUSE® CaaS Platform environment
    with Stratos.
   </p><p>
    In the Stratos UI, go to <span class="guimenu ">Endpoints</span> in the left-hand side
    navigation and click on the <span class="guimenu ">+</span> icon in the top-right of
    the view - you should be shown the "Register new Endpoint" view.
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      In the Stratos UI, go to <span class="guimenu ">Endpoints</span> in the left-hand side
      navigation and click on the <span class="guimenu ">+</span> icon in the top-right of
      the view.
     </p></li><li class="step "><p>
      On the <code class="literal">Register a new Endpoint</code> view, click the
      <code class="literal">SUSE CaaS Platform</code> button.
     </p></li><li class="step "><p>
      Enter a memorable name for your SUSE® CaaS Platform environment in the <span class="guimenu ">Name</span>
      field. For example, <em class="replaceable ">my-endpoint</em>.
     </p></li><li class="step "><p>
      Enter the URL of the API server for your Kubernetes environment in the
      <span class="guimenu ">Endpoint Address</span> field. Run <code class="command">kubectl cluster-info</code>
      and use the value of <code class="literal">Kubernetes master</code> as the URL.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl cluster-info</pre></div></li><li class="step "><p>
      Activate the <span class="guimenu ">Skip SSL validation for the endpoint</span> check box
      if using self-signed certificates.
     </p></li><li class="step "><p>
      Click <span class="guimenu ">Register</span>.
     </p></li><li class="step "><p>
      Activate the <span class="guimenu ">Connect to my-endpoint now (optional).</span> check box.
     </p></li><li class="step "><p>
      Provide a valid <code class="filename">kubeconfig</code> file for your SUSE® CaaS Platform environment.
     </p></li><li class="step "><p>
      Click <span class="guimenu ">Connect</span>.
     </p></li><li class="step "><p>
      In the Stratos UI, go to <span class="guimenu ">Kubernetes</span> in the left-hand side
      navigation. Information for your SUSE® CaaS Platform environment should now be
      displayed as in the following figure.
     </p></li></ol></div></div><div class="figure" id="stratos-kubernetes-view-caasp-png"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos-kubernetes-view-caasp.png" target="_blank"><img src="images/stratos-kubernetes-view-caasp.png" width="" alt="Kubernetes Environment Information on Stratos" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.2: </span><span class="name">Kubernetes Environment Information on Stratos </span><a title="Permalink" class="permalink" href="#stratos-kubernetes-view-caasp-png">#</a></h6></div></div></div></div><div class="sect1 " id="sec-cap-stratos-eks"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy Stratos on Amazon EKS</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-eks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-eks</li></ul></div></div></div></div><p>
   Before deploying Stratos, ensure <code class="literal">kubecf</code> has been successfully
   deployed on Amazon EKS (see <a class="xref" href="#cha-cap-depl-eks" title="Chapter 6. Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)">Chapter 6, <em>Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</em></a>).
  </p><p>
   Configure a scoped storage class for your Stratos deployment. Create a configuration
   file, called <code class="filename">scoped-storage-class.yaml</code> in this example,
   using the following as a template. Specify the region you are using as the
   <code class="literal">zone</code> and be sure to include the letter (for example, the
   letter <code class="literal">a</code> in <code class="literal">us-west-2a</code>) identifier to indicate
   the Availability Zone used:
  </p><div class="verbatim-wrap"><pre class="screen">kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: <em class="replaceable ">gp2scoped</em>
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
  zone: <em class="replaceable ">"us-west-2a"</em>
reclaimPolicy: Retain
mountOptions:
  - debug</pre></div><p>
   Create the storage class using the <code class="filename">scoped-storage-class.yaml</code>
   configuration file:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create --filename <em class="replaceable ">scoped-storage-class.yaml</em></pre></div><p>
   Verify the storage class has been created:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get storageclass
NAME            PROVISIONER             AGE
gp2 (default)   kubernetes.io/aws-ebs   1d
gp2scoped       kubernetes.io/aws-ebs   1d</pre></div><p>
   Create a YAML file, called <code class="filename">stratos-config-values.yaml</code> in this
   example, and use it to make configurations to the Stratos Helm chart.
  </p><div class="verbatim-wrap"><pre class="screen">### example Stratos deployment configuration file
### stratos-config-values.yaml

console:
  # Use local admin user instead of UAA
  localAdminPassword: <em class="replaceable ">changeme</em>

services:
  loadbalanced: true

kube:
  storage_class:
    persistent: gp2scoped</pre></div><div id="id-1.3.4.8.4.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note: Technology Preview Features</h6><p>
  Some Stratos releases may include features as part of a technology preview.
  Technology preview features are for evaluation purposes only and
  <span class="bold"><strong>not</strong></span> supported for production use. To see the
  technology preview features available for a given release, refer to
  <a class="link" href="https://github.com/SUSE/stratos/blob/master/CHANGELOG.md" target="_blank">https://github.com/SUSE/stratos/blob/master/CHANGELOG.md</a>.
 </p><p>
  To enable technology preview features, add the
  <code class="literal">console.techPreview</code> Helm value to your
  <code class="filename">stratos-config-values.yaml</code> and set it to
  <code class="literal">true</code>.
 </p><div class="verbatim-wrap"><pre class="screen">### example Stratos deployment configuration file                        
### stratos-config-values.yaml
                                                                                 
console:
  techPreview: true</pre></div></div><p>
   Create a namespace for your Stratos deployment.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">stratos</em></pre></div><p>
   Deploy Stratos using Helm.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">susecf-console</em> suse/console
\
--namespace <em class="replaceable ">stratos</em> \
--values stratos-config-values.yaml</pre></div><p>
  You can monitor the status of your <code class="literal">stratos</code> deployment with
  the <code class="command">watch</code> command:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace stratos'</pre></div><p>
  When <code class="literal">stratos</code> is successfully deployed, the following is
  observed:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    For the <code class="literal">volume-migration</code> pod, the
    <code class="literal">STATUS</code> is <code class="literal">Completed</code> and the
    <code class="literal">READY</code> column is at <code class="literal">0/1</code>.
   </p></li><li class="listitem "><p>
    All other pods have a <code class="literal">Running</code> <code class="literal">STATUS</code>
    and a <code class="literal">READY</code> value of <code class="literal">n/n</code>.
   </p></li></ul></div><p>
  Press <span class="keycap">Ctrl</span><span class="key-connector">–</span><span class="keycap">C</span> to
  exit the <code class="command">watch</code> command.
 </p><p>
   Obtain the host name of the service exposed through the public load balancer:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get service susecf-console-ui-ext --namespace stratos</pre></div><p>
   Use this host name to create a CNAME record. After the record is created,
   access the console in a web browser by navigating to the domain mapped to the
   host name of the service retrieved from the
   <code class="command">kubectl get service</code> step. Upon successfully logging in,
   you should see something similar to the following figure.
  </p><div class="figure" id="id-1.3.4.8.4.24"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos.png" target="_blank"><img src="images/stratos.png" width="" alt="Stratos UI Cloud Foundry Console" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.3: </span><span class="name">Stratos UI Cloud Foundry Console </span><a title="Permalink" class="permalink" href="#id-1.3.4.8.4.24">#</a></h6></div></div><div class="sect2 " id="sec-cap-stratos-eks-connect"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Connecting Amazon EKS to Stratos</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-eks-connect">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-eks-connect</li></ul></div></div></div></div><p>
    Stratos can show information from your Amazon EKS environment.
   </p><p>
    To enable this, you must register and connect your Amazon EKS environment
    with Stratos.
   </p><p>
    In the Stratos UI, go to <span class="guimenu ">Endpoints</span> in the left-hand side
    navigation and click on the <span class="guimenu ">+</span> icon in the top-right of
    the view - you should be shown the "Register new Endpoint" view.
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      In the Stratos UI, go to <span class="guimenu ">Endpoints</span> in the left-hand side
      navigation and click on the <span class="guimenu ">+</span> icon in the top-right of
      the view.
     </p></li><li class="step "><p>
      On the <code class="literal">Register a new Endpoint</code> view, click the
      <code class="literal">Amazon EKS</code> button.
     </p></li><li class="step "><p>
      Enter a memorable name for your Amazon EKS environment in the <span class="guimenu ">Name</span>
      field. For example, <em class="replaceable ">my-endpoint</em>.
     </p></li><li class="step "><p>
      Enter the URL of the API server for your Kubernetes environment in the
      <span class="guimenu ">Endpoint Address</span> field. Run <code class="command">kubectl cluster-info</code>
      and use the value of <code class="literal">Kubernetes master</code> as the URL.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl cluster-info</pre></div></li><li class="step "><p>
      Activate the <span class="guimenu ">Skip SSL validation for the endpoint</span> check box
      if using self-signed certificates.
     </p></li><li class="step "><p>
      Click <span class="guimenu ">Register</span>.
     </p></li><li class="step "><p>
      Activate the <span class="guimenu ">Connect to my-endpoint now (optional).</span> check box.
     </p></li><li class="step "><p>
      Enter the name of your Amazon EKS cluster in the <span class="guimenu ">Cluster</span>
      field.
     </p></li><li class="step "><p>
      Enter your AWS Access Key ID in the <span class="guimenu ">Access Key ID</span>
      field.
     </p></li><li class="step "><p>
      Enter your AWS Secret Access Key in the <span class="guimenu ">Secret Access Key</span>
      field.
     </p></li><li class="step "><p>
      Click <span class="guimenu ">Connect</span>.
     </p></li><li class="step "><p>
      In the Stratos UI, go to <span class="guimenu ">Kubernetes</span> in the left-hand side
      navigation. Information for your Amazon EKS environment should now be displayed
      as in the following figure.
     </p></li></ol></div></div><div class="figure" id="id-1.3.4.8.4.25.6"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos-kubernetes-view.png" target="_blank"><img src="images/stratos-kubernetes-view.png" width="" alt="Kubernetes Environment Information on Stratos" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.4: </span><span class="name">Kubernetes Environment Information on Stratos </span><a title="Permalink" class="permalink" href="#id-1.3.4.8.4.25.6">#</a></h6></div></div></div></div><div class="sect1 " id="sec-cap-stratos-aks"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy Stratos on Microsoft AKS</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-aks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-aks</li></ul></div></div></div></div><p>
   Before deploying Stratos, ensure <code class="literal">kubecf</code> has been successfully
   deployed on Microsoft AKS (see <a class="xref" href="#cha-cap-depl-aks" title="Chapter 5. Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)">Chapter 5, <em>Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</em></a>).
  </p><p>
   Create a YAML file, called <code class="filename">stratos-config-values.yaml</code> in this
   example, and use it to make configurations to the Stratos Helm chart.
  </p><div class="verbatim-wrap"><pre class="screen">### example Stratos deployment configuration file
### stratos-config-values.yaml

console:
  # Use local admin user instead of UAA
  localAdminPassword: <em class="replaceable ">changeme</em>

services:
  loadbalanced: true</pre></div><div id="id-1.3.4.8.5.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note: Technology Preview Features</h6><p>
  Some Stratos releases may include features as part of a technology preview.
  Technology preview features are for evaluation purposes only and
  <span class="bold"><strong>not</strong></span> supported for production use. To see the
  technology preview features available for a given release, refer to
  <a class="link" href="https://github.com/SUSE/stratos/blob/master/CHANGELOG.md" target="_blank">https://github.com/SUSE/stratos/blob/master/CHANGELOG.md</a>.
 </p><p>
  To enable technology preview features, add the
  <code class="literal">console.techPreview</code> Helm value to your
  <code class="filename">stratos-config-values.yaml</code> and set it to
  <code class="literal">true</code>.
 </p><div class="verbatim-wrap"><pre class="screen">### example Stratos deployment configuration file                        
### stratos-config-values.yaml
                                                                                 
console:
  techPreview: true</pre></div></div><p>
   Create a namespace for your Stratos deployment.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">stratos</em></pre></div><p>
   Deploy Stratos using Helm.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">susecf-console</em> suse/console
\
--namespace <em class="replaceable ">stratos</em> \
--values stratos-config-values.yaml</pre></div><p>
  You can monitor the status of your <code class="literal">stratos</code> deployment with
  the <code class="command">watch</code> command:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace stratos'</pre></div><p>
  When <code class="literal">stratos</code> is successfully deployed, the following is
  observed:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    For the <code class="literal">volume-migration</code> pod, the
    <code class="literal">STATUS</code> is <code class="literal">Completed</code> and the
    <code class="literal">READY</code> column is at <code class="literal">0/1</code>.
   </p></li><li class="listitem "><p>
    All other pods have a <code class="literal">Running</code> <code class="literal">STATUS</code>
    and a <code class="literal">READY</code> value of <code class="literal">n/n</code>.
   </p></li></ul></div><p>
  Press <span class="keycap">Ctrl</span><span class="key-connector">–</span><span class="keycap">C</span> to
  exit the <code class="command">watch</code> command.
 </p><p>
   Obtain the IP address of the service exposed through the public load balancer:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get service susecf-console-ui-ext --namespace stratos</pre></div><p>
   Use this IP address to create an A record. After the record is created,     
   access the console in a web browser by navigating to the domain mapped to the 
   IP address of the service retrieved from the                                   
   <code class="command">kubectl get service</code> step. Upon successfully logging in,    
   you should see something similar to the following figure.
  </p><div class="figure" id="id-1.3.4.8.5.18"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos.png" target="_blank"><img src="images/stratos.png" width="" alt="Stratos UI Cloud Foundry Console" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.5: </span><span class="name">Stratos UI Cloud Foundry Console </span><a title="Permalink" class="permalink" href="#id-1.3.4.8.5.18">#</a></h6></div></div><div class="sect2 " id="sec-cap-stratos-aks-connect"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Connecting Microsoft AKS to Stratos</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-aks-connect">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-aks-connect</li></ul></div></div></div></div><p>
    Stratos can show information from your Microsoft AKS environment.
   </p><p>
    To enable this, you must register and connect your Microsoft AKS environment
    with Stratos.
   </p><p>
    In the Stratos UI, go to <span class="guimenu ">Endpoints</span> in the left-hand side
    navigation and click on the <span class="guimenu ">+</span> icon in the top-right of
    the view - you should be shown the "Register new Endpoint" view.
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      In the Stratos UI, go to <span class="guimenu ">Endpoints</span> in the left-hand side
      navigation and click on the <span class="guimenu ">+</span> icon in the top-right of
      the view.
     </p></li><li class="step "><p>
      On the <code class="literal">Register a new Endpoint</code> view, click the
      <code class="literal">Azure AKS</code> button.
     </p></li><li class="step "><p>
      Enter a memorable name for your Microsoft AKS environment in the <span class="guimenu ">Name</span>
      field. For example, <em class="replaceable ">my-endpoint</em>.
     </p></li><li class="step "><p>
      Enter the URL of the API server for your Kubernetes environment in the
      <span class="guimenu ">Endpoint Address</span> field. Run <code class="command">kubectl cluster-info</code>
      and use the value of <code class="literal">Kubernetes master</code> as the URL.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl cluster-info</pre></div></li><li class="step "><p>
      Activate the <span class="guimenu ">Skip SSL validation for the endpoint</span> check box
      if using self-signed certificates.
     </p></li><li class="step "><p>
      Click <span class="guimenu ">Register</span>.
     </p></li><li class="step "><p>
      Activate the <span class="guimenu ">Connect to my-endpoint now (optional).</span> check box.
     </p></li><li class="step "><p>
      Provide a valid <code class="filename">kubeconfig</code> file for your Microsoft AKS environment.
     </p></li><li class="step "><p>
      Click <span class="guimenu ">Connect</span>.
     </p></li><li class="step "><p>
      In the Stratos UI, go to <span class="guimenu ">Kubernetes</span> in the left-hand side
      navigation. Information for your Microsoft AKS environment should now be displayed
      as in the following figure.
     </p></li></ol></div></div><div class="figure" id="id-1.3.4.8.5.19.6"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos-kubernetes-view.png" target="_blank"><img src="images/stratos-kubernetes-view.png" width="" alt="Kubernetes Environment Information on Stratos" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.6: </span><span class="name">Kubernetes Environment Information on Stratos </span><a title="Permalink" class="permalink" href="#id-1.3.4.8.5.19.6">#</a></h6></div></div></div></div><div class="sect1 " id="sec-cap-stratos-gke"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy Stratos on Google GKE</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-gke">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-gke</li></ul></div></div></div></div><p>
   Before deploying Stratos, ensure <code class="literal">kubecf</code> has been successfully
   deployed on Google GKE (see <a class="xref" href="#cha-cap-depl-gke" title="Chapter 7. Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)">Chapter 7, <em>Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</em></a>).
  </p><p>
   Create a YAML file, called <code class="filename">stratos-config-values.yaml</code> in this
   example, and use it to make configurations to the Stratos Helm chart.
  </p><div class="verbatim-wrap"><pre class="screen">### example Stratos deployment configuration file
### stratos-config-values.yaml

console:
  # Use local admin user instead of UAA
  localAdminPassword: <em class="replaceable ">changeme</em>

services:
  loadbalanced: true</pre></div><div id="id-1.3.4.8.6.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note: Technology Preview Features</h6><p>
  Some Stratos releases may include features as part of a technology preview.
  Technology preview features are for evaluation purposes only and
  <span class="bold"><strong>not</strong></span> supported for production use. To see the
  technology preview features available for a given release, refer to
  <a class="link" href="https://github.com/SUSE/stratos/blob/master/CHANGELOG.md" target="_blank">https://github.com/SUSE/stratos/blob/master/CHANGELOG.md</a>.
 </p><p>
  To enable technology preview features, add the
  <code class="literal">console.techPreview</code> Helm value to your
  <code class="filename">stratos-config-values.yaml</code> and set it to
  <code class="literal">true</code>.
 </p><div class="verbatim-wrap"><pre class="screen">### example Stratos deployment configuration file                        
### stratos-config-values.yaml
                                                                                 
console:
  techPreview: true</pre></div></div><p>
   Create a namespace for your Stratos deployment.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">stratos</em></pre></div><p>
   Deploy Stratos using Helm.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">susecf-console</em> suse/console
\
--namespace <em class="replaceable ">stratos</em> \
--values stratos-config-values.yaml</pre></div><p>
  You can monitor the status of your <code class="literal">stratos</code> deployment with
  the <code class="command">watch</code> command:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace stratos'</pre></div><p>
  When <code class="literal">stratos</code> is successfully deployed, the following is
  observed:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    For the <code class="literal">volume-migration</code> pod, the
    <code class="literal">STATUS</code> is <code class="literal">Completed</code> and the
    <code class="literal">READY</code> column is at <code class="literal">0/1</code>.
   </p></li><li class="listitem "><p>
    All other pods have a <code class="literal">Running</code> <code class="literal">STATUS</code>
    and a <code class="literal">READY</code> value of <code class="literal">n/n</code>.
   </p></li></ul></div><p>
  Press <span class="keycap">Ctrl</span><span class="key-connector">–</span><span class="keycap">C</span> to
  exit the <code class="command">watch</code> command.
 </p><p>
   Obtain the IP address of the service exposed through the public load balancer:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get service susecf-console-ui-ext --namespace stratos</pre></div><p>
   Use this IP address to create an A record. After the record is created,     
   access the console in a web browser by navigating to the domain mapped to the 
   IP address of the service retrieved from the                                   
   <code class="command">kubectl get service</code> step. Upon successfully logging in,    
   you should see something similar to the following figure.
  </p><div class="figure" id="id-1.3.4.8.6.18"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos.png" target="_blank"><img src="images/stratos.png" width="" alt="Stratos UI Cloud Foundry Console" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.7: </span><span class="name">Stratos UI Cloud Foundry Console </span><a title="Permalink" class="permalink" href="#id-1.3.4.8.6.18">#</a></h6></div></div><div class="sect2 " id="sec-cap-stratos-gke-connect"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Connecting Google GKE to Stratos</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-gke-connect">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-gke-connect</li></ul></div></div></div></div><p>
    Stratos can show information from your Google GKE environment.
   </p><p>
    To enable this, you must register and connect your Google GKE environment
    with Stratos.
   </p><p>
    In the Stratos UI, go to <span class="guimenu ">Endpoints</span> in the left-hand side
    navigation and click on the <span class="guimenu ">+</span> icon in the top-right of
    the view - you should be shown the "Register new Endpoint" view.
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      In the Stratos UI, go to <span class="guimenu ">Endpoints</span> in the left-hand side
      navigation and click on the <span class="guimenu ">+</span> icon in the top-right of
      the view.
     </p></li><li class="step "><p>
      On the <code class="literal">Register a new Endpoint</code> view, click the
      <code class="literal">Google Kubernetes Engine</code> button.
     </p></li><li class="step "><p>
      Enter a memorable name for your Microsoft AKS environment in the <span class="guimenu ">Name</span>
      field. For example, <em class="replaceable ">my-endpoint</em>.
     </p></li><li class="step "><p>
      Enter the URL of the API server for your Kubernetes environment in the
      <span class="guimenu ">Endpoint Address</span> field. Run <code class="command">kubectl cluster-info</code>
      and use the value of <code class="literal">Kubernetes master</code> as the URL.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl cluster-info</pre></div></li><li class="step "><p>
      Activate the <span class="guimenu ">Skip SSL validation for the endpoint</span> check box
      if using self-signed certificates.
     </p></li><li class="step "><p>
      Click <span class="guimenu ">Register</span>.
     </p></li><li class="step "><p>
      Activate the <span class="guimenu ">Connect to my-endpoint now (optional).</span> check box.
     </p></li><li class="step "><p>
      Provide a valid <code class="filename">Application Default Credentials</code> file for your
      Google GKE environment. Generate the file using the command below. The command saves the
      credentials to a file named <code class="filename">application_default_credentials.json</code>
      and outputs the path of the file.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>gcloud auth application-default login</pre></div></li><li class="step "><p>
      Click <span class="guimenu ">Connect</span>.
     </p></li><li class="step "><p>
      In the Stratos UI, go to <span class="guimenu ">Kubernetes</span> in the left-hand side
      navigation. Information for your Google GKE environment should now be displayed
      as in the following figure.
     </p></li></ol></div></div><div class="figure" id="id-1.3.4.8.6.19.6"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos-kubernetes-view.png" target="_blank"><img src="images/stratos-kubernetes-view.png" width="" alt="Kubernetes Environment Information on Stratos" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.8: </span><span class="name">Kubernetes Environment Information on Stratos </span><a title="Permalink" class="permalink" href="#id-1.3.4.8.6.19.6">#</a></h6></div></div></div></div><div class="sect1 " id="sec-cap-stratos-upgrade"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upgrading Stratos</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-upgrade">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-upgrade</li></ul></div></div></div></div><p>
   For instructions to upgrade Stratos, follow the process described in
   <a class="xref" href="#cha-cap-upgrade" title="Chapter 13. Upgrading SUSE Cloud Application Platform">Chapter 13, <em>Upgrading SUSE Cloud Application Platform</em></a>. Take note that <code class="literal">kubecf</code> is
   upgraded prior to upgrading Stratos.
  </p></div><div class="sect1 " id="sec-cap-stratos-metrics"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Stratos Metrics</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-metrics">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-metrics</li></ul></div></div></div></div><p>
   Stratos Metrics provides a Helm chart for deploying Prometheus (see
   <a class="link" href="https://prometheus.io/" target="_blank">https://prometheus.io/</a>) and the following metrics
   exporters to Kubernetes:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Cloud Foundry Firehose Exporter (enabled by default)
    </p></li><li class="listitem "><p>
     Cloud Foundry Exporter (disabled by default)
    </p></li><li class="listitem "><p>
     Kubernetes State Metrics Exporter (disabled by default)
    </p></li></ul></div><p>
   The Stratos Metrics Helm chart deploys a Prometheus server and the
   configured Exporters and fronts the Prometheus server with an nginx server
   to provide authenticated access to Prometheus (currently basic authentication
   over HTTPS).
  </p><p>
   When required by configuration, it also contains an initialization script
   that will setup users in the UAA that have correct scopes/permissions to be
   able to read data from the Cloud Foundry Firehose and/or API.
  </p><p>
   Lastly, the Helm chart generates a small metadata file in the root of the
   nginx server that is used by Stratos to determine which Cloud Foundry and Kubernetes
   clusters the Prometheus server is providing Metrics for.
  </p><p>
   To learn more about Stratos Metrics and its full list of configuration
   options, see <a class="link" href="https://github.com/SUSE/stratos-metrics" target="_blank">https://github.com/SUSE/stratos-metrics</a>.
  </p><div class="sect2 " id="sec-cap-stratos-metrics-exporter-config"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Exporter Configuration</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-metrics-exporter-config">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-metrics-exporter-config</li></ul></div></div></div></div><div class="sect3 " id="sec-cap-stratos-metrics-exporter-config-firehose"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.6.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Firehose Exporter</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-metrics-exporter-config-firehose">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-metrics-exporter-config-firehose</li></ul></div></div></div></div><p>
     This exporter can be enabled/disabled via the Helm value
     <code class="literal">firehoseExporter.enabled</code>. By default this exporter is
     enabled.
    </p><p>
You must provide the following Helm chart values for this Exporter to work correctly:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       <code class="literal">cloudFoundry.apiEndpoint</code> - API Endpoint of the Cloud Foundry
       API Server
      </p></li><li class="listitem "><p>
       <code class="literal">cloudFoundry.uaaAdminClient</code> - Admin client of the UAA
       used by the Cloud Foundry server
      </p></li><li class="listitem "><p>
       <code class="literal">cloudFoundry.uaaAdminClientSecret</code> - Admin client
       secret of the UAA used by the Cloud Foundry server
      </p></li><li class="listitem "><p>
       <code class="literal">cloudFoundry.skipSslVerification</code> - Whether to skip SSL
       verification when communicating with Cloud Foundry and the UAA APIs
      </p></li></ul></div><p>
     You can scale the firehose nozzle in Stratos Metrics by specifying the
     following override:
    </p><div class="verbatim-wrap"><pre class="screen">firehoseExporter:
  instances: 1</pre></div><p>
     Please note, the number of firehose nozzles should be proportional to the
     number of Traffic Controllers in your Cloud Foundry (see docs at
     <a class="link" href="https://docs.cloudfoundry.org/loggregator/log-ops-guide.html" target="_blank">https://docs.cloudfoundry.org/loggregator/log-ops-guide.html</a>).
     Otherwise, Loggregator will not split the firehose between the nozzles.
    </p></div><div class="sect3 " id="sec-cap-stratos-metrics-exporter-config-cloud-foundry"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.6.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cloud Foundry Exporter</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-metrics-exporter-config-cloud-foundry">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-metrics-exporter-config-cloud-foundry</li></ul></div></div></div></div><p>
     This exporter can be enabled/disabled via the Helm value
     <code class="literal">cfExporter.enabled</code>. By default this exporter is
     disabled.
    </p><p>
     You must provide the following Helm chart values for this Exporter to
     work correctly:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       <code class="literal">cloudFoundry.apiEndpoint</code> - API Endpoint of the Cloud Foundry
       API Server
      </p></li><li class="listitem "><p>
       <code class="literal">cloudFoundry.uaaAdminClient</code> - Admin client of the UAA
       used by the Cloud Foundry server
      </p></li><li class="listitem "><p>
       <code class="literal">cloudFoundry.uaaAdminClientSecret</code> - Admin client
       secret of the UAA used by the Cloud Foundry server
      </p></li><li class="listitem "><p>
       <code class="literal">cloudFoundry.skipSslVerification</code> - Whether to skip SSL
       verification when communicating with Cloud Foundry and the UAA APIs
      </p></li></ul></div></div><div class="sect3 " id="sec-cap-stratos-metrics-exporter-config-kubernetes"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.6.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes Monitoring</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-metrics-exporter-config-kubernetes">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-metrics-exporter-config-kubernetes</li></ul></div></div></div></div><p>
     This exporter can be enabled/disabled via the Helm value
     <code class="literal">prometheus.kubeStateMetrics.enabled</code>. By default this
     exporter is disabled.
    </p><p>
     You must provide the following Helm chart values for this Exporter to
     work correctly:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       <code class="literal">kubernetes.apiEndpoint</code> - The API Endpoint of the
       Kubernetes API Server
      </p></li></ul></div></div></div><div class="sect2 " id="sec-cap-stratos-metrics-install"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install Stratos Metrics with Helm</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-metrics-install">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-metrics-install</li></ul></div></div></div></div><p>
    In order to display metrics data with Stratos, you need to deploy the
    <code class="literal">stratos-metrics</code> Helm chart. As with othe examples in
    this guide, a YAML file is defined to change configurations of the Helm
    chart.
   </p><p>
    Create a new YAML file. In this example, it is named
    <code class="filename">stratos-metrics-values.yaml</code> and it contains
    configuration options specific to Stratos Metrics.
   </p><p>
    The following is an example <code class="filename">stratos-metrics-values.yaml</code>
    file.
   </p><div class="verbatim-wrap"><pre class="screen">cloudFoundry:
  apiEndpoint: <em class="replaceable ">https://api.example.com</em>
  uaaAdminClient: admin
  uaaAdminClientSecret: <em class="replaceable ">password</em>
  skipSslVerification: "true"
env:
  DOPPLER_PORT: 443
kubernetes:
  apiEndpoint: <em class="replaceable ">kube_server_address.example.com</em>
metrics:
  username: <em class="replaceable ">username</em>
  password: <em class="replaceable ">password</em>
prometheus:
  kubeStateMetrics:
    enabled: true
  server:
    storageClass: <em class="replaceable ">"persistent"</em>
services:
  loadbalanced: true</pre></div><p>
    where:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      <code class="literal">kubernetes.apiEndpoint</code> is the same URL that you used
      when registering your Kubernetes environment with Stratos (the Kubernetes API
      Server URL).
     </p></li><li class="listitem "><p>
      <code class="literal">prometheus.server.storageClass</code> is the storage class to
      be used by Stratos Metrics. If a storage class is not assigned, the
      default storage class will be used. If a storage class is not specified
      and there is no default storage class, the <code class="literal">prometheus</code>
      pod will fail to start.
     </p></li><li class="listitem "><p>
      <code class="literal">metrics.username</code> is the username used to authenticate
      with the nginx server that fronts Prometheus. This username is also used
      during the <a class="xref" href="#sec-cap-stratos-metrics-connect" title="8.6.3. Connecting Stratos Metrics">Section 8.6.3, “Connecting Stratos Metrics”</a>) process.
     </p></li><li class="listitem "><p>
      <code class="literal">metrics.password</code> is the password used to authenticate
      with the nginx server that fronts Prometheus. This password is also used
      during the <a class="xref" href="#sec-cap-stratos-metrics-connect" title="8.6.3. Connecting Stratos Metrics">Section 8.6.3, “Connecting Stratos Metrics”</a>) process.
      Ensure a secure password is chosen.
     </p></li><li class="listitem "><p>
      <code class="literal">services.loadbalanced</code> is set to <code class="literal">true</code>
      if your Kubernetes deployment supports automatic configuration of a load
      balancer (for example, AKS, EKS, and GKE).
     </p></li></ul></div><p>
    If you are using SUSE Enterprise Storage, you must copy the Ceph admin secret to the
    <code class="literal">metrics</code> namespace:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get secret ceph-secret-admin --output json --namespace default | \
sed 's/"namespace": "default"/"namespace": "metrics"/' | kubectl create --filename -</pre></div><p>
    Install Metrics with:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">metrics</em>

<code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">susecf-metrics</em> suse/metrics \
--namespace <em class="replaceable ">metrics</em> \
--values kubecf-config-values.yaml \
--values stratos-metrics-values.yaml</pre></div><p>
    Monitor progress:
   </p><div class="verbatim-wrap"><pre class="screen">$ watch --color 'kubectl get pods --namespace metrics'</pre></div><p>
    When all statuses show <code class="literal">Ready</code>, press <span class="keycap">Ctrl</span><span class="key-connector">–</span><span class="keycap">C</span> to exit and to
    view your release information.
   </p></div><div class="sect2 " id="sec-cap-stratos-metrics-connect"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Connecting Stratos Metrics</span> <a title="Permalink" class="permalink" href="#sec-cap-stratos-metrics-connect">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_stratos.xml</li><li><span class="ds-label">ID: </span>sec-cap-stratos-metrics-connect</li></ul></div></div></div></div><p>
    When Stratos Metrics is connected to Stratos, additional views are enabled
    that show metrics metadata that has been ingested into the Stratos Metrics
    Prometheus server.
   </p><p>
    To enable this, you must register and connect your Stratos Metrics instance
    with Stratos.
   </p><p>
    In the Stratos UI, go to <span class="guimenu ">Endpoints</span> in the left-hand side
    navigation and click on the <span class="guimenu ">+</span> icon in the top-right of
    the view - you should be shown the "Register new Endpoint" view. Next:
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      Select Metrics from the <span class="guimenu ">Endpoint Type</span> dropdown.
     </p></li><li class="step "><p>
      Enter a memorable name for your environment in the
      <span class="guimenu ">Name</span> field.
     </p></li><li class="step "><p>
      Enter the <span class="guimenu ">Endpoint Address</span>. Use the following to find
      the endpoint value.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get service susecf-metrics-metrics-nginx --namespace metrics</pre></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
	For Microsoft AKS, Amazon EKS, and Google GKE deployments which use a load balancer, the
	output will be similar to the following:
       </p><div class="verbatim-wrap"><pre class="screen">NAME                           TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)         AGE
susecf-metrics-metrics-nginx   LoadBalancer   10.0.202.180   52.170.253.229   443:30263/TCP   21h</pre></div><p>
        Preprend <code class="literal">https://</code> to the public IP of the load
        balancer, and enter it into the <span class="guimenu ">Endpoint Address</span>
        field. Using the values from the example above,
        <code class="literal">https://52.170.253.229</code> is entered as the endpoint
        address.
       </p></li><li class="listitem "><p>
        For SUSE CaaS Platform deployments which do not use a load balancer, the output
	will be similar to the following:
       </p><div class="verbatim-wrap"><pre class="screen">NAME                           TYPE       CLUSTER-IP       EXTERNAL-IP               PORT(S)         AGE
susecf-metrics-metrics-nginx   NodePort   172.28.107.209   10.86.101.115,172.28.0.31 443:30685/TCP   21h</pre></div><p>
        Prepend <code class="literal">https://</code> to the external IP of your node,
	followed by the <code class="literal">nodePort</code>, and enter it into the
        <span class="guimenu ">Endpoint Address</span> field. Using the values from the
        example above, <code class="literal">https://10.86.101.115:30685</code> is entered
        as the endpoint address.
       </p></li></ul></div></li><li class="step "><p>
      Check the <span class="guimenu ">Skip SSL validation for the endpoint</span>
      checkbox if using self-signed certificates.
     </p></li><li class="step "><p>
      Click <span class="guimenu ">Finish</span>.
     </p></li></ol></div></div><p>
    The view will refresh to show the new endpoint in the disconnected state.
    Next you will need to connect to this endpoint.
   </p><p>
    In the table of endpoints, click the overflow menu icon alongside the
    endpoint that you added above, then:
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      Click on <span class="guimenu ">Connect</span> in the dropdown menu.
     </p></li><li class="step "><p>
      Enter the username for your Stratos Metrics instance. This will be the
      <code class="literal">metrics.username</code> defined in your
      <code class="filename">stratos-metrics-values.yaml</code> file.
     </p></li><li class="step "><p>
      Enter the password for your Stratos Metrics instance. This will be the
      <code class="literal">metrics.password</code> defined in your
      <code class="filename">stratos-metrics-values.yaml</code> file.
     </p></li><li class="step "><p>
      Click <span class="guimenu ">Connect</span>.
     </p></li></ol></div></div><p>
    Once connected, you should see that the name of your Metrics endpoint is a
    hyperlink and clicking on it should show basic metadata about the Stratos
    Metrics endpoint.
   </p><p>
    Metrics data and views should now be available in the Stratos UI, for
    example:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      On the <span class="guimenu ">Instances</span> tab for an Application, the table
      should show an additional Cell column to indicate which Diego Cell the
      instance is running on. This should be clickable to navigate to a Cell
      view showing Cell information and metrics.
     </p><div class="figure" id="stratos-app-instances-metrics-png"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos-app-instances-metrics.png" target="_blank"><img src="images/stratos-app-instances-metrics.png" width="" alt="Cell Column on Application Instance Tab after Connecting Stratos Metrics" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.9: </span><span class="name">Cell Column on Application Instance Tab after Connecting Stratos Metrics </span><a title="Permalink" class="permalink" href="#stratos-app-instances-metrics-png">#</a></h6></div></div></li><li class="listitem "><p>
      On the view for an Application there should be a new Metrics tab that
      shows Application metrics.
     </p><div class="figure" id="stratos-app-metrics-tab-png"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos-app-metrics-tab.png" target="_blank"><img src="images/stratos-app-metrics-tab.png" width="" alt="Application Metrics Tab after Connecting Stratos Metrics" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.10: </span><span class="name">Application Metrics Tab after Connecting Stratos Metrics </span><a title="Permalink" class="permalink" href="#stratos-app-metrics-tab-png">#</a></h6></div></div></li><li class="listitem "><p>
      On the Kubernetes views, views such as the Node view should show an
      additional <span class="guimenu ">Metrics</span> tab with metric information.
     </p><div class="figure" id="stratos-kubernetes-node-metrics-png"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos-kubernetes-node-metrics.png" target="_blank"><img src="images/stratos-kubernetes-node-metrics.png" width="" alt="Node Metrics on the Stratos Kubernetes View" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 8.11: </span><span class="name">Node Metrics on the Stratos Kubernetes View </span><a title="Permalink" class="permalink" href="#stratos-kubernetes-node-metrics-png">#</a></h6></div></div></li></ul></div></div></div></div><div class="chapter " id="cha-cap-depl-eirini"><div class="titlepage"><div><div><h2 class="title"><span class="number">9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Eirini</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-eirini">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eirini.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-eirini-considerations"><span class="number">9.1 </span><span class="name">Limitations and Other Considerations</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-eirini-enable"><span class="number">9.2 </span><span class="name">Enabling Eirini</span></a></span></dt></dl></div></div><p>
  Eirini, an alternative to Diego, is a scheduler for the Cloud Foundry Application
  Runtime (CFAR) that runs Cloud Foundry user applications in Kubernetes. For details about
  Eirini, see <a class="link" href="https://www.cloudfoundry.org/project-eirini/" target="_blank">https://www.cloudfoundry.org/project-eirini/</a>
  and <a class="link" href="http://eirini.cf" target="_blank">http://eirini.cf</a>
 </p><p>
  Different schedulers and stacks have different memory requirements for
  applications. Not every combination is tested so there is no universal memory
  setting for Cloud Application Platform, and because it depends on the application deployed, it is
  up to the user to adjust the setting based on their application.
 </p><div class="sect1 " id="sec-cap-eirini-considerations"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Limitations and Other Considerations</span> <a title="Permalink" class="permalink" href="#sec-cap-eirini-considerations">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eirini.xml</li><li><span class="ds-label">ID: </span>sec-cap-eirini-considerations</li></ul></div></div></div></div><p>
   When using Eirini, it is important to take into consideration:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     If you are upgrading from SUSE Cloud Application Platform 2.0.1 to 2.1.0 and plan to convert
     from Diego to Eirini, please upgrade your Diego environment to SUSE Cloud Application Platform
     2.1.0 first and then migrate to Eirini as the earlier CAP versions relied a
     technical preview version of Eirini.
    </p><p>
     In this situation, your current applications relying on the
     <code class="literal">cflinuxfs3</code> stack need to be converted to the
     <code class="literal">sle15</code> stack. You can re-push your applications with
     <code class="command">cf push APP_NAME -s sle15</code> to do so, otherwise your
     applications will crash on Eirini.
    </p></li><li class="listitem "><p>
     Applications on Eirini will require slightly more memory than on Diego.
     From testing, add an additional 32 MB to your application's manifest. The
     increase may vary, depending on your application.
    </p></li><li class="listitem "><p>
     TCP routing is not available in Eirini deployments at this time.
    </p></li><li class="listitem "><p>
     Eirini requires the <code class="literal">k8s-metrics-server</code> to be installed
     on the Kubernetes environment where SUSE Cloud Application Platform is installed in order for
     Stratos Metrics to work.
    </p></li><li class="listitem "><p>
     Stratos Metrics will not show disk stats on Eirini.
    </p></li><li class="listitem "><p>
     When there is a Kubernetes outage, Eirini will not automatically restart
     applications upon its return. You will need to manually start them up at
     present.
    </p></li></ul></div></div><div class="sect1 " id="sec-cap-eirini-enable"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling Eirini</span> <a title="Permalink" class="permalink" href="#sec-cap-eirini-enable">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_eirini.xml</li><li><span class="ds-label">ID: </span>sec-cap-eirini-enable</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     To enable Eirini, and disable Diego, add the following to your
     <code class="filename">kubecf-config-values.yaml</code> file.
    </p><div class="verbatim-wrap"><pre class="screen">features:
  eirini:
    enabled: true</pre></div><p>
     When Eirini is enabled, both <code class="literal">features.suse_default_stack</code>
     and <code class="literal">features.suse_buildpacks</code> must be enabled as well.
     A cflinuxfs3 Eirini image is currently not available, and the SUSE stack
     must be used. By default, both the SUSE stack and buildpacks are enabled. 
    </p><div id="id-1.3.4.9.5.2.1.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        After enabling Eirini, you will still see the
        <code class="literal">diego-api</code> pod. This is normal behavior because the Diego pod has a component required by Eirini.
       </p></li><li class="listitem "><p>
        Eirini will only work on a cluster that has the parameter <code class="literal">--cluster-domain</code> set to <code class="literal">cluster.local</code>.
       </p></li></ul></div></div></li><li class="step "><p>
     Deploy <code class="literal">kubecf</code>.
    </p><p>
     Refer to the following for platform-specific instructions:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    For SUSE® CaaS Platform, see <a class="xref" href="#cha-cap-depl-caasp" title="Chapter 4. Deploying SUSE Cloud Application Platform on SUSE CaaS Platform">Chapter 4, <em>Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</em></a>.
   </p></li><li class="listitem "><p>
    For Microsoft Azure Kubernetes Service, see <a class="xref" href="#cha-cap-depl-aks" title="Chapter 5. Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)">Chapter 5, <em>Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Amazon Elastic Kubernetes Service, see <a class="xref" href="#cha-cap-depl-eks" title="Chapter 6. Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)">Chapter 6, <em>Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Google Kubernetes Engine, see <a class="xref" href="#cha-cap-depl-gke" title="Chapter 7. Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)">Chapter 7, <em>Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</em></a>.
   </p></li></ul></div></li><li class="step "><p>
     In order for Eirini to report application metrics, Metrics Server
     (link xlink:href="https://github.com/kubernetes-sigs/metrics-server"/&gt; must 
     be installed.
    </p><p>
     Note that <code class="literal">--kubelet-insecure-tls</code> is not recommended for
     production usage, but can be useful in test clusters with self-signed
     Kubelet serving certificates. For production, use
     <code class="literal">--tls-private-key-file</code>.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">metrics-server</em> stable/metrics-server --set args[0]="--kubelet-preferred-address-types=InternalIP" --set args[1]="--kubelet-insecure-tls"</pre></div></li></ol></div></div></div></div><div class="chapter " id="cha-cap-depl-terraform"><div class="titlepage"><div><div><h2 class="title"><span class="number">10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying SUSE Cloud Application Platform Using Terraform</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-terraform">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_terraform.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"></div><div id="id-1.3.4.10.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        <a class="link" href="https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2.0/" target="_blank">
        SUSE Cloud Application Platform Release Notes</a>
      </p></li><li class="listitem "><p>
        <a class="xref" href="#cha-cap-depl-notes" title="Chapter 3. Deployment and Administration Notes">Chapter 3, <em>Deployment and Administration Notes</em></a>
      </p></li></ul></div></div><p>
  In addition to the manual deployment methods mentioned earlier in this guide,
  operators have the option to deploy SUSE Cloud Application Platform on AWS, Azure, or GCP using
  Terraform. The Terraform scripts will deploy the entirety of SUSE Cloud Application Platform,
  including KubeCF, cf-operator, Stratos, and Stratos Metrics. Operators can
  deploy using Terraform  by following the instructions from
  <a class="link" href="https://github.com/SUSE/cap-terraform" target="_blank">https://github.com/SUSE/cap-terraform</a>.
 </p></div><div class="chapter " id="cha-cap-depl-air-gap-registry"><div class="titlepage"><div><div><h2 class="title"><span class="number">11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Setting Up a Registry for an Air Gapped Environment</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-air-gap-registry">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_air_gap_registry.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-prereqs-air-gap-registry"><span class="number">11.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-air-gap-registry"><span class="number">11.2 </span><span class="name">Mirror Images to Registry</span></a></span></dt></dl></div></div><div id="id-1.3.4.11.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        <a class="link" href="https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2.0/" target="_blank">
        SUSE Cloud Application Platform Release Notes</a>
      </p></li><li class="listitem "><p>
        <a class="xref" href="#cha-cap-depl-notes" title="Chapter 3. Deployment and Administration Notes">Chapter 3, <em>Deployment and Administration Notes</em></a>
      </p></li></ul></div></div><p>
  Cloud Application Platform, which consists of Docker images, is deployed to a Kubernetes cluster
  through Helm. These images are hosted on a Docker registry at
  <code class="literal">registry.suse.com</code>. In an air gapped environment,
  <code class="literal">registry.suse.com</code> will not be accessible. You will need to
  create a registry, and populate it will the images used by Cloud Application Platform.
 </p><p>
  This chapter describes how to load your registry with the necessary images to
  deploy Cloud Application Platform in an air gapped environment.
 </p><div class="sect1 " id="sec-cap-prereqs-air-gap-registry"><div class="titlepage"><div><div><h2 class="title"><span class="number">11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#sec-cap-prereqs-air-gap-registry">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_air_gap_registry.xml</li><li><span class="ds-label">ID: </span>sec-cap-prereqs-air-gap-registry</li></ul></div></div></div></div><p>
   The following prerequisites are required:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The Docker Command Line. See
     <a class="link" href="https://docs.docker.com/engine/reference/commandline/cli/" target="_blank">https://docs.docker.com/engine/reference/commandline/cli/</a>
     for more information.
    </p></li><li class="listitem "><p>
     A Docker registry has been created in your air gapped environment. Refer to
     the Docker documentation at
     <a class="link" href="https://docs.docker.com/registry/" target="_blank">https://docs.docker.com/registry/</a> for instructions.
    </p></li></ul></div></div><div class="sect1 " id="sec-cap-air-gap-registry"><div class="titlepage"><div><div><h2 class="title"><span class="number">11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Mirror Images to Registry</span> <a title="Permalink" class="permalink" href="#sec-cap-air-gap-registry">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_air_gap_registry.xml</li><li><span class="ds-label">ID: </span>sec-cap-air-gap-registry</li></ul></div></div></div></div><p>
   All the Cloud Application Platform Helm charts include an <code class="filename">imagelist.txt</code>
   file that lists all images from the <code class="literal">registry.suse.com</code>
   registry under the <code class="literal">cap</code> organization. They can be mirrored
   to a local registry with the following script.
  </p><p>
   Replace the value of <code class="literal">MIRROR</code> with your registry's domain.
  </p><div class="verbatim-wrap"><pre class="screen">#!/bin/bash

MIRROR=<em class="replaceable ">MY_REGISTRY.COM</em>

set -ex

function mirror {
    CHART=$1
    CHARTDIR=$(mktemp -d)
    helm fetch suse/$1 --untar --untardir=${CHARTDIR}
    IMAGES=$(cat ${CHARTDIR}/**/imagelist.txt)
    for IMAGE in ${IMAGES}; do
        echo $IMAGE
        docker pull registry.suse.com/cap/$IMAGE
        docker tag registry.suse.com/cap/$IMAGE $MIRROR/cap/$IMAGE
        docker push $MIRROR/cap/$IMAGE
    done
    docker save -o ${CHART}-images.tar.gz \
           $(perl -E "say qq(registry.suse.com/cap/\$_) for @ARGV" ${IMAGES})
    rm -r ${CHARTDIR}
}

mirror cf-operator
mirror kubecf
mirror console
mirror metrics
mirror minibroker</pre></div><p>
   The script above will both mirror to a local registry and save the images in
   a local tarball that can be restored with
   <code class="command">docker load foo-images.tgz</code>. In general only one of these
   mechanisms will be needed.
  </p><p>
   Also take note of the following regarding the script provided above.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The <code class="literal">nginx-ingress</code> chart is not supported by this
     mechanism because it is not part of the <code class="literal">cap</code> organization
     (and cannot be configured with the
     <code class="literal">kube.registry.hostname</code> setting at deploy time either).
    </p><p>
     Instead manually parse the Helm chart for the image names and do a manual
     <code class="command">docker pull &amp;&amp; docker tag &amp;&amp; docker push</code>
     on them.
    </p></li></ul></div><p>
   Before deploying Cloud Application Platform using <code class="command">helm install</code>, ensure the
   following in your
   <code class="filename">kubecf-config-values.yaml</code> has been updated to point to your
   registry, and not <code class="literal">registry.suse.com</code>.
  </p><div class="verbatim-wrap"><pre class="screen">kube:
  registry:
    # example registry domain
    hostname: <em class="replaceable ">"MY_REGISTRY.COM"</em>
    username: ""
    password: ""
  organization: "cap"</pre></div></div></div><div class="chapter " id="cha-cap-depl-private-registry"><div class="titlepage"><div><div><h2 class="title"><span class="number">12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">SUSE Private Registry</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-private-registry">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_depl_private_registry.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"></div><div id="id-1.3.4.12.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
  Before you start deploying SUSE Cloud Application Platform, review the following documents:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        <a class="link" href="https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2.0/" target="_blank">
        SUSE Cloud Application Platform Release Notes</a>
      </p></li><li class="listitem "><p>
        <a class="xref" href="#cha-cap-depl-notes" title="Chapter 3. Deployment and Administration Notes">Chapter 3, <em>Deployment and Administration Notes</em></a>
      </p></li></ul></div></div><p>
  SUSE Cloud Application Platform offers SUSE Private Registry as an Open Container Initiative
  (OCI) registry solution to store, replicate, manage, and secure OCI images and
  artifacts. Operators who opt to use SUSE Private Registry can follow the
  configuration and installation instructions from
  <a class="link" href="https://documentation.suse.com/sbp/all/single-html/SBP-Private-Registry" target="_blank">https://documentation.suse.com/sbp/all/single-html/SBP-Private-Registry</a>.
 </p></div></div><div class="part" id="part-cap-administration"><div class="titlepage"><div><div><h1 class="title"><span class="number">Part III </span><span class="name">SUSE Cloud Application Platform Administration </span><a title="Permalink" class="permalink" href="#part-cap-administration">#</a></h1></div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="#cha-cap-upgrade"><span class="number">13 </span><span class="name">Upgrading SUSE Cloud Application Platform</span></a></span></dt><dd class="toc-abstract"><p>
  SUSE Cloud Application Platform upgrades are delivered as container images from the SUSE
  registry and applied with Helm.
 </p></dd><dt><span class="chapter"><a href="#cha-cap-configuration-changes"><span class="number">14 </span><span class="name">Configuration Changes</span></a></span></dt><dd class="toc-abstract"><p>
  After the initial deployment of Cloud Application Platform, any changes made to your Helm chart
  values, whether through your <code class="filename">kubecf-config-values.yaml</code> file
  or directly using Helm's <code class="command">--set</code> flag, are applied using
  the <code class="command">helm upgrade</code> command.
 </p></dd><dt><span class="chapter"><a href="#cha-cap-create-admin-user"><span class="number">15 </span><span class="name">Creating Admin Users</span></a></span></dt><dd class="toc-abstract"><p>
  This chapter provides an overview on how to create additional
  administrators for your Cloud Application Platform cluster.
 </p></dd><dt><span class="chapter"><a href="#cha-cap-manage-passwords"><span class="number">16 </span><span class="name">Managing Passwords</span></a></span></dt><dd class="toc-abstract"><p>The various components of SUSE Cloud Application Platform authenticate to each other using passwords that are automatically managed by the Cloud Application Platform secrets-generator. The only passwords managed by the cluster administrator are passwords for human users. The administrator may create…</p></dd><dt><span class="chapter"><a href="#cha-cap-uaa-ui"><span class="number">17 </span><span class="name">Accessing the UAA User Interface</span></a></span></dt><dd class="toc-abstract"><p>After UAA is deployed successfully, users will not be able to log in to the UAA user interface (UI) with the admin user and the UAA_ADMIN_CLIENT_SECRET credentials. This user is only an OAuth client that is authorized to call UAA REST APIs and will need to create a separate user in the UAA server by…</p></dd><dt><span class="chapter"><a href="#cha-cap-memory-limits"><span class="number">18 </span><span class="name">Container Memory Limits and Requests</span></a></span></dt><dd class="toc-abstract"><p>
  In SUSE Cloud Application Platform, containers have predefined memory limits and request sizes.
  Depending on the workload, these may need to be adjusted in some cases.
 </p></dd><dt><span class="chapter"><a href="#cha-cap-ccdb-secret-rotation"><span class="number">19 </span><span class="name">Cloud Controller Database Secret Rotation</span></a></span></dt><dd class="toc-abstract"><p>The Cloud Controller Database (CCDB) encrypts sensitive information like passwords. The encryption key is generated when KubeCF is deployed. If it is compromised or needs to be rotated for any other reason, new keys can be added. Note that existing encrypted information will not be updated. The encr…</p></dd><dt><span class="chapter"><a href="#cha-cap-secrets-rotation"><span class="number">20 </span><span class="name">Rotating Automatically Generated Secrets</span></a></span></dt><dd class="toc-abstract"><p>Cloud Application Platform uses a number of automatically generated secrets (passwords and certificates) for use internally provided by cf-operator. This removes the burden from human operators while allowing for secure communication. From time to time, operators may wish to change such secrets, eit…</p></dd><dt><span class="chapter"><a href="#cha-cap-backup-restore"><span class="number">21 </span><span class="name">Backup and Restore</span></a></span></dt><dd class="toc-abstract"><p>
   <code class="literal">cf-plugin-backup</code> backs up and restores your Cloud
   Controller Database (CCDB), using the Cloud Foundry command line interface (cf CLI).
   (See <a class="xref" href="#sec-cap-cf-cli" title="26.1. Using the cf CLI with SUSE Cloud Application Platform">Section 26.1, “Using the cf CLI with SUSE Cloud Application Platform”</a>.)
  </p></dd><dt><span class="chapter"><a href="#cha-cap-service-brokers"><span class="number">22 </span><span class="name">Service Brokers</span></a></span></dt><dd class="toc-abstract"><p>The Open Service Broker API provides (OSBAPI) your SUSE Cloud Application Platform applications with access to external dependencies and platform-level capabilities, such as databases, filesystems, external repositories, and messaging systems. These resources are called services. Services are create…</p></dd><dt><span class="chapter"><a href="#cha-cap-app-autoscaler"><span class="number">23 </span><span class="name">App-AutoScaler</span></a></span></dt><dd class="toc-abstract"><p>
  The App-AutoScaler service is used for automatically managing an
  application's instance count when deployed on KubeCF. The scaling behavior is
  determined by a set of criteria defined in a policy (See
  <a class="xref" href="#sec-cap-app-autoscaler-policies" title="23.4. Policies">Section 23.4, “Policies”</a>).
 </p></dd><dt><span class="chapter"><a href="#cha-cap-credhub"><span class="number">24 </span><span class="name">Integrating CredHub with SUSE Cloud Application Platform</span></a></span></dt><dd class="toc-abstract"><p>
  SUSE Cloud Application Platform supports CredHub integration. You should already have a working
  CredHub instance, a CredHub service on your cluster, then apply the steps in
  this chapter to connect SUSE Cloud Application Platform.
 </p></dd><dt><span class="chapter"><a href="#cha-cap-buildpacks"><span class="number">25 </span><span class="name">Buildpacks</span></a></span></dt><dd class="toc-abstract"><p>Buildpacks are used to construct the environment needed to run your applications, including any required runtimes or frameworks as well as other dependencies. When you deploy an application, a buildpack can be specified or automatically detected by cycling through all available buildpacks to find on…</p></dd></dl></div><div class="chapter " id="cha-cap-upgrade"><div class="titlepage"><div><div><h2 class="title"><span class="number">13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upgrading SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#cha-cap-upgrade">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_upgrade.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-upgrade-considerations"><span class="number">13.1 </span><span class="name">Important Considerations</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-update"><span class="number">13.2 </span><span class="name">Upgrading SUSE Cloud Application Platform</span></a></span></dt></dl></div></div><p>
  SUSE Cloud Application Platform upgrades are delivered as container images from the SUSE
  registry and applied with Helm.
 </p><p>
   For additional upgrade information, always review the release notes
   published at
   <a class="link" href="https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2/" target="_blank">https://www.suse.com/releasenotes/x86_64/SUSE-CAP/2/</a>.
 </p><div class="sect1 " id="sec-cap-upgrade-considerations"><div class="titlepage"><div><div><h2 class="title"><span class="number">13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Important Considerations</span> <a title="Permalink" class="permalink" href="#sec-cap-upgrade-considerations">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_upgrade.xml</li><li><span class="ds-label">ID: </span>sec-cap-upgrade-considerations</li></ul></div></div></div></div><p>
   Before performing an upgrade, be sure to take note of the following:
  </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.5.3.4.3.1"><span class="term ">Perform Upgrades in Sequence</span></dt><dd><p>
      Cloud Application Platform only supports upgrading releases in sequential order. If there are
      any intermediate releases between your current release and your target
      release, they must be installed. Skipping releases is not supported.
     </p></dd><dt id="id-1.3.5.3.4.3.2"><span class="term ">Preserve Helm Value Changes during Upgrades</span></dt><dd><p>
      During a <code class="command">helm upgrade</code>, always ensure your
      <code class="filename">kubecf-config-values.yaml</code> file is passed. This will
      preserve any previously set Helm values while allowing additional
      Helm value changes to be made.
     </p></dd><dt id="id-1.3.5.3.4.3.3"><span class="term "><code class="command">helm rollback</code> Is Not Supported</span></dt><dd><p>
      <code class="command">helm rollback</code> is not supported in SUSE Cloud Application Platform or in
      upstream Cloud Foundry, and may break your cluster completely, because database
      migrations only run forward and cannot be reversed. Database schema can
      change over time. During upgrades both pods of the current and the next
      release may run concurrently, so the schema must stay compatible with the
      immediately previous release. But there is no way to guarantee such
      compatibility for future upgrades. One way to address this is to perform a
      full raw data backup and restore. (See
      <a class="xref" href="#sec-cap-backup-restore-of-raw-data" title="21.2. Disaster Recovery through Raw Data Backup and Restore">Section 21.2, “Disaster Recovery through Raw Data Backup and Restore”</a>)
     </p></dd></dl></div></div><div class="sect1 " id="sec-cap-update"><div class="titlepage"><div><div><h2 class="title"><span class="number">13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upgrading SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#sec-cap-update">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_upgrade.xml</li><li><span class="ds-label">ID: </span>sec-cap-update</li></ul></div></div></div></div><p>
   The supported upgrade method is to install all upgrades, in order. Skipping
   releases is not supported. This table matches the Helm chart versions to
   each release:
  </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col /><col /><col /><col /><col /><col /><col /><col /><col /></colgroup><thead><tr><th>CAP Release</th><th>cf-operator Helm Chart Version</th><th>KubeCF Helm Chart Version</th><th>Stratos Helm Chart Version</th><th>Stratos Metrics Helm Chart Version</th><th>Minimum Kubernetes Version Required</th><th>CF API Implemented</th><th>Known Compatible CF CLI Version</th><th>CF CLI URL</th></tr></thead><tbody><tr><td>2.1.0 (current release)</td><td>6.1.17+0.gec409fd7</td><td>2.5.8</td><td>4.2.0</td><td>1.3.0</td><td>1.14</td><td>2.144.0</td><td>6.49.0</td><td><a class="link" href="https://github.com/cloudfoundry/cli/releases/tag/v6.49.0" target="_blank">https://github.com/cloudfoundry/cli/releases/tag/v6.49.0</a></td></tr><tr><td>2.0.1</td><td>4.5.13+.gd4738712</td><td>2.2.3</td><td>4.0.1</td><td>1.2.1</td><td>1.14</td><td>2.144.0</td><td>6.49.0</td><td><a class="link" href="https://github.com/cloudfoundry/cli/releases/tag/v6.49.0" target="_blank">https://github.com/cloudfoundry/cli/releases/tag/v6.49.0</a></td></tr><tr><td>2.0</td><td>4.5.6+0.gffc6f942</td><td>2.2.2</td><td>3.2.1</td><td>1.2.1</td><td>1.14</td><td>2.144.0</td><td>6.49.0</td><td><a class="link" href="https://github.com/cloudfoundry/cli/releases/tag/v6.49.0" target="_blank">https://github.com/cloudfoundry/cli/releases/tag/v6.49.0</a></td></tr></tbody></table></div><p>
   Use <code class="command">helm list</code> to see the version of your installed release
   . Perform sequential upgrades until you reach the desired SUSE Cloud Application Platform
   release.
  </p><p>
   The process to upgrade SUSE Cloud Application Platform will differ depending on the versions
   involved.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     For upgrades from SUSE Cloud Application Platform 2.0.1 to SUSE Cloud Application Platform 2.1.0, see
     <a class="xref" href="#sec-cap-update-201-to-210" title="13.2.1. Upgrading from SUSE Cloud Application Platform 2.0.1 to SUSE Cloud Application Platform 2.1.0">Section 13.2.1, “Upgrading from SUSE Cloud Application Platform 2.0.1 to SUSE Cloud Application Platform 2.1.0”</a>.
    </p></li><li class="listitem "><p>                                                                       
     For upgrades from SUSE Cloud Application Platform 2.0 to SUSE Cloud Application Platform 2.0.1, see                 
     <a class="xref" href="#sec-cap-update-20-to-201" title="13.2.2. Upgrading from SUSE Cloud Application Platform 2.0 to SUSE Cloud Application Platform 2.0.1">Section 13.2.2, “Upgrading from SUSE Cloud Application Platform 2.0 to SUSE Cloud Application Platform 2.0.1”</a>.                                
    </p></li><li class="listitem "><p>
     For upgrades from SUSE Cloud Application Platform 1.5.2 to SUSE Cloud Application Platform 2.0, see
     <a class="xref" href="#sec-cap-update-152-to-20" title="13.2.3. Upgrading from SUSE Cloud Application Platform 1.5.2 to SUSE Cloud Application Platform 2.0">Section 13.2.3, “Upgrading from SUSE Cloud Application Platform 1.5.2 to SUSE Cloud Application Platform 2.0”</a>.
    </p></li></ul></div><div class="sect2 " id="sec-cap-update-201-to-210"><div class="titlepage"><div><div><h3 class="title"><span class="number">13.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upgrading from SUSE Cloud Application Platform 2.0.1 to SUSE Cloud Application Platform 2.1.0</span> <a title="Permalink" class="permalink" href="#sec-cap-update-201-to-210">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_upgrade.xml</li><li><span class="ds-label">ID: </span>sec-cap-update-201-to-210</li></ul></div></div></div></div><p>
    The following procedure will upgrade SUSE Cloud Application Platform 2.0.1 to SUSE Cloud Application Platform
    2.1.0
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      Begin by upgrading cf-operator.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">cf-operator</em> suse/cf-operator \
 --namespace <em class="replaceable ">cf-operator</em> \
 --set "global.operator.watchNamespace=<em class="replaceable ">kubecf</em>" \
 --version 6.1.17+0.gec409fd7</pre></div></li><li class="step "><p>
     Wait until cf-operator is successfully upgraded before proceeding. Monitor
     the status of your cf-operator upgrade using the <code class="command">watch</code>
     command.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">cf-operator</em>'</pre></div></li><li class="step "><p>
      When the cf-operator upgrade is completed, upgrade KubeCF. If you are
      planning to convert from Diego to Eirini, please upgrade your environment
      to CAP 2.1.0 first, then migrate to Eirini as the earlier CAP versions
      relied on a technical preview version of Eirini.
     </p><ol type="a" class="substeps "><li class="step "><p>
        Skip this step f you are not using an HA setup of the internal database
        in CAP 2.0.1. Otherwise you will need to scale down
        <code class="literal">sizing.database.instances</code> to 1 in order to upgrade to
        CAP 2.1.0. Running a high available version of the internal database
        during the upgrade will result in confusion during the password rotation
        process and you will run into difficulties recovering from it.
     </p></li><li class="step "><p>
      Perform the KubeCF upgrade. During the upgrade, applications will
      experience some downtime.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">kubecf</em> suse/kubecf \
 --namespace <em class="replaceable ">kubecf</em> \
 --values kubecf-config-values.yaml \
 --version 2.5.8</pre></div></li></ol></li><li class="step "><p>
      Monitor the status of your KubeCF upgrade using the <code class="command">watch</code>
      command.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">kubecf</em>'</pre></div></li></ol></div></div></div><div class="sect2 " id="sec-cap-update-20-to-201"><div class="titlepage"><div><div><h3 class="title"><span class="number">13.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upgrading from SUSE Cloud Application Platform 2.0 to SUSE Cloud Application Platform 2.0.1</span> <a title="Permalink" class="permalink" href="#sec-cap-update-20-to-201">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_upgrade.xml</li><li><span class="ds-label">ID: </span>sec-cap-update-20-to-201</li></ul></div></div></div></div><p>
    The following procedure will upgrade SUSE Cloud Application Platform 2.0 to SUSE Cloud Application Platform
    2.0.1.
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      Begin by upgrading cf-operator.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">cf-operator</em> suse/cf-operator \
 --namespace <em class="replaceable ">cf-operator</em> \
 --set "global.operator.watchNamespace=<em class="replaceable ">kubecf</em>" \
 --version 4.5.13+.gd4738712</pre></div></li><li class="step "><p>
     Wait until cf-operator is successfully upgraded before proceeding. Monitor
     the status of your cf-operator upgrade using the <code class="command">watch</code>
     command.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">cf-operator</em>'</pre></div></li><li class="step "><p>
      When the cf-operator upgrade is completed, upgrade KubeCF.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">kubecf</em> suse/kubecf \
 --namespace <em class="replaceable ">kubecf</em> \
 --values kubecf-config-values.yaml \
 --version 2.2.3</pre></div></li><li class="step "><p>
      Monitor the status of your KubeCF upgrade using the <code class="command">watch</code>
      command.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace <em class="replaceable ">kubecf</em>'</pre></div></li></ol></div></div></div><div class="sect2 " id="sec-cap-update-152-to-20"><div class="titlepage"><div><div><h3 class="title"><span class="number">13.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upgrading from SUSE Cloud Application Platform 1.5.2 to SUSE Cloud Application Platform 2.0</span> <a title="Permalink" class="permalink" href="#sec-cap-update-152-to-20">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_upgrade.xml</li><li><span class="ds-label">ID: </span>sec-cap-update-152-to-20</li></ul></div></div></div></div><p>
    The transition from SUSE Cloud Application Platform 1.5.2 to SUSE Cloud Application Platform 2.0 involves a
    migration of data rather than a direct upgrade. This process is outlined in
    the subsections below.
   </p><div id="id-1.3.5.3.5.9.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Scope of Migration</h6><p>
     This procedure only imports the UAA and CC databases. It does not import the
     Credhub and Diego BBS databases. Service credentials from Credhub are
     missing, and Diego does not know anything about the desired app states
     All running apps need to be restarted so that Diego knows about them.
    </p><p>
     This whole procedure also does not deal with exporting and recreating
     services.
    </p></div><div class="sect3 " id="sec-cap-upgrade-export-scf"><div class="titlepage"><div><div><h4 class="title"><span class="number">13.2.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Export Data from Existing SCF Deployment</span> <a title="Permalink" class="permalink" href="#sec-cap-upgrade-export-scf">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_upgrade.xml</li><li><span class="ds-label">ID: </span>sec-cap-upgrade-export-scf</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
       Export the blobstore.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --namespace scf blobstore-0 -- tar cfz -
 --exclude=/var/vcap/store/shared/tmp /var/vcap/store/shared &gt; blob.tgz</pre></div></li><li class="step "><p>
       Export the User Account and Authentication database (UAADB).
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec mysql-0 --namespace uaa -- bash -c
 '/var/vcap/packages/mariadb/bin/mysqldump \
    --defaults-file=/var/vcap/jobs/mysql/config/mylogin.cnf \
    --socket /var/vcap/sys/run/pxc-mysql/mysqld.sock \
    uaadb' &gt; uaadb-src.sql</pre></div></li><li class="step "><p>
       Export the Cloud Controller database (CCDB).
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec mysql-0 --namespace scf -- bash -c
 '/var/vcap/packages/mariadb/bin/mysqldump \
    --defaults-file=/var/vcap/jobs/mysql/config/mylogin.cnf \
    --socket /var/vcap/sys/run/pxc-mysql/mysqld.sock \
    ccdb' &gt; ccdb-src.sql</pre></div></li><li class="step "><p>
       Save database encryption key.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --stdin --tty --namespace scf api-group-0 --
 bash -c "cat /var/vcap/jobs/cloud_controller_ng/config/cloud_controller_ng.yml |
 grep -A 10 db_encryption" &gt; enc_key</pre></div></li><li class="step "><p>
       Lock all buildpacks.
      </p><p>
       When the Cloud Controller (CC) starts, it will replace all unlocked admin
       buildpacks with the versions bundled with the release. So if the
       buildpacks from the 1.5.2 export are required to restage applications,
       then they need to be locked before the CCDB is exported.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>for BP in $(cf buildpacks | perl -ne 'print if
 s/(_buildpack).*/\1/' | uniq); do cf update-buildpack $BP -s sle15 --lock; done

 <code class="prompt user">tux &gt; </code>for BP in $(cf buildpacks | perl -ne 'print if
 s/(_buildpack).*/\1/' | uniq); do cf update-buildpack $BP -s cflinuxfs3 --lock;
 done</pre></div></li><li class="step "><p>
       Rotate secrets and database encryption key. Do not copy the example as is,
 ensure a secure key is used in place of the example value of
 <em class="replaceable ">abcdef</em>.
      </p><ol type="a" class="substeps "><li class="step "><p>
         If the deployment uses an embedded UAA or an external UAA with a
         certificate signed by a well known Certificate Authority (CA), skip this
         step.
        </p><p>
         For deployments using an external UAA with either a certificate
         generated by the secret-generator or a self-signed certificate, the
         UAA's CA cert (<code class="literal">UAA_CA_CERT</code>) must be set in the
         <code class="command">helm upgrade</code> command.
        </p><p>
         Obtain your UAA secret and certificate: 
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SECRET=$(kubectl get pods --namespace uaa \
 --output
 jsonpath='{.items[?(.metadata.name=="uaa-0")].spec.containers[?(.name=="uaa")].env[?(.name=="INTERNAL_CA_CERT")].valueFrom.secretKeyRef.name}')

 <code class="prompt user">tux &gt; </code>CA_CERT="$(kubectl get secret $SECRET --namespace uaa \
 --output jsonpath="{.data['internal-ca-cert']}" | base64 --decode -)"</pre></div><p>
         Then include <code class="command">--set "secrets.UAA_CA_CERT=${CA_CERT}"</code>
         as part of the <code class="command">helm upgrade</code> command in the next step. 
        </p></li><li class="step "><p>
         Use <code class="command">helm upgrade</code> to apply the configuration update
         and rotate all generated secrets.
        </p><p>
         If secrets have been rotated previously 
         <code class="literal">kube.secrets_generation_counter</code> has
         already been set), be sure the new value provided for
         <code class="literal">kube.secrets_generation_counter</code> is an increment of
         the existing one.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade susecf-scf suse/cf \
 --namespace <em class="replaceable ">scf</em> \
 --set env.CC_DB_CURRENT_KEY_LABEL=<em class="replaceable ">NEW_KEY</em> \
 --set
 secrets.CC_DB_ENCRYPTION_KEYS.<em class="replaceable ">NEW_KEY</em>=<em class="replaceable ">abcdef</em>
 \
 --set kube.secrets_generation_counter=<em class="replaceable ">2</em> \
 --values scf-config-values.yaml \
 --version 2.20.3</pre></div><p>
         Wait until all pods are ready. To monitor the progress run the following
         command.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace
 scf'</pre></div></li><li class="step "><p>
         With the new encryption key in place, perform the rotation.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --namespace scf api-group-0 -- bash -c 'source
 /var/vcap/jobs/cloud_controller_ng/bin/ruby_version.sh; export
 CLOUD_CONTROLLER_NG_CONFIG=/var/vcap/jobs/cloud_controller_ng/config/cloud_controller_ng.yml;
 cd /var/vcap/packages/cloud_controller_ng/cloud_controller_ng; bundle exec rake
 rotate_cc_database_key:perform'</pre></div></li><li class="step "><p>
         Restart the pods for the changes to take effect.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl delete pod api-group-0 --namespace scf
 <code class="prompt user">tux &gt; </code>kubectl delete pod cc-worker-0 --namespace scf
 <code class="prompt user">tux &gt; </code>kubectl delete pod cc-clock-0 --namespace scf</pre></div></li></ol></li><li class="step "><p>
       Save the CCDB with locked buildpacks and rotated secrets/encryption keys.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec mysql-0 --namespace scf -- bash -c
 '/var/vcap/packages/mariadb/bin/mysqldump \
   --defaults-file=/var/vcap/jobs/mysql/config/mylogin.cnf \
   --socket /var/vcap/sys/run/pxc-mysql/mysqld.sock \
   ccdb' &gt; ccdb-rotated-src.sql

 <code class="prompt user">tux &gt; </code>kubectl exec --stdin --tty --namespace scf api-group-0 -- bash -c
 "cat /var/vcap/jobs/cloud_controller_ng/config/cloud_controller_ng.yml | grep -A
 10 db_encryption" &gt; enc_key_rotated</pre></div></li><li class="step "><p>
       Verify you have collected all required files.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>ls -l
 -rw-r--r-- 1 501 20 217539560 May 27 18:23 blob.tgz
 -rw-r--r-- 1 501 20    231904 May 27 19:53 ccdb-rotated-src.sql
 -rw-r--r-- 1 501 20    225726 May 27 18:24 ccdb-src.sql
 -rw-r--r-- 1 501 20       220 May 27 18:29 enc_key
 -rw-r--r-- 1 501 20       245 May 27 19:51 enc_key_rotated
 -rw-r--r-- 1 501 20     66281 May 27 18:24 uaadb-src.sql</pre></div></li></ol></div></div></div><div class="sect3 " id="sec-cap-upgrade-import-kube"><div class="titlepage"><div><div><h4 class="title"><span class="number">13.2.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Import Data into New KubeCF Deployment</span> <a title="Permalink" class="permalink" href="#sec-cap-upgrade-import-kube">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_upgrade.xml</li><li><span class="ds-label">ID: </span>sec-cap-upgrade-import-kube</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
       Deploy a SUSE Cloud Application Platform 2.0 cluster. Refer to the instructions for your
       target platform. Use <code class="literal">4.5.6+0.gffc6f942</code> as the
       cf-operator version and <code class="literal">2.2.2</code> as the KubeCF version.
      </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    For SUSE® CaaS Platform, see <a class="xref" href="#cha-cap-depl-caasp" title="Chapter 4. Deploying SUSE Cloud Application Platform on SUSE CaaS Platform">Chapter 4, <em>Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</em></a>.
   </p></li><li class="listitem "><p>
    For Microsoft Azure Kubernetes Service, see <a class="xref" href="#cha-cap-depl-aks" title="Chapter 5. Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)">Chapter 5, <em>Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Amazon Elastic Kubernetes Service, see <a class="xref" href="#cha-cap-depl-eks" title="Chapter 6. Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)">Chapter 6, <em>Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Google Kubernetes Engine, see <a class="xref" href="#cha-cap-depl-gke" title="Chapter 7. Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)">Chapter 7, <em>Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</em></a>.
   </p></li></ul></div></li><li class="step "><p>
       Import the UAA database.
      </p><p>
       The current database configuration does not allow importing of a mysqldump
       , so needs to be made more permissive
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cat &lt;&lt;EOF | kubectl exec -i database-0 --namespace
 kubecf -- mysql
 SET GLOBAL pxc_strict_mode=PERMISSIVE;
 SET GLOBAL
 sql_mode='STRICT_ALL_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';
 set GLOBAL innodb_strict_mode='OFF';
 EOF</pre></div><p>
       It is not possible to drop the KubeCF database for UAA and import the
       version from SCF. KubeCF has additional clients and scopes that would
       get lost. So the migration strategy is to only extract users and
       passwords from the export, and add them to KubeCF. Since this is a new
       setup, none of the users should exist. Except for <code class="literal">admin</code>
       , so we are only updating the password for that user.
     </p><p>
       The <code class="filename">adduser.pl</code> script will also update all identity
       zone ids to <code class="literal">uaa</code>, in case the export comes from an
       external and not an embedded UAA.
      </p><div class="verbatim-wrap"><pre class="screen"># adduser.pl
 use strict;
 use warnings;

 my %table;
 while (&lt;&gt;) {
     my($insert,$table,$values) = /^(INSERT INTO `(.*?)` VALUES) (.*);$/ or next;

     my $literal_value = qr/ ' (?: [^'\\] | '' | \\. )* ' | -?\w+ /x;
     # Each row contains the comma-separated list of values including the
     # surrounding parens.
     my @rows = $values =~ / \( (?: (?: $literal_value ) ,? )+ \) /gx;

     my @records;
     # Each record is a reference to a list of all fields of a row.
     foreach my $record (map [/$literal_value/g], @rows) {
         # Replace old identity_zone_id with 'uaa'.
         my %zone_id_column = (group_membership =&gt; 7, groups =&gt; 5,
 oauth_client_details =&gt; 11,
                               user_google_mfa_credentials =&gt; 5, users =&gt; 15);
         $record-&gt;[$zone_id_column{$table}] = "'uaa'" if defined
 $zone_id_column{$table};

         # Admin user name has changed from uaaadmin to uaa.
         $record-&gt;[6] = 'uaa' if $table eq "schema_version";

         push @records, $record;
     }
     $table{$table} = \@records;
 }

 my $users = $table{users};
 my $admin = (grep $_-&gt;[4] eq "'admin'", @$users)[0];
 die unless $admin;
 my $admin_id = $admin-&gt;[0];

 # Set admin password to exported value.
 printf "UPDATE `users` SET password = %s WHERE username = 'admin';\n",
 $admin-&gt;[5];

 # Export all tables that have a user_id column.
 my %id_column = (user_google_mfa_credentials =&gt; 0, user_info =&gt; 0, users =&gt; 0);
 for my $table (keys %id_column) {
     # Add records for all users, except 'admin'.
     for my $record (grep $_-&gt;[$id_column{$table}] ne $admin_id,
 @{$table{$table}}) {
         printf "INSERT INTO `$table` VALUES(%s);\n", join(",", @$record);
     }
 }</pre></div><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>perl adduser.pl uaadb-src.sql &gt; adduser.sql
 cat adduser.sql

 kubectl exec -i database-0 --namespace kubecf -- mysql uaa &lt; adduser.sql

 echo "select username from uaa.users;" | kubectl exec -i database-0 --namespace
 kubecf -- mysql
 cf login --skip-ssl-validation -a https://api.&lt;system_domain&gt; -u admin -p
 changeme</pre></div></li><li class="step "><p>
       Import the blobstore.
      </p><p>
       The blobstore is still empty, except for the admin buildpacks. The
       buildpacks will be reinstalled anyways, unless the CCDB in the export has
       them locked, so deleting them here is kind of optional.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --namespace kubecf singleton-blobstore-0 -- rm
 -rf /var/vcap/store/shared/cc-buildpacks
 <code class="prompt user">tux &gt; </code>kubectl exec -i --namespace kubecf singleton-blobstore-0 -- tar xfz
 - -C / &lt; blob.tgz
 <code class="prompt user">tux &gt; </code>kubectl delete pod --namespace kubecf singleton-blobstore-0</pre></div></li><li class="step "><p>
       Import the Cloud Controller database (CCDB).
      </p><p>
       The CC database includes routes, that <span class="emphasis"><em>may</em></span> need to be
 updated for the new
       cluster. The list of migrations also includes artificial
       "squashed migrations" that are generated by SCF to combine all previous
       migrations into a single transaction. These squashed migrations don't
       exist in KubeCF and must be filtered out. The original migrations still
       exist in the table, so no other actions are required.
      </p><div class="verbatim-wrap"><pre class="screen"># normalize.pl
 use strict;
 use warnings;

 while (&lt;&gt;) {
     if (my($insert,$table,$values) = /^(INSERT INTO `(.*?)` VALUES) (.*);$/) {
         my $literal_value = qr/ ' (?: [^'\\] | '' | \\. )* ' | -?\w+ /x;
         # Each row contains the comma-separated list of values including the
         # surrounding parens.
         my @rows = $values =~ / \( (?: (?: $literal_value ) ,? )+ \) /gx;

         my @records;
         # Each record is a reference to a list of all fields of a row.
         foreach my $record (map [/$literal_value/g], @rows) {
             # Squashed migration are an SCF optimization that doesn't exist in
             # kubecf.
             next if $table eq "schema_migrations" &amp;&amp; $record-&gt;[0] =~
 /^'\d+_squashed_migrations.rb'$/;
             push @records, $record;
         }

         # Print each row on a separate line for easier reading/comparison.
         printf "$insert\n%s;\n", join(",\n", map(sprintf("  (%s)", join(",",
 @$_)), @records));
         next;
     }

     print;
 }</pre></div><p>
       For a CCDB that has not been rotated:
      </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
         Update the routes for the new cluster in the
         <code class="filename">ccdb-src.sql</code> file. Replace the placeholders values
         with the value of <code class="literal">DOMAIN</code> from the SCF cluster and the
         value of <code class="literal">system_domain</code> from the KubeCF cluster.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sed
 "s/<em class="replaceable ">SCF_DOMAIN</em>/<em class="replaceable ">KubeCF_system_domain</em>/g"
 ccdb-src.sql &gt; ccdb-src-kubecf.sql</pre></div></li><li class="listitem "><p>
         Filter out the squashed migrations.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>perl normalize.pl ccdb-src-kubecf.sql &gt; normal.sql</pre></div></li><li class="listitem "><p>
         Drop the current CCDB and import the dump from SCF.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>echo "drop database cloud_controller; create database
 cloud_controller;" | \
      kubectl exec -i database-0 --namespace kubecf -- mysql
 <code class="prompt user">tux &gt; </code>kubectl exec -i database-0 --namespace kubecf -- mysql
 cloud_controller &lt; normal.sql</pre></div></li></ol></div><p>
       For a CCDB that has already been rotated before:
      </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
         Update the routes for the new cluster in the
         <code class="filename">ccdb-rotated-src.sql</code> file. Replace the placeholders
 values
         with the value of <code class="literal">DOMAIN</code> from the SCF cluster and the
         value of <code class="literal">system_domain</code> from the KubeCF cluster.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sed
 "s/<em class="replaceable ">SCF_DOMAIN</em>/<em class="replaceable ">KubeCF_system_domain</em>/g"
 ccdb-rotated-src.sql &gt; ccdb-src-kubecf.sql</pre></div></li><li class="listitem "><p>
         Filter out the squashed migrations.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>perl normalize.pl ccdb-src-kubecf.sql &gt; normal.sql</pre></div></li><li class="listitem "><p>
         Drop the current CCDB and import the dump from SCF.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>echo "drop database cloud_controller; create database
 cloud_controller;" | \
      kubectl exec -i database-0 --namespace kubecf -- mysql
 <code class="prompt user">tux &gt; </code>kubectl exec -i database-0 --namespace kubecf -- mysql
 cloud_controller &lt; normal.sql</pre></div></li></ol></div></li><li class="step "><p>
       Update the encryption key.
      </p><p>
       For a CCDB that has not been rotated:
      </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cat enc_key
 db_encryption_key:
 qmF4BZxVUZoVkvDdYi2crkezdNWww6mLRh32W77VsLY5xhinpunVNp1d2mzc3O7F

 database_encryption:
   keys: {}
   current_key_label: ""
   pbkdf2_hmac_iterations: 2048</pre></div></li><li class="listitem "><p>
         When only <code class="literal">db_encryption_key</code> is set, we must use the
         same legacy mechanism in KubeCF as well.
        </p><p>
         Create a YAML configuration file with the structure below. Replace the
         example values with the values found in the
         <code class="filename">enc_key</code> file.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cat enc_key_values.yaml
 credentials:
   cc_db_encryption_key:
 <em class="replaceable ">qmF4BZxVUZoVkvDdYi2crkezdNWww6mLRh32W77VsLY5xhinpunVNp1d2mzc3O7F</em></pre></div><p>
          Use <code class="command">helm upgrade</code> to apply the configuration update.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade kubecf suse/kubecf \
 --namespace <em class="replaceable ">kubecf</em> \
 --values kubecf-config-values.yaml \
 --values enc_key_values.yaml \
 --version 2.5.8</pre></div></li></ol></div><p>
       For a CCDB that has already been rotated before:
      </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cat enc_key_rotated
 db_encryption_key:
 qmF4BZxVUZoVkvDdYi2crkezdNWww6mLRh32W77VsLY5xhinpunVNp1d2mzc3O7F

 database_encryption:
   keys: {"NEW_KEY":"abcdef"}
   current_key_label: "NEW_KEY"
   pbkdf2_hmac_iterations: 2048</pre></div></li><li class="listitem "><p>
         Since a rotated key exists, <code class="literal">db_encryption_key</code> can be
         ignored. The <code class="literal">current_key_label</code> setting must be copied
         over, with the exact same name and value. Any other (older) keys in that
         set can be ignored, as long as encryption key rotation has been
         performed in SCF since the last update to that list.
        </p><p>
         Create a YAML configuration file with the structure below. Replace the
         example values with the values found in the
        <code class="filename">enc_key_rotated</code> file.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cat enc_key_values.yaml
 ccdb:
   encryption:
     rotation:
       key_labels:
       - NEW_KEY
       current_key_label: NEW_KEY

 credentials:
   cc_db_encryption_key:
 qmF4BZxVUZoVkvDdYi2crkezdNWww6mLRh32W77VsLY5xhinpunVNp1d2mzc3O7F
   ccdb_key_label_new_key: abcdef</pre></div><p>
          Use <code class="command">helm upgrade</code> to apply the configuration update.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade kubecf suse/kubecf \
 --namespace <em class="replaceable ">kubecf</em> \
 --values kubecf-config-values.yaml \
 --values enc_key_values.yaml \
 --version 2.5.8</pre></div></li></ol></div><p>
       Wait until <code class="literal">api</code>, <code class="literal">cc-worker</code>, and
       <code class="literal">scheduler</code> have restarted. To monitor the progress run
       the following command.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace
 kubecf'</pre></div></li><li class="step "><p>
       Rotate the encryption key.
      </p><p>
       The imported data can now be decrypted with the legacy
       <code class="literal">db_encryption_key</code>. For consistency we want to run a
       rotation, so all the imported data will be re-encrypted with the current
       KubeCF encryption key.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl patch qjob rotate-cc-database-key --namespace
 kubecf --type merge \
       --patch '{"spec":{"trigger":{"strategy":"now"}}}'

 <code class="prompt user">tux &gt; </code>kubectl logs -l
 quarks.cloudfoundry.org/qjob-name=rotate-cc-database-key --namespace kubecf -c
 logs -f</pre></div></li><li class="step "><p>
       Verify everything works.
      </p><ol type="a" class="substeps "><li class="step "><p>
         Target an existing <code class="literal">org</code> and <code class="literal">space</code>
         from your previous SUSE Cloud Application Platform 1.5.2 deployment.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf target -o EXISTING_ORG -s EXISTING_SPACE</pre></div></li><li class="step "><p>
         Verify the apps that were previously deployed to the
         <code class="literal">org</code> and <code class="literal">space</code> are listed.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf apps
 name        requested state   instances   memory   disk   urls
 12factor    started           0/1         64M      256M   12factor.example.com</pre></div></li><li class="step "><p>
         The <code class="literal">started</code> value for
         <code class="literal">requested state</code> is misleading. Since we did not
         import the BBS database, Diego does not know anything about these apps.
         No app instances will be started until the <code class="command">cf restart</code>
         command is manually issued (it does not require restaging).
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf restart 12factor</pre></div><p>
         Repeat for all apps.
        </p></li><li class="step "><p>
         Check the encryption key.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --stdin --tty --namespace kubecf api-0 -- bash
 -c "cat /var/vcap/jobs/cloud_controller_ng/config/cloud_controller_ng.yml | grep
 -A 10 db_encryption"
 Defaulting container name to cloud-controller-ng-cloud-controller-ng.
 Use 'kubectl describe pod/api-0 -n kubecf' to see all of the containers in this
 pod.
 db_encryption_key:
 qmF4BZxVUZoVkvDdYi2crkezdNWww6mLRh32W77VsLY5xhinpunVNp1d2mzc3O7F

 database_encryption:
   keys:
 {"ccdb_key_label_encryption_key_0":"jHlbjl11nZ2wqdh9bCA9ZIOCMxgseIf7OyVP2aSrESmZEuovqLXSWPTKTEcU0CCo"}
   current_key_label: "ccdb_key_label_encryption_key_0"
   pbkdf2_hmac_iterations: 2048</pre></div></li><li class="step "><p>
         List the buildpacks.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks
 Getting buildpacks...

 buildpack               position   enabled   locked   filename
 stack
 staticfile_buildpack    1          true      false
 staticfile-buildpack-sle15-v1.5.5.1-5.1-eaf36a02.zip    sle15
 staticfile_buildpack    2          true      false
 staticfile_buildpack-cflinuxfs3-v1.5.4.zip              cflinuxfs3
 ...</pre></div><p>
         These are the buildpacks bundled with KubeCF. Since buildpacks in the
         CCDB were not locked, they were upgraded when the <code class="literal">api</code>
         (or <code class="literal">cc-worker</code>) pods were restarted.
        </p></li></ol></li><li class="step "><p>
       To update previously locked buildpacks to the KubeCF version, unlock the
       buildpack and restart the Cloud Controller.
      </p><ol type="a" class="substeps "><li class="step "><p>
         This example unlocks all buildpacks associated with the
         <code class="literal">cflinuxfs3</code> stack.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>for BP in $(cf buildpacks | perl -ne 'print if
 s/(_buildpack).*/\1/' | uniq); do cf update-buildpack $BP -s cflinuxfs3
 --unlock; done
 Updating buildpack staticfile_buildpack with stack cflinuxfs3 as admin...
 OK</pre></div></li><li class="step "><p>
         Restart the <code class="literal">api</code> pod. Restarting the
         <code class="literal">api</code> pod will cause a restart of the CC. As the CC
         starts, all <span class="emphasis"><em>unlocked</em></span> admin buildpacks will be
         replaced with versions bundled in the release.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl delete pod api-0 --namespace kubecf
 pod "api-0" deleted</pre></div><p>
         After restarting the <code class="literal">api-0i</code> pod, wait for it to be
         ready again. To monitor the progress run the following command.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace
 kubecf'</pre></div></li><li class="step "><p>
         Verify the buildpacks have been updated to the KubeCF version.  
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks</pre></div></li></ol></li></ol></div></div></div></div></div></div><div class="chapter " id="cha-cap-configuration-changes"><div class="titlepage"><div><div><h2 class="title"><span class="number">14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration Changes</span> <a title="Permalink" class="permalink" href="#cha-cap-configuration-changes">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_configuration_changes.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-configuration-change-example"><span class="number">14.1 </span><span class="name">Configuration Change Example</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-configuration-change-other-examples"><span class="number">14.2 </span><span class="name">Other Examples</span></a></span></dt></dl></div></div><p>
  After the initial deployment of Cloud Application Platform, any changes made to your Helm chart
  values, whether through your <code class="filename">kubecf-config-values.yaml</code> file
  or directly using Helm's <code class="command">--set</code> flag, are applied using
  the <code class="command">helm upgrade</code> command.
 </p><div id="id-1.3.5.4.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: Do Not Make Changes to Pod Counts During a Version Upgrade</h6><p>
   The <code class="command">helm upgrade</code> command can be used to apply
   configuration changes as well as perform version upgrades to Cloud Application Platform. A change
   to the pod count configuration should not be applied simultaneously with a
   version upgrade. Sizing changes should be made separately, either before or
   after, from a version upgrade.
  </p></div><div class="sect1 " id="sec-cap-configuration-change-example"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration Change Example</span> <a title="Permalink" class="permalink" href="#sec-cap-configuration-change-example">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_configuration_changes.xml</li><li><span class="ds-label">ID: </span>sec-cap-configuration-change-example</li></ul></div></div></div></div><p>
   Consider an example where you want to enable the App-AutoScaler.
  </p><p>
   The entry below is added to your <code class="filename">kubecf-config-values.yaml</code> file and set with
   <code class="literal">enabled</code> set to <code class="literal">true</code>.
  </p><div class="verbatim-wrap"><pre class="screen">features:
  autoscaler:
    enabled: true</pre></div><p>
   The changed is then applied with the <code class="command">helm upgrade</code> command. This
   example assumes the <code class="literal">suse/kubecf</code> Helm chart deployed was
   named <code class="literal">kubecf</code>.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">kubecf</em> suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values <em class="replaceable ">kubecf-config-values.yaml</em> \
--version 2.5.8</pre></div><p>
   When all pods are in a <code class="literal">READY</code> state, the configuration
   change will also be reflected. Assuming the chart was deployed to the
   <code class="literal">kubecf</code> namespace, progress can be monitored with:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace kubecf'</pre></div></div><div class="sect1 " id="sec-cap-configuration-change-other-examples"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Other Examples</span> <a title="Permalink" class="permalink" href="#sec-cap-configuration-change-other-examples">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_configuration_changes.xml</li><li><span class="ds-label">ID: </span>sec-cap-configuration-change-other-examples</li></ul></div></div></div></div><p>
   The following are other examples of using <code class="command">helm upgrade</code> to
   make configuration changes:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Secrets rotation (see <a class="xref" href="#cha-cap-secrets-rotation" title="Chapter 20. Rotating Automatically Generated Secrets">Chapter 20, <em>Rotating Automatically Generated Secrets</em></a>)
    </p></li><li class="listitem "><p>
     Enabling additional services (see
     <a class="xref" href="#sec-cap-enable-app-autoscaler" title="23.2. Enabling and Disabling the App-AutoScaler Service">Section 23.2, “Enabling and Disabling the App-AutoScaler Service”</a>)
    </p></li></ul></div></div></div><div class="chapter " id="cha-cap-create-admin-user"><div class="titlepage"><div><div><h2 class="title"><span class="number">15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating Admin Users</span> <a title="Permalink" class="permalink" href="#cha-cap-create-admin-user">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_create_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-create-admin-prereqs"><span class="number">15.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-create-admin-procedure"><span class="number">15.2 </span><span class="name">Creating an Example Cloud Application Platform Cluster Administrator</span></a></span></dt></dl></div></div><p>
  This chapter provides an overview on how to create additional
  administrators for your Cloud Application Platform cluster.
 </p><div class="sect1 " id="sec-cap-create-admin-prereqs"><div class="titlepage"><div><div><h2 class="title"><span class="number">15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#sec-cap-create-admin-prereqs">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_create_admin.xml</li><li><span class="ds-label">ID: </span>sec-cap-create-admin-prereqs</li></ul></div></div></div></div><p>
   The following prerequisites are required in order to create
   additional Cloud Application Platform cluster administrators:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">uaac</code>, the Cloud Foundry <code class="literal">uaa</code> command line client
 (UAAC). See
 <a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-user-management.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-user-management.html</a>
 for more information and installation instructions.
</p><p>
 On SUSE Linux Enterprise systems, ensure the <code class="literal">ruby-devel</code> and <code class="literal">gcc-c++</code>
 packages have been installed before installing the <code class="literal">cf-uaac</code> gem.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install ruby-devel gcc-c++</pre></div></li></ul></div></div><div class="sect1 " id="sec-cap-create-admin-procedure"><div class="titlepage"><div><div><h2 class="title"><span class="number">15.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating an Example Cloud Application Platform Cluster Administrator</span> <a title="Permalink" class="permalink" href="#sec-cap-create-admin-procedure">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_create_admin.xml</li><li><span class="ds-label">ID: </span>sec-cap-create-admin-procedure</li></ul></div></div></div></div><p>
   The following example demonstrates the steps required to create a new
   administrator user for your Cloud Application Platform cluster. Note that creating administrator
   accounts must be done using the UAAC and cannot be done using the cf CLI.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
 Use UAAC to target your <code class="literal">uaa</code> server.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac target --skip-ssl-validation <em class="replaceable ">https://uaa.example.com</em></pre></div></li><li class="step "><p>
 Authenticate to the <code class="literal">uaa</code> server as
 <code class="literal">admin</code> using the
 <code class="literal">uaa_admin_client_secret</code> set in your
 <code class="filename">kubecf-config-values.yaml</code> file.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac token client get admin --secret <em class="replaceable ">PASSWORD</em></pre></div></li><li class="step "><p>
     Create a new user:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac user add <em class="replaceable ">NEW_ADMIN</em> --password <em class="replaceable ">PASSWORD</em> --emails <em class="replaceable ">new-admin@example.com</em> --zone <em class="replaceable ">kubecf</em></pre></div></li><li class="step "><p>
     Add the new user to the following groups to grant administrator privileges
     to the cluster (see
     <a class="link" href="https://docs.cloudfoundry.org/concepts/architecture/uaa.html#uaa-scopes" target="_blank">https://docs.cloudfoundry.org/concepts/architecture/uaa.html#uaa-scopes</a> for information on privileges provided by each group):
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac member add scim.write <em class="replaceable ">NEW_ADMIN</em> --zone <em class="replaceable ">kubecf</em>

<code class="prompt user">tux &gt; </code>uaac member add scim.read <em class="replaceable ">NEW_ADMIN</em> --zone <em class="replaceable ">kubecf</em>

<code class="prompt user">tux &gt; </code>uaac member add cloud_controller.admin <em class="replaceable ">NEW_ADMIN</em> --zone <em class="replaceable ">kubecf</em>

<code class="prompt user">tux &gt; </code>uaac member add clients.read <em class="replaceable ">NEW_ADMIN</em> --zone <em class="replaceable ">kubecf</em>

<code class="prompt user">tux &gt; </code>uaac member add clients.write <em class="replaceable ">NEW_ADMIN</em> --zone <em class="replaceable ">kubecf</em>

<code class="prompt user">tux &gt; </code>uaac member add doppler.firehose <em class="replaceable ">NEW_ADMIN</em> --zone <em class="replaceable ">kubecf</em>

<code class="prompt user">tux &gt; </code>uaac member add routing.router_groups.read <em class="replaceable ">NEW_ADMIN</em> --zone <em class="replaceable ">kubecf</em>

<code class="prompt user">tux &gt; </code>uaac member add routing.router_groups.write <em class="replaceable ">NEW_ADMIN</em> --zone <em class="replaceable ">kubecf</em></pre></div></li><li class="step "><p>
     Log into your Cloud Application Platform deployment as the newly created administrator:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation <em class="replaceable ">https://api.example.com</em>

<code class="prompt user">tux &gt; </code>cf login -u <em class="replaceable ">NEW_ADMIN</em></pre></div></li><li class="step "><p>
     The following commands can be used to verify the new administrator account has sufficient permissions:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-shared-domain <em class="replaceable ">TEST_DOMAIN.COM</em>

<code class="prompt user">tux &gt; </code>cf set-org-role <em class="replaceable ">NEW_ADMIN</em> org OrgManager

<code class="prompt user">tux &gt; </code>cf create-buildpack <em class="replaceable ">TEST_BUILDPACK</em> <em class="replaceable ">/tmp/ruby_buildpack-cached-sle15-v1.7.30.1.zip</em> <em class="replaceable ">1</em></pre></div><p>
     If the account has sufficient permissions, you should not receive any authorization message similar to the following:
    </p><div class="verbatim-wrap"><pre class="screen">FAILED
Server error, status code: 403, error code: 10003, message: You are not authorized to perform the requested action</pre></div><p>
     See <a class="link" href="https://docs.cloudfoundry.org/cf-cli/cf-help.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/cf-help.html</a> for other administrator-specific commands that can be run to confirm sufficient permissions are provided.
    </p></li></ol></div></div></div></div><div class="chapter " id="cha-cap-manage-passwords"><div class="titlepage"><div><div><h2 class="title"><span class="number">16 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Managing Passwords</span> <a title="Permalink" class="permalink" href="#cha-cap-manage-passwords">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_passwords.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-passwords-cli"><span class="number">16.1 </span><span class="name">Password Management with the Cloud Foundry Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-passwords-stratos"><span class="number">16.2 </span><span class="name">Changing User Passwords with Stratos</span></a></span></dt></dl></div></div><p>
  The various components of SUSE Cloud Application Platform authenticate to each other using
  passwords that are automatically managed by the Cloud Application Platform secrets-generator. The
  only passwords managed by the cluster administrator are passwords for human
  users. The administrator may create and remove user logins, but cannot change
  user passwords.
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    The cluster administrator password is initially defined in the deployment's
    <code class="filename">values.yaml</code> file with
    <code class="literal">CLUSTER_ADMIN_PASSWORD</code>
   </p></li><li class="listitem "><p>
    The Stratos Web UI provides a form for users, including the administrator,
    to change their own passwords
   </p></li><li class="listitem "><p>
    User logins are created (and removed) with the Cloud Foundry Client,
    cf CLI
   </p></li></ul></div><div class="sect1 " id="sec-cap-passwords-cli"><div class="titlepage"><div><div><h2 class="title"><span class="number">16.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Password Management with the Cloud Foundry Client</span> <a title="Permalink" class="permalink" href="#sec-cap-passwords-cli">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_passwords.xml</li><li><span class="ds-label">ID: </span>sec-cap-passwords-cli</li></ul></div></div></div></div><p>
   The administrator cannot change other users' passwords. Only users may
   change their own passwords, and password changes require the current
   password:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf passwd
Current Password&gt;
New Password&gt;
Verify Password&gt;
Changing password...
OK
Please log in again</pre></div><p>
   The administrator can create a new user:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-user <em class="replaceable ">NEW_USER</em> <em class="replaceable ">PASSWORD</em></pre></div><p>
   and delete a user:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf delete-user <em class="replaceable ">NEW_USER</em> <em class="replaceable ">PASSWORD</em></pre></div><p>
   Use the cf CLI to assign space and org roles. Run <code class="command">cf help
   -a</code> for a complete command listing, or see
   <a class="link" href="https://docs.cloudfoundry.org/adminguide/cli-user-management.html" target="_blank">Creating
   and Managing Users with the cf CLI</a>.
  </p></div><div class="sect1 " id="sec-cap-passwords-stratos"><div class="titlepage"><div><div><h2 class="title"><span class="number">16.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Changing User Passwords with Stratos</span> <a title="Permalink" class="permalink" href="#sec-cap-passwords-stratos">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_passwords.xml</li><li><span class="ds-label">ID: </span>sec-cap-passwords-stratos</li></ul></div></div></div></div><p>
   The Stratos Web UI provides a form for changing passwords on your profile
   page. Click the overflow menu button on the top right to access your
   profile, then click the edit button on your profile page. You can manage
   your password and username on this page.
  </p><div class="figure" id="fig-cap-stratos-profile-png"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos-profile.png" target="_blank"><img src="images/stratos-profile.png" width="" alt="Stratos Profile Page" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 16.1: </span><span class="name">Stratos Profile Page </span><a title="Permalink" class="permalink" href="#fig-cap-stratos-profile-png">#</a></h6></div></div><div class="figure" id="fig-cap-stratos-edit-profile-png"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/stratos-edit-profile.png" target="_blank"><img src="images/stratos-edit-profile.png" width="" alt="Stratos Edit Profile Page" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 16.2: </span><span class="name">Stratos Edit Profile Page </span><a title="Permalink" class="permalink" href="#fig-cap-stratos-edit-profile-png">#</a></h6></div></div></div></div><div class="chapter " id="cha-cap-uaa-ui"><div class="titlepage"><div><div><h2 class="title"><span class="number">17 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Accessing the UAA User Interface</span> <a title="Permalink" class="permalink" href="#cha-cap-uaa-ui">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_uaa_ui.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-uaa-ui-prereqs"><span class="number">17.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-uaa-ui-procedure"><span class="number">17.2 </span><span class="name">Procedure</span></a></span></dt></dl></div></div><p>
  After UAA is deployed successfully, users will not be able to log in to the
  UAA user interface (UI) with the <code class="literal">admin</code> user and the
  <code class="literal">UAA_ADMIN_CLIENT_SECRET</code> credentials. This user is only an
  OAuth client that is authorized to call UAA REST APIs and will need to create
  a separate user in the UAA server by using the UAAC utility.
 </p><div class="sect1 " id="sec-cap-uaa-ui-prereqs"><div class="titlepage"><div><div><h2 class="title"><span class="number">17.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#sec-cap-uaa-ui-prereqs">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_uaa_ui.xml</li><li><span class="ds-label">ID: </span>sec-cap-uaa-ui-prereqs</li></ul></div></div></div></div><p>
   The following prerequisites are required in order to access the UAA UI.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
 <code class="command">uaac</code>, the Cloud Foundry <code class="literal">uaa</code> command line client
 (UAAC). See
 <a class="link" href="https://docs.cloudfoundry.org/uaa/uaa-user-management.html" target="_blank">https://docs.cloudfoundry.org/uaa/uaa-user-management.html</a>
 for more information and installation instructions.
</p><p>
 On SUSE Linux Enterprise systems, ensure the <code class="literal">ruby-devel</code> and <code class="literal">gcc-c++</code>
 packages have been installed before installing the <code class="literal">cf-uaac</code> gem.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install ruby-devel gcc-c++</pre></div></li><li class="listitem "><p>
     UAA has been successfully deployed.
    </p></li></ul></div></div><div class="sect1 " id="sec-cap-uaa-ui-procedure"><div class="titlepage"><div><div><h2 class="title"><span class="number">17.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Procedure</span> <a title="Permalink" class="permalink" href="#sec-cap-uaa-ui-procedure">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_uaa_ui.xml</li><li><span class="ds-label">ID: </span>sec-cap-uaa-ui-procedure</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
 Use UAAC to target your <code class="literal">uaa</code> server.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac target --skip-ssl-validation <em class="replaceable ">https://uaa.example.com</em></pre></div></li><li class="step "><p>
 Authenticate to the <code class="literal">uaa</code> server as
 <code class="literal">admin</code> using the
 <code class="literal">uaa_admin_client_secret</code> set in your
 <code class="filename">kubecf-config-values.yaml</code> file.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac token client get admin --secret <em class="replaceable ">PASSWORD</em></pre></div></li><li class="step "><p>
     Create a new user.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>uaac user add <em class="replaceable ">NEW-USER</em> -p <em class="replaceable ">PASSWORD</em> --emails <em class="replaceable ">NEW-USER-EMAIL</em></pre></div></li><li class="step "><p>
     Go to the UAA UI at <a class="link" href="https://uaa.example.com:2793/login" target="_blank">https://uaa.example.com:2793/login</a>
     , replacing <code class="literal">example.com</code> with your domain.
    </p></li><li class="step "><p>
     Log in using the the newly created user. Use the username and password as
     the credentials.
    </p></li></ol></div></div></div></div><div class="chapter " id="cha-cap-memory-limits"><div class="titlepage"><div><div><h2 class="title"><span class="number">18 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Container Memory Limits and Requests</span> <a title="Permalink" class="permalink" href="#cha-cap-memory-limits">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_memory_limits.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-memory-limits-enable"><span class="number">18.1 </span><span class="name">Enabling and Disabling Memory Limits and Request Sizes</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-memory-limits-configure"><span class="number">18.2 </span><span class="name">Configuring Memory Limits and Request Sizes</span></a></span></dt></dl></div></div><p>
  In SUSE Cloud Application Platform, containers have predefined memory limits and request sizes.
  Depending on the workload, these may need to be adjusted in some cases.
 </p><div class="sect1 " id="sec-cap-memory-limits-enable"><div class="titlepage"><div><div><h2 class="title"><span class="number">18.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling and Disabling Memory Limits and Request Sizes</span> <a title="Permalink" class="permalink" href="#sec-cap-memory-limits-enable">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_memory_limits.xml</li><li><span class="ds-label">ID: </span>sec-cap-memory-limits-enable</li></ul></div></div></div></div><p>
   By default, memory limits and request sizes are enabled. To disable it, add
   the following block to your <code class="filename">kubecf-config-values.yaml</code> file.
  </p><div class="verbatim-wrap"><pre class="screen">features:
  memory_limits:
    enabled: false</pre></div><p>
   To enable memory limits again, update the above block in your
   <code class="filename">kubecf-config-values.yaml</code> so that <code class="literal">enabled</code> is set to
   <code class="literal">true</code>.
  </p><p>
  After making the change above, and any other configuration changes, apply the
   update by doing the following:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     For an initial deployment, continue to the deployment steps for your platform:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       For SUSE CaaS Platform, see <a class="xref" href="#sec-cap-cap-on-caasp" title="4.13. Deploying SUSE Cloud Application Platform">Section 4.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Microsoft AKS, see <a class="xref" href="#sec-cap-cap-on-aks" title="5.13. Deploying SUSE Cloud Application Platform">Section 5.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Amazon EKS, see <a class="xref" href="#sec-cap-cap-on-eks" title="6.13. Deploying SUSE Cloud Application Platform">Section 6.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Google GKE, see <a class="xref" href="#sec-cap-cap-on-gke" title="7.14. Deploying SUSE Cloud Application Platform">Section 7.14, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li></ul></div></li><li class="listitem "><p>
     For an existing deployment, use <code class="command">helm upgrade</code> to apply
     the change.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">kubecf</em> suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values <em class="replaceable ">kubecf-config-values.yaml</em> \
--version 2.5.8</pre></div></li></ul></div></div><div class="sect1 " id="sec-cap-memory-limits-configure"><div class="titlepage"><div><div><h2 class="title"><span class="number">18.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring Memory Limits and Request Sizes</span> <a title="Permalink" class="permalink" href="#sec-cap-memory-limits-configure">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_memory_limits.xml</li><li><span class="ds-label">ID: </span>sec-cap-memory-limits-configure</li></ul></div></div></div></div><p>
   Configuring memory limits and request sizes requires that
   <code class="literal">feature.memory_limits</code> is enabled. The default memory limits
   and request sizes can be found by examining the <code class="literal">resources</code>
   block at
   <a class="link" href="https://github.com/SUSE/kubernetes-charts-suse-com/blob/master/stable/kubecf/config/resources.yaml" target="_blank">https://github.com/SUSE/kubernetes-charts-suse-com/blob/master/stable/kubecf/config/resources.yaml</a>.
   To configure memory limits and request sizes, add a
   <code class="literal">resources</code> block to your <code class="filename">kubecf-config-values.yaml</code>. It contains a
   mapping of instance groups to jobs to processes. The process then contains a
   resource definition with limits and requests. All values are integers and
   represent the number of megabytes (Mi) for the given limit or request. A fully
   expanded tree looks like:
  </p><div class="verbatim-wrap"><pre class="screen">resources:
  some_ig:
    some_job:
      some_process:
        memory:
          limit: ~
          request: ~</pre></div><p>
   Each level can define a <code class="literal">$defaults</code> resource definition that
   will be applied to all processes below it, that don't have their own
   definition (or a default further down the tree closer to them):
  </p><div class="verbatim-wrap"><pre class="screen">resources:
  '$defaults':
    memory:
      limit: ~
      request: ~
  some_ig:
    '$defaults': { ... }
    some_job:
      '$defaults': { ... }
       some_process: ~</pre></div><p>
   For convenience a <code class="literal">$defaults</code> value can be just an integer.
   This
  </p><div class="verbatim-wrap"><pre class="screen">resources:
  '$defaults': 32</pre></div><p>
   is a shortcut for:
  </p><div class="verbatim-wrap"><pre class="screen">resources:
  '$defaults': {memory: {limit: 32, request: ~}, cpu: {limit: ~, request:~}}</pre></div><p>
   In addition, an instance group, job, or process can also be set to just an
   integer. This:
  </p><div class="verbatim-wrap"><pre class="screen">resources:
  some_ig: 32</pre></div><p>
   is a shortcut for:
  </p><div class="verbatim-wrap"><pre class="screen">resources:
  some_ig:
    $defaults': 32</pre></div><p>
   Of course this means that any lower level jobs and processes will have to
   share this specific resource definition, as there is no way to explicitly
   enumerate the jobs or processes when the value is just an integer and not a
   map.
  </p><p>
   Note that there is a difference between this
  </p><div class="verbatim-wrap"><pre class="screen">resources:
  '$defaults': 32
  some_ig: 64</pre></div><p>
   and this:
  </p><div class="verbatim-wrap"><pre class="screen">resources:
  '$defaults': 32
  some_ig:
    some_job: 64</pre></div><p>
   The former definitions sets the memory limit of
   <span class="bold"><strong>all</strong></span> jobs under <code class="literal">some_ig</code>
   while the latter only specifies the limit for <code class="literal">some_job</code>. If
   there are more jobs in <code class="literal">some_ig</code>, then they will use the
   global limit (32) and only <code class="literal">some_job</code> will use the specific
   limit (64).
  </p><p>
   Memory requests will have a calculated default value, which is a configurable
   percentage of the limit, at least some configurable minimum value, and never
   higher than the limit itself. The default is always at least a minimum value,
   but never larger than the limit itself. These defaults can be configured by
   using <code class="literal">features.memory_limits.default_request_minimum</code> and
   <code class="literal">features.memory_limits.default_request_in_percent</code>. The
   following is an example configuration where the example values are the
   respective defaults. 
  </p><div class="verbatim-wrap"><pre class="screen">features:
  memory_limits:
    default_request_minimum: 32
    default_request_in_percent: 25</pre></div><p>
  After making the change above, and any other configuration changes, apply the
   update by doing the following:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     For an initial deployment, continue to the deployment steps for your platform:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       For SUSE CaaS Platform, see <a class="xref" href="#sec-cap-cap-on-caasp" title="4.13. Deploying SUSE Cloud Application Platform">Section 4.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Microsoft AKS, see <a class="xref" href="#sec-cap-cap-on-aks" title="5.13. Deploying SUSE Cloud Application Platform">Section 5.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Amazon EKS, see <a class="xref" href="#sec-cap-cap-on-eks" title="6.13. Deploying SUSE Cloud Application Platform">Section 6.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Google GKE, see <a class="xref" href="#sec-cap-cap-on-gke" title="7.14. Deploying SUSE Cloud Application Platform">Section 7.14, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li></ul></div></li><li class="listitem "><p>
     For an existing deployment, use <code class="command">helm upgrade</code> to apply
     the change.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">kubecf</em> suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values <em class="replaceable ">kubecf-config-values.yaml</em> \
--version 2.5.8</pre></div></li></ul></div></div></div><div class="chapter " id="cha-cap-ccdb-secret-rotation"><div class="titlepage"><div><div><h2 class="title"><span class="number">19 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cloud Controller Database Secret Rotation</span> <a title="Permalink" class="permalink" href="#cha-cap-ccdb-secret-rotation">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_ccdb_key_rotation.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-ccdb-tables"><span class="number">19.1 </span><span class="name">Tables with Encrypted Information</span></a></span></dt></dl></div></div><p>
  The Cloud Controller Database (CCDB) encrypts sensitive information like
  passwords. The encryption key is generated when KubeCF is deployed.
  If it is compromised or needs to be rotated for any other reason, new keys can be
  added. Note that existing encrypted information will not be updated. The
  encrypted information must be set again to have them re-encrypted with the
  new key. The old key cannot be dropped until all references to it are removed
  from the database.
 </p><p>
  Updating these secrets is a manual process that involves decrypting the
  current contents of the database using the old key and re-encrypting the
  contents using a new key. The following procedure outlines
  how this is done.
 </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    For each label under <code class="literal">key_labels</code>, KubeCF will generate
    an encryption key. The <code class="literal">current_key_label</code> indicates which
    key is currently being used.
   </p><div class="verbatim-wrap"><pre class="screen">ccdb:
  encryption:
    rotation:
      key_labels:
      - <em class="replaceable ">encryption_key_0</em>
      current_key_label: <em class="replaceable ">encryption_key_0</em></pre></div></li><li class="step "><p>
    In order to rotate the CCDB encryption key, add a new label to
    <code class="literal">key_labels</code> (keeping the old labels), and mark
    the <code class="literal">current_key_label</code> with the newly added label:
   </p><div class="verbatim-wrap"><pre class="screen">ccdb:
  encryption:
    rotation:
      key_labels:
      - <em class="replaceable ">encryption_key_0</em>
      - <em class="replaceable ">encryption_key_1</em>
      current_key_label: <em class="replaceable ">encryption_key_1</em></pre></div></li><li class="step "><p>
    Save the above information into a file, for example
    <em class="replaceable ">rotate-secret.yaml</em>, and perform the rotation:
   </p><ol type="a" class="substeps "><li class="step "><p>
      Update the KubeCF Helm installation:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade kubecf --namespace <em class="replaceable ">kubecf</em> --values <em class="replaceable ">rotate-secret.yaml</em> --reuse-values</pre></div></li><li class="step "><p>
      After Helm finishes its updates, trigger the
      <code class="literal">rotate-cc-database-key</code> errand:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl patch qjob kubecf-rotate-cc-database-key \
--namespace <em class="replaceable ">kubecf</em> \
--type merge \
--patch '{"spec":{"trigger":{"strategy":"now"}}}'</pre></div></li></ol></li></ol></div></div><div class="sect1 " id="sec-cap-ccdb-tables"><div class="titlepage"><div><div><h2 class="title"><span class="number">19.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Tables with Encrypted Information</span> <a title="Permalink" class="permalink" href="#sec-cap-ccdb-tables">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_ccdb_key_rotation.xml</li><li><span class="ds-label">ID: </span>sec-cap-ccdb-tables</li></ul></div></div></div></div><p>
   The CCDB contains several tables with encrypted information as follows:
  </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.5.9.5.3.1"><span class="term ">apps</span></dt><dd><p>
      Environment variables
     </p></dd><dt id="id-1.3.5.9.5.3.2"><span class="term ">buildpack_lifecycle_buildpacks</span></dt><dd><p>
      Buildpack URLs may contain passwords
     </p></dd><dt id="id-1.3.5.9.5.3.3"><span class="term ">buildpack_lifecycle_data</span></dt><dd><p>
      Buildpack URLs may contain passwords
     </p></dd><dt id="id-1.3.5.9.5.3.4"><span class="term ">droplets</span></dt><dd><p>
      May contain Docker registry passwords
     </p></dd><dt id="id-1.3.5.9.5.3.5"><span class="term ">env_groups</span></dt><dd><p>
      Environment variables
     </p></dd><dt id="id-1.3.5.9.5.3.6"><span class="term ">packages</span></dt><dd><p>
      May contain Docker registry passwords
     </p></dd><dt id="id-1.3.5.9.5.3.7"><span class="term ">service_bindings</span></dt><dd><p>
      Contains service credentials
     </p></dd><dt id="id-1.3.5.9.5.3.8"><span class="term ">service_brokers</span></dt><dd><p>
      Contains service credentials
     </p></dd><dt id="id-1.3.5.9.5.3.9"><span class="term ">service_instances</span></dt><dd><p>
      Contains service credentials
     </p></dd><dt id="id-1.3.5.9.5.3.10"><span class="term ">service_keys</span></dt><dd><p>
      Contains service credentials
     </p></dd><dt id="id-1.3.5.9.5.3.11"><span class="term ">tasks</span></dt><dd><p>
      Environment variables
     </p></dd></dl></div><div class="sect2 " id="sec-cap-ccdb-update-existing-table-data"><div class="titlepage"><div><div><h3 class="title"><span class="number">19.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update Existing Data with New Encryption Key</span> <a title="Permalink" class="permalink" href="#sec-cap-ccdb-update-existing-table-data">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_ccdb_key_rotation.xml</li><li><span class="ds-label">ID: </span>sec-cap-ccdb-update-existing-table-data</li></ul></div></div></div></div><p>
    To ensure the encryption key is updated for existing data, the command (or
    its <code class="command">update-</code> equivalent) can be run again with the same
    parameters. Some commands need to be deleted/recreated to update the label.
   </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.5.9.5.4.3.1"><span class="term ">apps</span></dt><dd><p>
       Run <code class="command">cf set-env</code> again
      </p></dd><dt id="id-1.3.5.9.5.4.3.2"><span class="term ">buildpack_lifecycle_buildpacks, buildpack_lifecycle_data, droplets</span></dt><dd><p>
       <code class="command">cf restage</code> the app
      </p></dd><dt id="id-1.3.5.9.5.4.3.3"><span class="term ">packages</span></dt><dd><p>
       <code class="command">cf delete</code>, then <code class="command">cf push</code> the app
       (Docker apps with registry password)
      </p></dd><dt id="id-1.3.5.9.5.4.3.4"><span class="term ">env_groups</span></dt><dd><p>
       Run <code class="command">cf set-staging-environment-variable-group</code> or
       <code class="command">cf set-running-environment-variable-group</code> again
      </p></dd><dt id="id-1.3.5.9.5.4.3.5"><span class="term ">service_bindings</span></dt><dd><p>
       Run <code class="command">cf unbind-service</code> and <code class="command">cf
       bind-service</code> again
      </p></dd><dt id="id-1.3.5.9.5.4.3.6"><span class="term ">service_brokers</span></dt><dd><p>
       Run <code class="command">cf update-service-broker</code> with the appropriate
       credentials
      </p></dd><dt id="id-1.3.5.9.5.4.3.7"><span class="term ">service_instances</span></dt><dd><p>
       Run <code class="command">cf update-service</code> with the appropriate
       credentials
      </p></dd><dt id="id-1.3.5.9.5.4.3.8"><span class="term ">service_keys</span></dt><dd><p>
       Run <code class="command">cf delete-service-key</code> and <code class="command">cf
       create-service-key</code> again
      </p></dd><dt id="id-1.3.5.9.5.4.3.9"><span class="term ">tasks</span></dt><dd><p>
       While tasks have an encryption key label, they are generally meant to be
       a one-off event, and left to run to completion. If there is a task still
       running, it could be stopped with <code class="command">cf terminate-task</code>,
       then run again with <code class="command">cf run-task</code>.
      </p></dd></dl></div></div></div></div><div class="chapter " id="cha-cap-secrets-rotation"><div class="titlepage"><div><div><h2 class="title"><span class="number">20 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Rotating Automatically Generated Secrets</span> <a title="Permalink" class="permalink" href="#cha-cap-secrets-rotation">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_secret_rotation.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-secrets-rotation-finding"><span class="number">20.1 </span><span class="name">Finding Secrets</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-secrets-rotation-specific"><span class="number">20.2 </span><span class="name">Rotating Specific Secrets</span></a></span></dt></dl></div></div><p>
   Cloud Application Platform uses a number of automatically generated secrets (passwords and
   certificates) for use internally provided by cf-operator. This removes
   the burden from human operators while allowing for secure communication.

   From time to time, operators may wish to change such secrets, either manually
   or on a schedule. This is called rotating a secret.
  </p><div class="sect1 " id="sec-cap-secrets-rotation-finding"><div class="titlepage"><div><div><h2 class="title"><span class="number">20.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Finding Secrets</span> <a title="Permalink" class="permalink" href="#sec-cap-secrets-rotation-finding">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_secret_rotation.xml</li><li><span class="ds-label">ID: </span>sec-cap-secrets-rotation-finding</li></ul></div></div></div></div><p>
     Retrieve the list of all secrets maintained by KubeCF:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get quarkssecret --namespace <em class="replaceable ">kubecf</em></pre></div><p>
      To see information about a specific secret, for example the NATS
      password:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get quarkssecret --namespace <em class="replaceable ">kubecf</em> <em class="replaceable ">kubecf.var-nats-password</em> --output yaml</pre></div><p>
     Note that each quarkssecret has a corresponding regular Kubernetes secret
     that it controls:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get secret --namespace <em class="replaceable ">kubecf</em>
<code class="prompt user">tux &gt; </code>kubectl get secret --namespace <em class="replaceable ">kubecf</em> <em class="replaceable ">kubecf.var-nats-password</em> --output yaml</pre></div></div><div class="sect1 " id="sec-cap-secrets-rotation-specific"><div class="titlepage"><div><div><h2 class="title"><span class="number">20.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Rotating Specific Secrets</span> <a title="Permalink" class="permalink" href="#sec-cap-secrets-rotation-specific">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_secret_rotation.xml</li><li><span class="ds-label">ID: </span>sec-cap-secrets-rotation-specific</li></ul></div></div></div></div><p>
      To rotate a secret, for example <em class="replaceable ">kubecf.var-nats-password</em>:
    </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create a YAML file for a ConfigMap of the form:</p><div class="verbatim-wrap"><pre class="screen">---
apiVersion: v1
kind: ConfigMap
metadata:
  name: <em class="replaceable ">rotate-kubecf.var-nats-password</em>
  labels:
    quarks.cloudfoundry.org/secret-rotation: "true"
data:
  secrets: '["<em class="replaceable ">kubecf.var-nats-password</em>"]'</pre></div><p>
         The name of the ConfigMap can be anything allowed by Kubernetes syntax but
         we recommend using a name derived from the name of the secret itself.
       </p><p>
         Also, the example above rotates only a single secret but 
         the <code class="literal">data.secrets</code> key accepts an array of secret
         names, allowing simultaneous rotation of many secrets. 
       </p></li><li class="step "><p>Apply the ConfigMap:</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl apply --namespace <em class="replaceable ">kubecf</em> -f <em class="replaceable ">/path/to/your/yaml/file</em></pre></div><p>
         The result can be seen in the cf-operator's log.</p></li><li class="step "><p>
          After the rotation is complete, that is after secrets have been
          changed and all affected pods have been restarted, delete the config
          map again:
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl delete <em class="replaceable ">--namespace</em> kubecf -f <em class="replaceable ">/path/to/your/yaml/file</em></pre></div></li></ol></div></div></div></div><div class="chapter " id="cha-cap-backup-restore"><div class="titlepage"><div><div><h2 class="title"><span class="number">21 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Backup and Restore</span> <a title="Permalink" class="permalink" href="#cha-cap-backup-restore">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-backup-restore-with-plugin"><span class="number">21.1 </span><span class="name">Backup and Restore Using cf-plugin-backup</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-backup-restore-of-raw-data"><span class="number">21.2 </span><span class="name">Disaster Recovery through Raw Data Backup and Restore</span></a></span></dt></dl></div></div><div class="sect1 " id="sec-cap-backup-restore-with-plugin"><div class="titlepage"><div><div><h2 class="title"><span class="number">21.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Backup and Restore Using cf-plugin-backup</span> <a title="Permalink" class="permalink" href="#sec-cap-backup-restore-with-plugin">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span>sec-cap-backup-restore-with-plugin</li></ul></div></div></div></div><p>
   <code class="literal">cf-plugin-backup</code> backs up and restores your Cloud
   Controller Database (CCDB), using the Cloud Foundry command line interface (cf CLI).
   (See <a class="xref" href="#sec-cap-cf-cli" title="26.1. Using the cf CLI with SUSE Cloud Application Platform">Section 26.1, “Using the cf CLI with SUSE Cloud Application Platform”</a>.)
  </p><p>
   <code class="literal">cf-plugin-backup</code> is not a general-purpose backup and
   restore plugin. It is designed to save the state of a KubeCF instance before
   making changes to it. If the changes cause problems, use
   <code class="literal">cf-plugin-backup</code> to restore the instance from scratch. Do
   not use it to restore to a non-pristine KubeCF instance. Some of the
   limitations for applying the backup to a non-pristine KubeCF instance are:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Application configuration is not restored to running applications, as the
     plugin does not have the ability to determine which applications should be
     restarted to load the restored configurations.
    </p></li><li class="listitem "><p>
     User information is managed by the User Account and Authentication (<code class="literal">uaa</code>) Server,
     not the Cloud Controller (CC). As the plugin talks only to the CC it cannot
     save full user information, nor restore users. Saving and restoring users
     must be performed separately, and user restoration must be performed before
     the backup plugin is invoked.
    </p></li><li class="listitem "><p>
     The set of available stacks is part of the KubeCF instance setup, and is
     not part of the CC configuration. Trying to restore applications using
     stacks not available on the target KubeCF instance will fail. Setting up
     the necessary stacks must be performed separately before the backup plugin
     is invoked.
    </p></li><li class="listitem "><p>
     Buildpacks are not saved. Applications using custom buildpacks not
     available on the target KubeCF instance will not be restored.
     Custom buildpacks must be managed separately, and relevant buildpacks must
     be in place before the affected applications are restored.
    </p></li></ul></div><div class="sect2 " id="sec-cap-install-backup-restore-plugin"><div class="titlepage"><div><div><h3 class="title"><span class="number">21.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing the cf-plugin-backup</span> <a title="Permalink" class="permalink" href="#sec-cap-install-backup-restore-plugin">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span>sec-cap-install-backup-restore-plugin</li></ul></div></div></div></div><p>
    Download the plugin from
    <a class="link" href="https://github.com/SUSE/cf-plugin-backup/releases" target="_blank">https://github.com/SUSE/cf-plugin-backup/releases</a>.
   </p><p>
    Then install it with <code class="command">cf</code>, using the name of the plugin
    binary that you downloaded:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf install-plugin <em class="replaceable ">cf-plugin-backup-1.0.8.0.g9e8438e.linux-amd64</em>
 Attention: Plugins are binaries written by potentially untrusted authors.
 Install and use plugins at your own risk.
 Do you want to install the plugin
 backup-plugin/cf-plugin-backup-1.0.8.0.g9e8438e.linux-amd64? [yN]: y
 Installing plugin backup...
 OK
 Plugin backup 1.0.8 successfully installed.</pre></div><p>
    Verify installation by listing installed plugins:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf plugins
 Listing installed plugins...

 plugin   version   command name      command help
 backup   1.0.8     backup-info       Show information about the current snapshot
 backup   1.0.8     backup-restore    Restore the CloudFoundry state from a
  backup created with the snapshot command
 backup   1.0.8     backup-snapshot   Create a new CloudFoundry backup snapshot
  to a local file

 Use 'cf repo-plugins' to list plugins in registered repos available to install.</pre></div></div><div class="sect2 " id="sec-cap-using-backup-restore-plugin"><div class="titlepage"><div><div><h3 class="title"><span class="number">21.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using cf-plugin-backup</span> <a title="Permalink" class="permalink" href="#sec-cap-using-backup-restore-plugin">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span>sec-cap-using-backup-restore-plugin</li></ul></div></div></div></div><p>
    The plugin has three commands:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      backup-info
     </p></li><li class="listitem "><p>
      backup-snapshot
     </p></li><li class="listitem "><p>
      backup-restore
     </p></li></ul></div><p>
    View the online help for any command, like this example:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code> cf backup-info --help
 NAME:
   backup-info - Show information about the current snapshot

 USAGE:
   cf backup-info</pre></div><p>
    Create a backup of your SUSE Cloud Application Platform data and applications. The command
    outputs progress messages until it is completed:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf backup-snapshot
 2018/08/18 12:48:27 Retrieving resource /v2/quota_definitions
 2018/08/18 12:48:30 org quota definitions done
 2018/08/18 12:48:30 Retrieving resource /v2/space_quota_definitions
 2018/08/18 12:48:32 space quota definitions done
 2018/08/18 12:48:32 Retrieving resource /v2/organizations
 [...]</pre></div><p>
    Your Cloud Application Platform data is saved in the current directory in
    <code class="filename">cf-backup.json</code>, and application data in the
    <code class="filename">app-bits/</code> directory.
   </p><p>
    View the current backup:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf backup-info
 - Org  system</pre></div><p>
    Restore from backup:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf backup-restore</pre></div><p>
    There are two additional restore options:
    <code class="command">--include-security-groups</code> and
    <code class="command">--include-quota-definitions</code>.
   </p></div><div class="sect2 " id="sec-cap-backup-restore-plugin-scope"><div class="titlepage"><div><div><h3 class="title"><span class="number">21.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Scope of Backup</span> <a title="Permalink" class="permalink" href="#sec-cap-backup-restore-plugin-scope">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span>sec-cap-backup-restore-plugin-scope</li></ul></div></div></div></div><p>
    The following table lists the scope of the
    <code class="literal">cf-plugin-backup</code> backup. Organization and space users
    are backed up at the SUSE Cloud Application Platform level. The user account in
    <code class="literal">uaa</code>/LDAP, the service instances and their application
    bindings, and buildpacks are not backed up. The sections following the
    table goes into more detail.
   </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col /><col /></colgroup><thead><tr><th>Scope</th><th>Restore</th></tr></thead><tbody><tr><td>Orgs</td><td>Yes</td></tr><tr><td>Org auditors</td><td>Yes</td></tr><tr><td>Org billing-manager</td><td>Yes</td></tr><tr><td>Quota definitions</td><td>Optional</td></tr><tr><td>Spaces</td><td>Yes</td></tr><tr><td>Space developers</td><td>Yes</td></tr><tr><td>Space auditors</td><td>Yes</td></tr><tr><td>Space managers</td><td>Yes</td></tr><tr><td>Apps</td><td>Yes</td></tr><tr><td>App binaries</td><td>Yes</td></tr><tr><td>Routes</td><td>Yes</td></tr><tr><td>Route mappings</td><td>Yes</td></tr><tr><td>Domains</td><td>Yes</td></tr><tr><td>Private domains</td><td>Yes</td></tr><tr><td>Stacks</td><td>not available</td></tr><tr><td>Feature flags</td><td>Yes</td></tr><tr><td>Security groups</td><td>Optional</td></tr><tr><td>Custom buildpacks</td><td>No</td></tr></tbody></table></div><p>
    <code class="command">cf backup-info</code> reads the
    <code class="filename">cf-backup.json</code> snapshot file found in the current
    working directory, and reports summary statistics on the content.
   </p><p>
    <code class="command">cf backup-snapshot</code> extracts and saves the following
    information from the CC into a <code class="filename">cf-backup.json</code> snapshot
    file. Note that it does not save user information, but only the references
    needed for the roles. The full user information is handled by the
    <code class="literal">uaa</code> server, and the plugin talks only to the CC. The
    following list provides a summary of what each plugin command does.
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      Org Quota Definitions
     </p></li><li class="listitem "><p>
      Space Quota Definitions
     </p></li><li class="listitem "><p>
      Shared Domains
     </p></li><li class="listitem "><p>
      Security Groups
     </p></li><li class="listitem "><p>
      Feature Flags
     </p></li><li class="listitem "><p>
      Application droplets (zip files holding the staged app)
     </p></li><li class="listitem "><p>
      Orgs
     </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        Spaces
       </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
          Applications
         </p></li><li class="listitem "><p>
          Users' references (role in the space)
         </p></li></ul></div></li></ul></div></li></ul></div><p>
    <code class="command">cf backup-restore</code> reads the
    <code class="filename">cf-backup.json</code> snapshot file found in the current
    working directory, and then talks to the targeted KubeCF instance to upload
    the following information, in the specified order:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      Shared domains
     </p></li><li class="listitem "><p>
      Feature flags
     </p></li><li class="listitem "><p>
      Quota Definitions (iff --include-quota-definitions)
     </p></li><li class="listitem "><p>
      Orgs
     </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        Space Quotas (iff --include-quota-definitions)
       </p></li><li class="listitem "><p>
        UserRoles
       </p></li><li class="listitem "><p>
        (private) Domains
       </p></li><li class="listitem "><p>
        Spaces
       </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
          UserRoles
         </p></li><li class="listitem "><p>
          Applications (+ droplet)
         </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
            Bound Routes
           </p></li></ul></div></li><li class="listitem "><p>
          Security Groups (iff --include-security-groups)
         </p></li></ul></div></li></ul></div></li></ul></div><p>
    The following list provides more details of each action.
   </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.5.11.2.7.10.1"><span class="term ">Shared Domains</span></dt><dd><p>
       Attempts to create domains from the backup. Existing domains are
       retained, and not overwritten.
      </p></dd><dt id="id-1.3.5.11.2.7.10.2"><span class="term ">Feature Flags</span></dt><dd><p>
       Attempts to update flags from the backup.
      </p></dd><dt id="id-1.3.5.11.2.7.10.3"><span class="term ">Quota Definitions</span></dt><dd><p>
       Existing quotas are overwritten from the backup (deleted, re-created).
      </p></dd><dt id="id-1.3.5.11.2.7.10.4"><span class="term ">Orgs</span></dt><dd><p>
       Attempts to create orgs from the backup. Attempts to update existing
       orgs from the backup.
      </p></dd><dt id="id-1.3.5.11.2.7.10.5"><span class="term ">Space Quota Definitions</span></dt><dd><p>
       Existing quotas are overwritten from the backup (deleted, re-created).
      </p></dd><dt id="id-1.3.5.11.2.7.10.6"><span class="term ">User roles</span></dt><dd><p>
       Expect the referenced user to exist. Will fail when the user is already
       associated with the space, in the given role.
      </p></dd><dt id="id-1.3.5.11.2.7.10.7"><span class="term ">(private) Domains</span></dt><dd><p>
       Attempts to create domains from the backup. Existing domains are
       retained, and not overwritten.
      </p></dd><dt id="id-1.3.5.11.2.7.10.8"><span class="term ">Spaces</span></dt><dd><p>
       Attempts to create spaces from the backup. Attempts to update existing
       spaces from the backup.
      </p></dd><dt id="id-1.3.5.11.2.7.10.9"><span class="term ">User roles</span></dt><dd><p>
       Expect the referenced user to exist. Will fail when the user is already
       associated with the space, in the given role.
      </p></dd><dt id="id-1.3.5.11.2.7.10.10"><span class="term ">Apps</span></dt><dd><p>
       Attempts to create apps from the backup. Attempts to update existing
       apps from the backup (memory, instances, buildpack, state, ...)
      </p></dd><dt id="id-1.3.5.11.2.7.10.11"><span class="term ">Security groups</span></dt><dd><p>
       Existing groups are overwritten from the backup
      </p></dd></dl></div></div></div><div class="sect1 " id="sec-cap-backup-restore-of-raw-data"><div class="titlepage"><div><div><h2 class="title"><span class="number">21.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Disaster Recovery through Raw Data Backup and Restore</span> <a title="Permalink" class="permalink" href="#sec-cap-backup-restore-of-raw-data">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span>sec-cap-backup-restore-of-raw-data</li></ul></div></div></div></div><p>
   An existing SUSE Cloud Application Platform deployment's data can be migrated to a new
   SUSE Cloud Application Platform deployment through a backup and restore of its raw data. The
   process involves performing a backup and restore of the
   <code class="literal">kubecf</code> components respectively. This procedure is agnostic of
   the underlying Kubernetes infrastructure and can be included as part of your
   disaster recovery solution.
  </p><div class="sect2 " id="sec-cap-raw-data-prerequisites"><div class="titlepage"><div><div><h3 class="title"><span class="number">21.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#sec-cap-raw-data-prerequisites">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span>sec-cap-raw-data-prerequisites</li></ul></div></div></div></div><p>
    In order to complete a raw data backup and restore, the following are
    required:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      Access to a running deployment of <code class="literal">kubecf</code> to create backups
      with
     </p></li><li class="listitem "><p>
      Access to a new deployment of <code class="literal">kubecf</code> (deployed with a
      <code class="filename">kubecf-config-values.yaml</code> configured according to
      <a class="xref" href="#prepare-config-for-new-cluster" title="Step 1">Step 1</a> of
      <a class="xref" href="#sec-cap-raw-data-restore-procedure" title="21.2.4. Performing a Raw Data Restore">Section 21.2.4, “Performing a Raw Data Restore”</a>) to perform the
      restore to
     </p></li></ul></div></div><div class="sect2 " id="sec-cap-raw-data-scope"><div class="titlepage"><div><div><h3 class="title"><span class="number">21.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Scope of Raw Data Backup and Restore</span> <a title="Permalink" class="permalink" href="#sec-cap-raw-data-scope">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span>sec-cap-raw-data-scope</li></ul></div></div></div></div><p>
    The following lists the data that is included as part of the backup (and
    restore) procedure:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      The Cloud Controller Database (CCDB). In addition to what is encompassed
      by the CCDB listed in
      <a class="xref" href="#sec-cap-backup-restore-plugin-scope" title="21.1.3. Scope of Backup">Section 21.1.3, “Scope of Backup”</a>, this will include
      service binding data as well.
     </p></li><li class="listitem "><p>
      The Cloud Controller blobstore, which includes the types of binary large
      object (blob) files listed below. (See
      <a class="link" href="https://docs.cloudfoundry.org/concepts/architecture/cloud-controller.html#blob-store" target="_blank">https://docs.cloudfoundry.org/concepts/architecture/cloud-controller.html#blob-store</a>
      to learn more about each blob type.)
     </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        App Packages
       </p></li><li class="listitem "><p>
        Buildpacks
       </p></li><li class="listitem "><p>
        Resource Cache
       </p></li><li class="listitem "><p>
        Buildpack Cache
       </p></li><li class="listitem "><p>
        Droplets
       </p></li></ul></div></li><li class="listitem "><p>
      User data
     </p></li></ul></div></div><div class="sect2 " id="sec-cap-raw-data-backup-procedure"><div class="titlepage"><div><div><h3 class="title"><span class="number">21.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Performing a Raw Data Backup</span> <a title="Permalink" class="permalink" href="#sec-cap-raw-data-backup-procedure">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span>sec-cap-raw-data-backup-procedure</li></ul></div></div></div></div><div id="id-1.3.5.11.3.5.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note: Restore to the Same Version</h6><p>
     This process is intended for backing up and restoring to a target
     deployment with the same version as the source deployment. For example,
     data from a backup of SUSE Cloud Application Platform 2.1.0 should be restored to a
     SUSE Cloud Application Platform 2.1.0 deployment.
    </p></div><p>
    Perform the following steps to create a backup of your source
    SUSE Cloud Application Platform deployment.
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      Export the blobstore into a file.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --namespace kubecf singleton-blobstore-0 --
tar cfz - --exclude=/var/vcap/store/shared/tmp /var/vcap/store/shared &gt;
blob.tgz</pre></div></li><li class="step "><p>
      The current UAA database configuration does not allow exporting of a
      mysqldump, so need to be more permissive.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cat &lt;&lt;EOF | kubectl exec --stdin database-0 --namespace kubecf
-- mysql
SET GLOBAL pxc_strict_mode=PERMISSIVE;
SET GLOBAL
sql_mode='STRICT_ALL_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';
set GLOBAL innodb_strict_mode='OFF';
EOF</pre></div></li><li class="step "><p>
      Export the UAA database into a file.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --stdin database-0 --namespace kubecf --
mysqldump uaa &gt; uaadb-src.sql</pre></div></li><li class="step "><p>
      Export the Cloud Controller Database (CCDB) into a file.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --stdin database-0 --namespace kubecf --
mysqldump cloud_controller &gt; ccdb-src.sql</pre></div></li><li class="step " id="get-encryption-key"><p>
      Save the CCDB encryption key(s). Adjust the <code class="command">A</code> flag as
      needed to include all keys.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --stdin --tty --namespace kubecf api-0 -- bash
-c "cat /var/vcap/jobs/cloud_controller_ng/config/cloud_controller_ng.yml | grep
-A 10 db_encryption" &gt; enc_key</pre></div></li></ol></div></div></div><div class="sect2 " id="sec-cap-raw-data-restore-procedure"><div class="titlepage"><div><div><h3 class="title"><span class="number">21.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Performing a Raw Data Restore</span> <a title="Permalink" class="permalink" href="#sec-cap-raw-data-restore-procedure">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_backup-restore.xml</li><li><span class="ds-label">ID: </span>sec-cap-raw-data-restore-procedure</li></ul></div></div></div></div><div id="id-1.3.5.11.3.6.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Ensure Access to the Correct Deployment</h6><p>
     Working with multiple Kubernetes clusters simultaneously can be confusing.
     Ensure you are communicating with the desired cluster
     <a class="link" href="https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#set-the-kubeconfig-environment-variable" target="_blank">by
     setting <code class="literal">$KUBECONFIG</code> correctly</a>.
    </p></div><p>
    Perform the following steps to restore your backed up data to the target
    SUSE Cloud Application Platform deployment.
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step " id="prepare-config-for-new-cluster"><p>
      Deploy the target SUSE Cloud Application Platform cluster following the steps for your
      platform.
     </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    For SUSE® CaaS Platform, see <a class="xref" href="#cha-cap-depl-caasp" title="Chapter 4. Deploying SUSE Cloud Application Platform on SUSE CaaS Platform">Chapter 4, <em>Deploying SUSE Cloud Application Platform on SUSE CaaS Platform</em></a>.
   </p></li><li class="listitem "><p>
    For Microsoft Azure Kubernetes Service, see <a class="xref" href="#cha-cap-depl-aks" title="Chapter 5. Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)">Chapter 5, <em>Deploying SUSE Cloud Application Platform on Microsoft Azure Kubernetes Service (AKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Amazon Elastic Kubernetes Service, see <a class="xref" href="#cha-cap-depl-eks" title="Chapter 6. Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)">Chapter 6, <em>Deploying SUSE Cloud Application Platform on Amazon Elastic Kubernetes Service (EKS)</em></a>.
   </p></li><li class="listitem "><p>
    For Google Kubernetes Engine, see <a class="xref" href="#cha-cap-depl-gke" title="Chapter 7. Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)">Chapter 7, <em>Deploying SUSE Cloud Application Platform on Google Kubernetes Engine (GKE)</em></a>.
   </p></li></ul></div></li><li class="step "><p>
      The current UAA database configuration does not allow importing of a
      mysqldump, so needs to be made more permissive.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cat &lt;&lt;EOF | kubectl exec --stdin database-0 --namespace kubecf
-- mysql
SET GLOBAL pxc_strict_mode=PERMISSIVE;
SET GLOBAL
sql_mode='STRICT_ALL_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';
set GLOBAL innodb_strict_mode='OFF';
EOF</pre></div></li><li class="step "><p>
      Import the UAA database.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --stdin database-0 --namespace kubecf -- mysql
uaa &lt; uaadb-src.sql</pre></div><p>
      Verify the import is successful. The output should list the users from the
      deployment the backup was taken from.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>echo "select username from uaa.users;" | kubectl exec -i
database-0 --namespace kubecf -- mysql</pre></div></li><li class="step "><p>
      Import the blobstore and restart the pod for changes to take affect.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --stdin singleton-blobstore-0 --namespace kubecf -- tar xfz - -C
/ &lt; blob.tgz

<code class="prompt user">tux &gt; </code>kubectl delete pod --namespace kubecf singleton-blobstore-0</pre></div></li><li class="step "><p>
      Drop the current CCDB and create a new instance.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>echo "drop database cloud_controller; create database
cloud_controller;" | \
     kubectl exec -i database-0 --namespace kubecf -- mysql</pre></div></li><li class="step "><p>
      Import the CCDB.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --stdin database-0 --namespace kubecf -- mysql
cloud_controller &lt; ccdb-src.sql</pre></div></li><li class="step "><p>
      Update the encryption key.
     </p><ol type="a" class="substeps "><li class="step "><p>
        Create a YAML configuration file containing the encryption key
        information. The file structure should look similar to the following
        example, called <code class="filename">enc_key_values.yaml</code>. Replace 
        the example values using the values from the <code class="filename">enc_key</code>
        file generated earlier. Depending on the state of the cluster the
        encryption keys were retrieved from, the key labels may differ and not
        be <code class="literal">encryption_key_0</code>. 
       </p><div class="verbatim-wrap"><pre class="screen">ccdb:
  encryption:
    rotation:
      key_labels:
      - <em class="replaceable ">encryption_key_0</em>
      current_key_label: <em class="replaceable ">encryption_key_0</em>

credentials:
  cc_db_encryption_key:
<em class="replaceable ">elqdi7TARO6NYELa9cUr6WwMYIvqaG4U0nMyfL1loDYi02C1Rrneov6fxxfd64je</em>
  ccdb_key_label_<em class="replaceable ">encryption_key_0</em>:
<em class="replaceable ">tPhZZbMNYVWKs0II8e8pMxsJMokeReUrJAnQNdLaXEheTZVv5OpMe7vdyThhrkEP</em></pre></div><p>
        In the above, the key
        <code class="literal">credentials.ccdb_key_label_encryption_key_0</code> is
        based on the generic form
        <code class="literal">credentials.ccdb_key_label_XYZ</code>. The
        <code class="literal">XYZ</code> should be replaced with the value of the
        <code class="literal">current_key_label</code>.
       </p><p>
        For example, if the <code class="literal">current_key_label</code> is
        <code class="literal">new_key</code>, then
        <code class="literal">credentials.ccdb_key_label_new_key</code> should be used.
       </p></li><li class="step "><p>
        Perform a <code class="command">helm upgrade</code> for the changes to take
        affect.
       </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">kubecf</em> suse/kubecf
\
--namespace <em class="replaceable ">kubecf</em> \
--values kubecf-config-values.yaml \
--values <em class="replaceable ">enc_key_values.yaml</em> \
--version 2.5.8</pre></div></li></ol></li><li class="step "><p>
      When all pods are fully running, verify the restore is successful. Example
      commands to run include <code class="command">cf apps</code>,
      <code class="command">cf marketplace</code>, or <code class="command">cf services</code>.
     </p></li></ol></div></div></div></div></div><div class="chapter " id="cha-cap-service-brokers"><div class="titlepage"><div><div><h2 class="title"><span class="number">22 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Service Brokers</span> <a title="Permalink" class="permalink" href="#cha-cap-service-brokers">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_service_broker.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-minibroker"><span class="number">22.1 </span><span class="name">Provisioning Services with Minibroker</span></a></span></dt></dl></div></div><p>
  The Open Service Broker API provides (OSBAPI) your SUSE Cloud Application Platform applications
  with access to external dependencies and platform-level capabilities, such as
  databases, filesystems, external repositories, and messaging systems. These
  resources are called services. Services are created, used, and deleted as
  needed, and provisioned on demand. This chapter focuses on Minibroker but
  there are others.
 </p><p>
  Use the following guideline to determine which service broker is most suitable
  for your situation.
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    When you want services deployed on demand to Kubernetes, use Minibroker. See
    <a class="xref" href="#sec-cap-minibroker" title="22.1. Provisioning Services with Minibroker">Section 22.1, “Provisioning Services with Minibroker”</a> for more information.
   </p></li><li class="listitem "><p>
    When you want a service that is not one of the above, note that 3rd party
    OSBAPI brokers will work with SUSE Cloud Application Platform. Refer to the Cloud Foundry documentation
    at <a class="link" href="https://docs.cloudfoundry.org/services/managing-service-brokers.html" target="_blank">https://docs.cloudfoundry.org/services/managing-service-brokers.html</a> 
    for configuration instructions.
   </p></li></ul></div><div class="sect1 " id="sec-cap-minibroker"><div class="titlepage"><div><div><h2 class="title"><span class="number">22.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Provisioning Services with Minibroker</span> <a title="Permalink" class="permalink" href="#sec-cap-minibroker">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_service_broker.xml</li><li><span class="ds-label">ID: </span>sec-cap-minibroker</li></ul></div></div></div></div><p>
   <a class="link" href="https://github.com/SUSE/minibroker" target="_blank">Minibroker</a> is an
   <a class="link" href="https://www.openservicebrokerapi.org/" target="_blank">OSBAPI compliant
   broker</a> created by members of the
   <a class="link" href="https://github.com/osbkit" target="_blank">Microsoft Azure team</a>. It
   provides a simple method to provision service brokers on Kubernetes clusters.
  </p><div id="id-1.3.5.12.5.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Minibroker Upstream Services</h6><p>
    The services deployed by Minibroker are sourced from the stable upstream
    charts repository, see
    <a class="link" href="https://github.com/helm/charts/tree/master/stable" target="_blank">https://github.com/helm/charts/tree/master/stable</a>,
    and maintained by contributors to the Helm project. Though SUSE supports
    Minibroker itself, it does not support the service charts it deploys.
    Operators should inspect the charts and images exposed by the service plans
    before deciding to use them in a production environment.
   </p></div><div class="sect2 " id="sec-cap-minibroker-deployment"><div class="titlepage"><div><div><h3 class="title"><span class="number">22.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy Minibroker</span> <a title="Permalink" class="permalink" href="#sec-cap-minibroker-deployment">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_service_broker.xml</li><li><span class="ds-label">ID: </span>sec-cap-minibroker-deployment</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      Minibroker is deployed using a Helm chart. Ensure your SUSE Helm chart
      repository contains the most recent Minibroker chart:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm repo update</pre></div></li><li class="step "><p>
      Use Helm to deploy Minibroker:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace minibroker
	     
<code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">minibroker</em> suse/minibroker \
--namespace <em class="replaceable ">minibroker</em> \
--set "deployServiceCatalog=false" \
--set "defaultNamespace=minibroker"</pre></div><p>                                                                        
      If you are using SUSE Enterprise Storage, you must copy the Ceph admin secret to the           
      <code class="literal">minibroker</code> namespace:                                        
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get secret ceph-secret-admin --output json
--namespace default | \
sed 's/"namespace": "default"/"namespace": "minibroker"/' | kubectl create
--filename -</pre></div><div id="id-1.3.5.12.5.4.2.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
       Platform users provisioning service instances will be able to set
       arbitrary parameters, which can be potentially dangerous, e.g. if setting
       a high number of replicas. To prevent this, it is possible to define
       override parameters per service in the according fields of the
       <code class="literal">provisioning</code> chart value. If defined, the user-defined
       parameters are dropped and the override parameters are used instead. 
      </p><p>
       The below is an example <code class="filename">values.yaml</code> file where the
       <code class="literal">provisioning</code> chart value contains a series of override
       definitions for different services. When the override parameters (or
       other configurations) are defined in a <code class="filename">values.yaml</code>
       file, ensure the file is used by including <code class="command">--values
       FILE</code> in the <code class="command">helm install</code> command.
      </p><div class="verbatim-wrap"><pre class="screen">### Example configuration file
### minibroker-values.yaml

provisioning:
  mariadb:
    overrideParams:
      db:
        user: "dbuser"
        name: "default"
      replication:
        enabled: false
      metrics:
        enabled: false
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
  postgresql:
    overrideParams:
      postgresqlUsername: "dbuser"
      postgresqlDatabase: "default"
      replication:
        enabled: false
      metrics:
        enabled: false
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
  redis:
    overrideParams:
      cluster:
        enabled: false
      networkPolicy:
        enabled: false
      securityContext:
        enabled: true
      sentinel:
        enabled: false
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
  rabbitmq:
    overrideParams:
      rabbitmq:
        username: "dbuser"
      replicas: 1
      networkPolicy:
        enabled: false
      ingress:
        enabled: false
      metrics:
        enabled: false
      forceBoot:
        enabled: false
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
  mongodb:
    overrideParams:
      volumePermissions:
        enabled: false
      service:
        type: ClusterIP
      replicaSet:
        enabled: false
      ingress:
        enabled: false
      metrics:
        enabled: false
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi</pre></div></div><p>
      The following tables list the services provided by Minibroker, along with
      the latest chart and application version combination known to work with
      Minibroker.
     </p><p>
      If your deployment uses Kubernetes 1.15 or earlier, use the following versions.
     </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col /><col /><col /></colgroup><thead><tr><th>Service</th><th>Version</th><th>appVersion</th></tr></thead><tbody><tr><td>MariaDB</td><td>4.3.0</td><td>10.1.34</td></tr><tr><td>MongoDB</td><td>5.3.3</td><td>4.0.6</td></tr><tr><td>PostgreSQL</td><td>6.2.1</td><td>11.5.0</td></tr><tr><td>Redis</td><td>3.7.2</td><td>4.0.10</td></tr></tbody></table></div><p>
      If your deployment uses Kubernetes 1.16 or later, use the following versions.
     </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col /><col /><col /></colgroup><thead><tr><th>Service</th><th>Version</th><th>appVersion</th></tr></thead><tbody><tr><td>MariaDB</td><td>7.0.0</td><td>10.3.18</td></tr><tr><td>MongoDB</td><td>7.2.9</td><td>4.0.12</td></tr><tr><td>PostgreSQL</td><td>7.0.0</td><td>11.5.0</td></tr><tr><td>Redis</td><td>9.1.12</td><td>5.0.5</td></tr></tbody></table></div></li><li class="step "><p>
      Monitor the deployment progress. Wait until all pods are in a ready state
      before proceeding:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace minibroker'</pre></div></li></ol></div></div></div><div class="sect2 " id="sec-cap-minibroker-environment-setup"><div class="titlepage"><div><div><h3 class="title"><span class="number">22.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Setting Up the Environment for Minibroker Usage</span> <a title="Permalink" class="permalink" href="#sec-cap-minibroker-environment-setup">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_service_broker.xml</li><li><span class="ds-label">ID: </span>sec-cap-minibroker-environment-setup</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      Begin by logging into your Cloud Application Platform deployment. Select an organization and
      space to work with, creating them if needed. Be sure to replace
      <code class="literal">example.com</code> with the <code class="literal">system_domain</code>
      set in your <code class="filename">kubecf-config-values.yaml</code>.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation <em class="replaceable ">https://api.example.com</em>
 <code class="prompt user">tux &gt; </code>cf login -u <em class="replaceable ">admin</em> -p <em class="replaceable ">PASSWORD</em>
 <code class="prompt user">tux &gt; </code>cf create-org <em class="replaceable ">MY_ORG</em>
 <code class="prompt user">tux &gt; </code>cf create-space <em class="replaceable ">MY_SPACE</em> -o <em class="replaceable ">MY_ORG</em>
 <code class="prompt user">tux &gt; </code>cf target -o <em class="replaceable ">MY_ORG</em> -s <em class="replaceable ">MY_SPACE</em></pre></div></li><li class="step "><p>
      Create the service broker. Note that Minibroker does not require
      authentication and the <code class="literal">USERNAME</code> and
      <code class="literal">PASSWORD</code> parameters act as dummy values to pass to the
      <code class="command">cf</code> command. These parameters do not need to be
      customized for the Cloud Application Platform installation:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-service-broker <em class="replaceable ">minibroker</em> <em class="replaceable ">USERNAME</em> <em class="replaceable ">PASSWORD</em> http://minibroker-minibroker.minibroker.svc.cluster.local</pre></div><p>
      After the service broker is ready, it can be seen on your deployment:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf service-brokers
 Getting service brokers as admin...

 name               url
 minibroker         http://minibroker-minibroker.minibroker.svc.cluster.local</pre></div></li><li class="step "><p>
      List the services and their associated plans the Minibroker has access to:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf service-access -b <em class="replaceable ">minibroker</em></pre></div></li><li class="step "><p>
      Enable access to a service. Refer to the table in
      <a class="xref" href="#sec-cap-minibroker-deployment" title="22.1.1. Deploy Minibroker">Section 22.1.1, “Deploy Minibroker”</a> for service plans known to
      be working with Minibroker.
     </p><p>
      This example enables access to the Redis service:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf enable-service-access <em class="replaceable ">redis</em> -b <em class="replaceable ">minibroker</em> -p <em class="replaceable ">5-0-5</em></pre></div><p>
      Use <code class="command">cf marketplace</code> to verify the service has been
      enabled:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf marketplace
 Getting services from marketplace in org org / space space as admin...
 OK

 service      plans     description
 redis        5-0-5     Helm Chart for redis

 TIP:  Use 'cf marketplace -s SERVICE' to view descriptions of individual plans of a given service.</pre></div></li><li class="step "><p>
      Define your
      <a class="link" href="https://docs.cloudfoundry.org/concepts/asg.html" target="_blank">Application
      Security Group (ASG)</a> rules in a JSON file. Using the defined rules,
      create an ASG and bind it to an organization and space:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>echo &gt; <em class="replaceable ">redis.json</em> '[{ "protocol": "tcp", "destination": "<em class="replaceable ">10.0.0.0/8</em>", "ports": "<em class="replaceable ">6379</em>", "description": "<em class="replaceable ">Allow Redis traffic</em>" }]'
 <code class="prompt user">tux &gt; </code>cf create-security-group <em class="replaceable ">redis_networking</em> <em class="replaceable ">redis.json</em>
 <code class="prompt user">tux &gt; </code>cf bind-security-group <em class="replaceable ">redis_networking</em> <em class="replaceable ">org</em> <em class="replaceable ">space</em></pre></div><p>
      Use following ports to define your ASG for the given service:
     </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col /><col /></colgroup><thead><tr><th>Service</th><th>Port</th></tr></thead><tbody><tr><td>MariaDB</td><td>3306</td></tr><tr><td>MongoDB</td><td>27017</td></tr><tr><td>PostgreSQL</td><td>5432</td></tr><tr><td>Redis</td><td>6379</td></tr></tbody></table></div></li><li class="step "><p>
      Create an instance of the Redis service. The <code class="command">cf
      marketplace</code> or <code class="command">cf marketplace -s redis</code>
      commands can be used to see the available plans for the service:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-service <em class="replaceable ">redis</em> <em class="replaceable ">5-0-5</em> <em class="replaceable ">redis-example-service</em></pre></div><p>
      Monitor the progress of the pods and wait until all pods are in a ready
      state. The example below shows the additional <code class="literal">redis</code>
      pods with a randomly generated name that have been created in the
      <code class="literal">minibroker</code> namespace:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>watch --color 'kubectl get pods --namespace minibroker'
 NAME                                            READY     STATUS             RESTARTS   AGE
 alternating-frog-redis-master-0                 1/1       Running            2          1h
 alternating-frog-redis-slave-7f7444978d-z86nr   1/1       Running            0          1h
 minibroker-minibroker-5865f66bb8-6dxm7          2/2       Running            0          1h</pre></div></li></ol></div></div></div><div class="sect2 " id="sec-cap-minibroker-application-usage"><div class="titlepage"><div><div><h3 class="title"><span class="number">22.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Minibroker with Applications</span> <a title="Permalink" class="permalink" href="#sec-cap-minibroker-application-usage">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_service_broker.xml</li><li><span class="ds-label">ID: </span>sec-cap-minibroker-application-usage</li></ul></div></div></div></div><p>
    This section demonstrates how to use Minibroker services with your
    applications. The example below uses the Redis service instance created in
    the previous section.
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      Obtain the demo application from Github and use <code class="command">cf push</code>
      with the <code class="literal">--no-start</code> flag to deploy the application
      without starting it:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>git clone https://github.com/scf-samples/cf-redis-example-app
 <code class="prompt user">tux &gt; </code>cd cf-redis-example-app
 <code class="prompt user">tux &gt; </code>cf push --no-start</pre></div></li><li class="step "><p>
      Bind the service to your application and start the application:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf bind-service redis-example-app redis-example-service
 <code class="prompt user">tux &gt; </code>cf start redis-example-app</pre></div></li><li class="step "><p>
      When the application is ready, it can be tested by storing a value into
      the Redis service. Be sure to replace <code class="literal">example.com</code> with
      the <code class="literal">system_domain</code> set in your <code class="filename">kubecf-config-values.yaml</code>.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>export APP=redis-example-app.example.com
 <code class="prompt user">tux &gt; </code>curl --request GET $APP/foo
 <code class="prompt user">tux &gt; </code>curl --request PUT $APP/foo --data 'data=bar'
 <code class="prompt user">tux &gt; </code>curl --request GET $APP/foo</pre></div><p>
      The first <code class="literal">GET</code> will return <code class="literal">key not
      present</code>. After storing a value, it will return
      <code class="literal">bar</code>.
     </p></li></ol></div></div><div id="id-1.3.5.12.5.6.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Database Names for PostgreSQL and MariaDB Instances</h6><p>
     By default, Minibroker creates PostgreSQL and MariaDB server instances
     without a named database. A named database is required for normal usage
     with these and will need to be added during the <code class="command">cf
     create-service</code> step using the <code class="literal">-c</code> flag. To find
     out the exact parameter to be used, reference the <code class="literal">values.yaml</code>
     file in the upstream Helm charts at <a class="link" href="https://github.com/helm/charts" target="_blank">https://github.com/helm/charts</a>
     located in the <code class="literal">stable</code> directory.
    </p></div></div></div></div><div class="chapter " id="cha-cap-app-autoscaler"><div class="titlepage"><div><div><h2 class="title"><span class="number">23 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">App-AutoScaler</span> <a title="Permalink" class="permalink" href="#cha-cap-app-autoscaler">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_app_autoscaler.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-app-autoscaler-prereqs"><span class="number">23.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-enable-app-autoscaler"><span class="number">23.2 </span><span class="name">Enabling and Disabling the App-AutoScaler Service</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-app-autoscaler-usage"><span class="number">23.3 </span><span class="name">Using the App-AutoScaler Service</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-app-autoscaler-policies"><span class="number">23.4 </span><span class="name">Policies</span></a></span></dt></dl></div></div><p>
  The App-AutoScaler service is used for automatically managing an
  application's instance count when deployed on KubeCF. The scaling behavior is
  determined by a set of criteria defined in a policy (See
  <a class="xref" href="#sec-cap-app-autoscaler-policies" title="23.4. Policies">Section 23.4, “Policies”</a>).
 </p><div class="sect1 " id="sec-cap-app-autoscaler-prereqs"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#sec-cap-app-autoscaler-prereqs">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_app_autoscaler.xml</li><li><span class="ds-label">ID: </span>sec-cap-app-autoscaler-prereqs</li></ul></div></div></div></div><p>
   Using the App-AutoScaler service requires:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     A running deployment of <code class="literal">kubecf</code>
    </p></li><li class="listitem "><p>
 <code class="command">cf</code>, the Cloud Foundry command line interface. For more information,
 see <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">https://docs.cloudfoundry.org/cf-cli/</a>.
</p><p>
 For SUSE Linux Enterprise and openSUSE systems, install using <code class="command">zypper</code>.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo zypper install cf-cli</pre></div><p>
 For SLE, ensure the SUSE Cloud Application Platform Tools Module has been added. Add the
 module using YaST or SUSEConnect.
</p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SUSEConnect --product sle-module-cap-tools/15.1/x86_64</pre></div><p>
 For other systems, follow the instructions at
 <a class="link" href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_blank">https://docs.cloudfoundry.org/cf-cli/install-go-cli.html</a>.
</p></li><li class="listitem "><p>
     The Cloud Foundry CLI AutoScaler Plug-in, see <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin</a>
    </p><p>
     The plugin can be installed by running the following command:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf install-plugin -r <em class="replaceable ">CF-Community</em> app-autoscaler-plugin</pre></div><p>
      If the plugin repo is not found, add it first:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf add-plugin-repo <em class="replaceable ">CF-Community</em> https://plugins.cloudfoundry.org</pre></div></li></ul></div></div><div class="sect1 " id="sec-cap-enable-app-autoscaler"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling and Disabling the App-AutoScaler Service</span> <a title="Permalink" class="permalink" href="#sec-cap-enable-app-autoscaler">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_app_autoscaler.xml</li><li><span class="ds-label">ID: </span>sec-cap-enable-app-autoscaler</li></ul></div></div></div></div><p>
   App-AutoScaler is disabled by default. To enable it, add the following the following
   block to your <code class="filename">kubecf-config-values.yaml</code> file.
  </p><div class="verbatim-wrap"><pre class="screen">features:
  autoscaler:
    enabled: true</pre></div><p>
   To disable App-AutoScaler again, update the above block in your <code class="filename">kubecf-config-values.yaml</code>
   so that <code class="literal">enabled</code> is set to <code class="literal">false</code>.
  </p><p>
  After making the change above, and any other configuration changes, apply the
   update by doing the following:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     For an initial deployment, continue to the deployment steps for your platform:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       For SUSE CaaS Platform, see <a class="xref" href="#sec-cap-cap-on-caasp" title="4.13. Deploying SUSE Cloud Application Platform">Section 4.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Microsoft AKS, see <a class="xref" href="#sec-cap-cap-on-aks" title="5.13. Deploying SUSE Cloud Application Platform">Section 5.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Amazon EKS, see <a class="xref" href="#sec-cap-cap-on-eks" title="6.13. Deploying SUSE Cloud Application Platform">Section 6.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Google GKE, see <a class="xref" href="#sec-cap-cap-on-gke" title="7.14. Deploying SUSE Cloud Application Platform">Section 7.14, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li></ul></div></li><li class="listitem "><p>
     For an existing deployment, use <code class="command">helm upgrade</code> to apply
     the change.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">kubecf</em> suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values <em class="replaceable ">kubecf-config-values.yaml</em> \
--version 2.5.8</pre></div></li></ul></div></div><div class="sect1 " id="sec-cap-app-autoscaler-usage"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the App-AutoScaler Service</span> <a title="Permalink" class="permalink" href="#sec-cap-app-autoscaler-usage">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_app_autoscaler.xml</li><li><span class="ds-label">ID: </span>sec-cap-app-autoscaler-usage</li></ul></div></div></div></div><p>
   Push the application without starting it
   first:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf push <em class="replaceable ">MY_APPLICATION</em> --no-start</pre></div><p>
   Attach autoscaling policy to the application:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf attach-autoscaling-policy<em class="replaceable ">MY_APPLICATION</em> <em class="replaceable ">MY_POLICY.json</em></pre></div><p>
    The policy is defined as a JSON file
    (See <a class="xref" href="#sec-cap-app-autoscaler-policies" title="23.4. Policies">Section 23.4, “Policies”</a>) in a proper format
    (See <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/policy.md" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/policy.md</a>).
  </p><p>
   Start the application:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf start <em class="replaceable ">MY_APPLICATION</em></pre></div><p>
   Autoscaling policies can be managed using cf CLI with the App-AutoScaler plugin
   as above (See <a class="xref" href="#sec-cap-app-autoscaler-cli" title="23.3.1. The App-AutoScaler cf CLI Plugin">Section 23.3.1, “The App-AutoScaler cf CLI Plugin”</a>) or using the
   App-AutoScaler API (See <a class="xref" href="#sec-cap-app-autoscaler-api" title="23.3.2. App-AutoScaler API">Section 23.3.2, “App-AutoScaler API”</a>).
  </p><div class="sect2 " id="sec-cap-app-autoscaler-cli"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The App-AutoScaler cf CLI Plugin</span> <a title="Permalink" class="permalink" href="#sec-cap-app-autoscaler-cli">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_app_autoscaler.xml</li><li><span class="ds-label">ID: </span>sec-cap-app-autoscaler-cli</li></ul></div></div></div></div><p>
    The App-AutoScaler plugin is used for managing the service with your
    applications and provides the following commands (with shortcuts in brackets). Refer to <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin#command-list" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin#command-list</a> for details about each command:
   </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.5.13.5.10.3.1"><span class="term ">autoscaling-api (asa)</span></dt><dd><p>
       Set or view AutoScaler service API endpoint. See <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-autoscaling-api" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-autoscaling-api</a> for more information.
      </p></dd><dt id="id-1.3.5.13.5.10.3.2"><span class="term ">autoscaling-policy (asp)</span></dt><dd><p>
       Retrieve the scaling policy of an application. See <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-autoscaling-policy" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-autoscaling-policy</a> for more information.
      </p></dd><dt id="id-1.3.5.13.5.10.3.3"><span class="term ">attach-autoscaling-policy (aasp)</span></dt><dd><p>
       Attach a scaling policy to an application. See <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-attach-autoscaling-policy" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-attach-autoscaling-policy</a> for more information.
      </p></dd><dt id="id-1.3.5.13.5.10.3.4"><span class="term ">detach-autoscaling-policy (dasp)</span></dt><dd><p>
       Detach the scaling policy from an application. See <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-detach-autoscaling-policy" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-detach-autoscaling-policy</a> for more information.
      </p></dd><dt id="id-1.3.5.13.5.10.3.5"><span class="term ">create-autoscaling-credential (casc)</span></dt><dd><p>
       Create custom metric credential for an application. See <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-create-autoscaling-credential" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-create-autoscaling-credential</a> for more information.
      </p></dd><dt id="id-1.3.5.13.5.10.3.6"><span class="term ">delete-autoscaling-credential (dasc)</span></dt><dd><p>
        Delete the custom metric credential of an application.
        See <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-delete-autoscaling-credential" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-delete-autoscaling-credential</a> for more information.
      </p></dd><dt id="id-1.3.5.13.5.10.3.7"><span class="term ">autoscaling-metrics (asm)</span></dt><dd><p>
       Retrieve the metrics of an application. See <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-autoscaling-metrics" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-autoscaling-metrics</a> for more information.
      </p></dd><dt id="id-1.3.5.13.5.10.3.8"><span class="term ">autoscaling-history (ash)</span></dt><dd><p>
       Retrieve the scaling history of an application. See <a class="link" href="https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-autoscaling-history" target="_blank">https://github.com/cloudfoundry/app-autoscaler-cli-plugin#cf-autoscaling-history</a> for more information.
      </p></dd></dl></div></div><div class="sect2 " id="sec-cap-app-autoscaler-api"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">App-AutoScaler API</span> <a title="Permalink" class="permalink" href="#sec-cap-app-autoscaler-api">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_app_autoscaler.xml</li><li><span class="ds-label">ID: </span>sec-cap-app-autoscaler-api</li></ul></div></div></div></div><p>
    The App-AutoScaler service provides a
    Public
    API with detailed usage information, see <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst</a>. It includes requests to:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      List scaling history of an application. For details, refer to <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#list-scaling-history-of-an-application" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#list-scaling-history-of-an-application</a>
     </p></li><li class="listitem "><p>
      List instance metrics of an application. For details, refer to <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#list-instance-metrics-of-an-application" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#list-instance-metrics-of-an-application</a>
     </p></li><li class="listitem "><p>
      List aggregated metrics of an application. For details, refer to <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#list-aggregated-metrics-of-an-application" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#list-aggregated-metrics-of-an-application</a>
     </p></li><li class="listitem "><p>
      Policy api. For details, refer to <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#policy-api" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#policy-api</a>
     </p></li><li class="listitem "><p>
      Delete policy. For details, refer to <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#delete-policy" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#delete-policy</a>
     </p></li><li class="listitem "><p>
      Get policy. For details, refer to <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#get-policy" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/develop/docs/Public_API.rst#get-policy</a>
     </p></li></ul></div></div></div><div class="sect1 " id="sec-cap-app-autoscaler-policies"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Policies</span> <a title="Permalink" class="permalink" href="#sec-cap-app-autoscaler-policies">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_app_autoscaler.xml</li><li><span class="ds-label">ID: </span>sec-cap-app-autoscaler-policies</li></ul></div></div></div></div><p>
   A policy identifies characteristics including minimum instance count,
   maximum instance count, and the rules used to determine when the number of
   application instances is scaled up or down. These rules are categorized into
   two types, scheduled scaling and dynamic scaling. (See
   <a class="xref" href="#sec-cap-app-autoscaler-scaling-types" title="23.4.1. Scaling Types">Section 23.4.1, “Scaling Types”</a>). Multiple scaling
   rules can be specified in a policy, but App-AutoScaler does not detect or
   handle conflicts that may occur. Ensure there are no conflicting rules to
   avoid unintended scaling behavior.
  </p><p>
   Policies are defined using the JSON format and can be attached to an
   application either by passing the path to the policy file or directly as a
   parameter.
  </p><p>
   The following is an example of a policy file, called
   <code class="filename">my-policy.json</code>.
  </p><div class="verbatim-wrap"><pre class="screen">{
    "instance_min_count": 1,
    "instance_max_count": 4,
    "scaling_rules": [{
        "metric_type": "memoryused",
        "stat_window_secs": 60,
        "breach_duration_secs": 60,
        "threshold": 10,
        "operator": "&gt;=",
        "cool_down_secs": 300,
        "adjustment": "+1"
    }]
}</pre></div><p>
   For an example that demonstrates defining multiple scaling rules in a single
   policy, refer to the sample of a policy file at <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/develop/src/integration/fakePolicyWithSchedule.json" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/develop/src/integration/fakePolicyWithSchedule.json</a>. The complete list of configurable policy values can be
   found at
   <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/blob/master/docs/policy.md" target="_blank">https://github.com/cloudfoundry/app-autoscaler/blob/master/docs/policy.md</a>.
  </p><div class="sect2 " id="sec-cap-app-autoscaler-scaling-types"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Scaling Types</span> <a title="Permalink" class="permalink" href="#sec-cap-app-autoscaler-scaling-types">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_app_autoscaler.xml</li><li><span class="ds-label">ID: </span>sec-cap-app-autoscaler-scaling-types</li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.5.13.6.7.2.1"><span class="term ">Scheduled Scaling</span></dt><dd><p>
       Modifies an application's instance count at a predetermined time. This
       option is suitable for workloads with predictable resource usage.
      </p></dd><dt id="id-1.3.5.13.6.7.2.2"><span class="term ">Dynamic Scaling</span></dt><dd><p>
       Modifies an application's instance count based on metrics criteria. This
       option is suitable for workloads with dynamic resource usage. The
       following metrics are available:
      </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
         memoryused
        </p></li><li class="listitem "><p>
         memoryutil
        </p></li><li class="listitem "><p>
         cpu
        </p></li><li class="listitem "><p>
         responsetime
        </p></li><li class="listitem "><p>
         throughput
        </p></li><li class="listitem "><p>
         custom metric
        </p></li></ul></div></dd></dl></div><p>
    See
    <a class="link" href="https://github.com/cloudfoundry/app-autoscaler/tree/develop/docs#scaling-type" target="_blank">https://github.com/cloudfoundry/app-autoscaler/tree/develop/docs#scaling-type</a> for additional details.
   </p></div></div></div><div class="chapter " id="cha-cap-credhub"><div class="titlepage"><div><div><h2 class="title"><span class="number">24 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Integrating CredHub with SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#cha-cap-credhub">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_credhub.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-credhub"><span class="number">24.1 </span><span class="name">Installing the CredHub Client</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-credhub-enable"><span class="number">24.2 </span><span class="name">Enabling and Disabling CredHub</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-credhub-connect"><span class="number">24.3 </span><span class="name">Connecting to the CredHub Service</span></a></span></dt></dl></div></div><p>
  SUSE Cloud Application Platform supports CredHub integration. You should already have a working
  CredHub instance, a CredHub service on your cluster, then apply the steps in
  this chapter to connect SUSE Cloud Application Platform.
 </p><div class="sect1 " id="sec-cap-credhub"><div class="titlepage"><div><div><h2 class="title"><span class="number">24.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing the CredHub Client</span> <a title="Permalink" class="permalink" href="#sec-cap-credhub">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_credhub.xml</li><li><span class="ds-label">ID: </span>sec-cap-credhub</li></ul></div></div></div></div><p>
   Start by creating a new directory for the CredHub client on your local
   workstation, then download and unpack the CredHub client. The following
   example is for the 2.2.0 Linux release. For other platforms and current
   releases, see the cloudfoundry-incubator/credhub-cli at
   <a class="link" href="https://github.com/cloudfoundry-incubator/credhub-cli/releases" target="_blank">https://github.com/cloudfoundry-incubator/credhub-cli/releases</a>
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>mkdir <em class="replaceable ">chclient</em>
<code class="prompt user">tux &gt; </code>cd <em class="replaceable ">chclient</em>
<code class="prompt user">tux &gt; </code>wget https://github.com/cloudfoundry-incubator/credhub-cli/releases/download/2.2.0/credhub-linux-2.2.0.tgz
<code class="prompt user">tux &gt; </code>tar zxf credhub-linux-2.2.0.tgz</pre></div></div><div class="sect1 " id="sec-cap-credhub-enable"><div class="titlepage"><div><div><h2 class="title"><span class="number">24.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling and Disabling CredHub</span> <a title="Permalink" class="permalink" href="#sec-cap-credhub-enable">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_credhub.xml</li><li><span class="ds-label">ID: </span>sec-cap-credhub-enable</li></ul></div></div></div></div><p>
   CredHub is enabled by default. To disable it, add the following the following
   block to your <code class="filename">kubecf-config-values.yaml</code> file.
  </p><div class="verbatim-wrap"><pre class="screen">features:
  credhub:
    enabled: false</pre></div><p>
   To enable CredHub again, update the above block in your <code class="filename">kubecf-config-values.yaml</code> so that
   <code class="literal">enabled</code> is set to <code class="literal">true</code>.
  </p><p>
  After making the change above, and any other configuration changes, apply the
   update by doing the following:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     For an initial deployment, continue to the deployment steps for your platform:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       For SUSE CaaS Platform, see <a class="xref" href="#sec-cap-cap-on-caasp" title="4.13. Deploying SUSE Cloud Application Platform">Section 4.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Microsoft AKS, see <a class="xref" href="#sec-cap-cap-on-aks" title="5.13. Deploying SUSE Cloud Application Platform">Section 5.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Amazon EKS, see <a class="xref" href="#sec-cap-cap-on-eks" title="6.13. Deploying SUSE Cloud Application Platform">Section 6.13, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li><li class="listitem "><p>
       For Google GKE, see <a class="xref" href="#sec-cap-cap-on-gke" title="7.14. Deploying SUSE Cloud Application Platform">Section 7.14, “Deploying SUSE Cloud Application Platform”</a>.
      </p></li></ul></div></li><li class="listitem "><p>
     For an existing deployment, use <code class="command">helm upgrade</code> to apply
     the change.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm upgrade <em class="replaceable ">kubecf</em> suse/kubecf \
--namespace <em class="replaceable ">kubecf</em> \
--values <em class="replaceable ">kubecf-config-values.yaml</em> \
--version 2.5.8</pre></div></li></ul></div><div id="id-1.3.5.14.4.7" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>
    On occasion, the <code class="literal">credhub</code> pod may fail to start due to
    database migration failures; this has been spotted intermittently on
    Microsoft Azure Kubernetes Service and to a lesser extent, other public clouds.
    In these situations, manual intervention is required to track the last
    completed transaction in <code class="literal">credhub_user</code> database and
    update the flyway schema history table with the record of the last
    completed transaction. Please contact support for further instructions.
   </p></div></div><div class="sect1 " id="sec-cap-credhub-connect"><div class="titlepage"><div><div><h2 class="title"><span class="number">24.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Connecting to the CredHub Service</span> <a title="Permalink" class="permalink" href="#sec-cap-credhub-connect">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_credhub.xml</li><li><span class="ds-label">ID: </span>sec-cap-credhub-connect</li></ul></div></div></div></div><p>
   Set environment variables for the CredHub client, your CredHub service
   location, and Cloud Application Platform namespace. In these guides the example namespace is
   <code class="literal">kubecf</code>:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>CH_CLI=~/chclient/credhub
<code class="prompt user">tux &gt; </code>CH_SERVICE=<em class="replaceable ">https://credhub.example.com</em>
<code class="prompt user">tux &gt; </code>NAMESPACE=<em class="replaceable ">kubecf</em></pre></div><p>
   Set up the CredHub service location:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>SECRET="$(kubectl get secrets --namespace "${NAMESPACE}" | awk '/^secrets-/ { print $1 }')"
<code class="prompt user">tux &gt; </code>CH_SECRET="$(kubectl get secrets --namespace "${NAMESPACE}" "${SECRET}" --output jsonpath="{.data['uaa-clients-credhub-user-cli-secret']}"|base64 --decode)"
<code class="prompt user">tux &gt; </code>CH_CLIENT=credhub_user_cli
<code class="prompt user">tux &gt; </code>echo Service ......@ $CH_SERVICE
<code class="prompt user">tux &gt; </code>echo CH cli Secret @ $CH_SECRET</pre></div><p>
   Set the CredHub target through its Kubernetes service, then log into CredHub:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>"${CH_CLI}" api --skip-tls-validation --server "${CH_SERVICE}"
<code class="prompt user">tux &gt; </code>"${CH_CLI}" login --client-name="${CH_CLIENT}" --client-secret="${CH_SECRET}"</pre></div><p>
   Test your new connection by inserting and retrieving some fake credentials:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>"${CH_CLI}" set --name FOX --type value --value 'fox over lazy dog'
<code class="prompt user">tux &gt; </code>"${CH_CLI}" set --name DOG --type user --username dog --password fox
<code class="prompt user">tux &gt; </code>"${CH_CLI}" get --name FOX
<code class="prompt user">tux &gt; </code>"${CH_CLI}" get --name DOG</pre></div></div></div><div class="chapter " id="cha-cap-buildpacks"><div class="titlepage"><div><div><h2 class="title"><span class="number">25 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Buildpacks</span> <a title="Permalink" class="permalink" href="#cha-cap-buildpacks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_buildpacks.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-cap-system-buildpacks"><span class="number">25.1 </span><span class="name">System Buildpacks</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-using-buildpacks"><span class="number">25.2 </span><span class="name">Using Buildpacks</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-adding-buildpacks"><span class="number">25.3 </span><span class="name">Adding Buildpacks</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-updating-buildpacks"><span class="number">25.4 </span><span class="name">Updating Buildpacks</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-offline-buildpacks"><span class="number">25.5 </span><span class="name">Offline Buildpacks</span></a></span></dt></dl></div></div><p>
  <a class="link" href="https://docs.cloudfoundry.org/buildpacks" target="_blank">Buildpacks</a>
  are used to construct the environment needed to run your applications,
  including any required runtimes or frameworks as well as other dependencies.
  When you deploy an application, a buildpack can be specified or automatically
  detected by cycling through all available buildpacks to find one that is
  applicable. When there is a suitable buildpack for your application, the
  buildpack will then download any necessary dependencies during the staging
  process.
 </p><div class="sect1 " id="sec-cap-cap-system-buildpacks"><div class="titlepage"><div><div><h2 class="title"><span class="number">25.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">System Buildpacks</span> <a title="Permalink" class="permalink" href="#sec-cap-cap-system-buildpacks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_buildpacks.xml</li><li><span class="ds-label">ID: </span>sec-cap-cap-system-buildpacks</li></ul></div></div></div></div><p>
   SUSE Cloud Application Platform releases include a set of system, or built-in, buildpacks for
   common languages and frameworks. These system buildpacks are based on the
   upstream versions of the buildpack, but are made compatible with the
   SLE-based stack(s) found in SUSE Cloud Application Platform.
  </p><p>
   The following table lists the default system buildpacks and their associated
   versions included as part of the SUSE Cloud Application Platform 2.1.0 release.
  </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col /><col /><col /></colgroup><thead><tr><th>Buildpack</th><th>Version</th><th>Github Repository</th></tr></thead><tbody><tr><td>Staticfile</td><td>1.5.5</td><td><a class="link" href="https://github.com/SUSE/cf-staticfile-buildpack" target="_blank">https://github.com/SUSE/cf-staticfile-buildpack</a></td></tr><tr><td>NGINX</td><td>1.1.7</td><td><a class="link" href="https://github.com/SUSE/cf-nginx-buildpack" target="_blank">https://github.com/SUSE/cf-nginx-buildpack</a></td></tr><tr><td>Java</td><td>4.29.1</td><td><a class="link" href="https://github.com/SUSE/cf-java-buildpack" target="_blank">https://github.com/SUSE/cf-java-buildpack</a></td></tr><tr><td>Ruby</td><td>1.8.15</td><td><a class="link" href="https://github.com/SUSE/cf-ruby-buildpack" target="_blank">https://github.com/SUSE/cf-ruby-buildpack</a></td></tr><tr><td>Node.js</td><td>1.7.17</td><td><a class="link" href="https://github.com/SUSE/cf-nodejs-buildpack" target="_blank">https://github.com/SUSE/cf-nodejs-buildpack</a></td></tr><tr><td>Go</td><td>1.9.11</td><td><a class="link" href="https://github.com/SUSE/cf-go-buildpack" target="_blank">https://github.com/SUSE/cf-go-buildpack</a></td></tr><tr><td>Python</td><td>1.7.12</td><td><a class="link" href="https://github.com/SUSE/cf-python-buildpack" target="_blank">https://github.com/SUSE/cf-python-buildpack</a></td></tr><tr><td>PHP</td><td>4.4.12</td><td><a class="link" href="https://github.com/SUSE/cf-php-buildpack" target="_blank">https://github.com/SUSE/cf-php-buildpack</a></td></tr><tr><td>Binary</td><td>1.0.36</td><td><a class="link" href="https://github.com/SUSE/cf-binary-builder" target="_blank">https://github.com/SUSE/cf-binary-builder</a></td></tr><tr><td>.NET Core</td><td>2.3.9</td><td><a class="link" href="https://github.com/SUSE/cf-dotnet-core-buildpack" target="_blank">https://github.com/SUSE/cf-dotnet-core-buildpack</a></td></tr></tbody></table></div></div><div class="sect1 " id="sec-cap-using-buildpacks"><div class="titlepage"><div><div><h2 class="title"><span class="number">25.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Buildpacks</span> <a title="Permalink" class="permalink" href="#sec-cap-using-buildpacks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_buildpacks.xml</li><li><span class="ds-label">ID: </span>sec-cap-using-buildpacks</li></ul></div></div></div></div><p>
   When deploying an application, a buildpack can be selected by passing the
   buildpack's name through one of the following methods:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Using the <code class="command">-b</code> option during the
     <code class="command">cf push</code> command, for example:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf push <em class="replaceable ">12factor</em> -b <em class="replaceable ">ruby_buildpack</em></pre></div></li><li class="listitem "><p>
     Using the <code class="literal">buildpacks</code> attribute in your application's
     <code class="filename">manifest.yml</code>. For more information, see
     <a class="link" href="https://docs.cloudfoundry.org/devguide/deploy-apps/manifest-attributes.html#buildpack" target="_blank">https://docs.cloudfoundry.org/devguide/deploy-apps/manifest-attributes.html#buildpack</a>.
    </p><div class="verbatim-wrap"><pre class="screen">---
applications:
- name: <em class="replaceable ">12factor</em>
  buildpacks:
    - <em class="replaceable ">ruby_buildpack</em></pre></div></li><li class="listitem "><p>
     Using buildpack detection.
    </p><p>
     Buildpack detection occurs when an application is pushed and a buildpack
     has not been specified using any of the other methods. The application is
     checked aginst the detection criteria of a buildpack to verify whether its
     compatible. Each buildpack has its own detection criteria, defined in the
     <code class="filename">/bin/detect</code> file. The Ruby buildpack, for example,
     considers an application compatible if it contains a
     <code class="filename">Gemfile</code> file and <code class="filename">Gemfile.lock</code>
     file in its root directory.
    </p><p>
     The detection process begins with the first buildpack in the detection
     priority list. If the buildpack is compatible with the application, the
     staging process continues. If the buildpack is <span class="emphasis"><em>not</em></span>
     compatible with the application, the buildpack in the next position is
     checked. To see the detection priority list, run
     <code class="command">cf buildpacks</code> and examine the
     <code class="literal">position</code> field. If there are no compatible buildpacks,
     the <code class="command">cf push</code> command will fail.
    </p><p>
     For more information, see
     <a class="link" href="https://docs.cloudfoundry.org/buildpacks/understand-buildpacks.html#buildpack-detection" target="_blank">https://docs.cloudfoundry.org/buildpacks/understand-buildpacks.html#buildpack-detection</a>.
    </p></li></ul></div><p>
   In the above, <em class="replaceable ">ruby_buildpack</em> can be replaced with:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The name of a buildpack. To list the currently available buildpacks,
     including any that were created or updated, examine the
     <code class="literal">buildpack</code> field after running:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks</pre></div></li><li class="listitem "><p>
     The Git URL of a buildpack. For example,
     <em class="replaceable ">https://github.com/SUSE/cf-ruby-buildpack</em>.
    </p></li><li class="listitem "><p>
     The Git URL of a buildpack with a specific branch or tag. For example,
     <em class="replaceable ">https://github.com/SUSE/cf-ruby-buildpack#1.7.40</em>.
    </p></li></ul></div><p>
   For more information about using buildpacks, see
   <a class="link" href="https://docs.cloudfoundry.org/buildpacks/#using-buildpacks" target="_blank">https://docs.cloudfoundry.org/buildpacks/#using-buildpacks</a>.
  </p></div><div class="sect1 " id="sec-cap-adding-buildpacks"><div class="titlepage"><div><div><h2 class="title"><span class="number">25.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Adding Buildpacks</span> <a title="Permalink" class="permalink" href="#sec-cap-adding-buildpacks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_buildpacks.xml</li><li><span class="ds-label">ID: </span>sec-cap-adding-buildpacks</li></ul></div></div></div></div><p>
   Additional buildpacks can be added to your SUSE Cloud Application Platform deployment to
   complement the ones already installed.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     List the currently installed buildpacks.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks
Getting buildpacks...

buildpack               position   enabled   locked   filename                                           stack
staticfile_buildpack    1          true      false    staticfile-buildpack-v1.4.43.1-1.1-53227ab3.zip
nginx_buildpack         2          true      false    nginx-buildpack-v1.0.15.1-1.1-868e3dbf.zip
java_buildpack          3          true      false    java-buildpack-v4.20.0.1-7b3efeee.zip
ruby_buildpack          4          true      false    ruby-buildpack-v1.7.42.1-1.1-897dec18.zip
nodejs_buildpack        5          true      false    nodejs-buildpack-v1.6.53.1-1.1-ca7738ac.zip
go_buildpack            6          true      false    go-buildpack-v1.8.42.1-1.1-c93d1f83.zip
python_buildpack        7          true      false    python-buildpack-v1.6.36.1-1.1-4c0057b7.zip
php_buildpack           8          true      false    php-buildpack-v4.3.80.1-6.1-613615bf.zip
binary_buildpack        9          true      false    binary-buildpack-v1.0.33.1-1.1-a53fa79d.zip
dotnet-core_buildpack   10         true      false    dotnet-core-buildpack-v2.2.13.1-1.1-cf41131a.zip</pre></div></li><li class="step "><p>
     Add a new buildpack using the <code class="command">cf create-buildpack</code>
     command.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-buildpack <em class="replaceable ">ANOTHER_RUBY_BUILDPACK</em> <em class="replaceable ">https://cf-buildpacks.suse.com/ruby-buildpack-v1.7.41.1-1.1-c4cd5fed.zip</em> <em class="replaceable ">10</em></pre></div><p>
     Where:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       <em class="replaceable ">ANOTHER_RUBY_BUILDPACK</em> is the name of the
       buildpack.
      </p></li><li class="listitem "><p>
       <em class="replaceable ">https://cf-buildpacks.suse.com/ruby-buildpack-v1.7.41.1-1.1-c4cd5fed.zip</em>
       is the path to the buildpack release. It should be a zip file, a URL to a
       zip file, or a local directory.
      </p></li><li class="listitem "><p>
       <em class="replaceable ">10</em> is the position of the buildpack and
       used to determine priority. A lower value indicates a higher priority.
      </p></li></ul></div><p>
     To see all available options, run:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-buildpack -h</pre></div></li><li class="step "><p>
     Verify the new buildpack has been added.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks
Getting buildpacks...

buildpack                position   enabled   locked   filename                                           stack
staticfile_buildpack     1          true      false    staticfile-buildpack-v1.4.43.1-1.1-53227ab3.zip
nginx_buildpack          2          true      false    nginx-buildpack-v1.0.15.1-1.1-868e3dbf.zip
java_buildpack           3          true      false    java-buildpack-v4.20.0.1-7b3efeee.zip
ruby_buildpack           4          true      false    ruby-buildpack-v1.7.42.1-1.1-897dec18.zip
nodejs_buildpack         5          true      false    nodejs-buildpack-v1.6.53.1-1.1-ca7738ac.zip
go_buildpack             6          true      false    go-buildpack-v1.8.42.1-1.1-c93d1f83.zip
python_buildpack         7          true      false    python-buildpack-v1.6.36.1-1.1-4c0057b7.zip
php_buildpack            8          true      false    php-buildpack-v4.3.80.1-6.1-613615bf.zip
binary_buildpack         9          true      false    binary-buildpack-v1.0.33.1-1.1-a53fa79d.zip
ANOTHER_RUBY_BUILDPACK   10         true      false    ruby-buildpack-v1.7.41.1-1.1-c4cd5fed.zip
dotnet-core_buildpack    11         true      false    dotnet-core-buildpack-v2.2.13.1-1.1-cf41131a.zip</pre></div></li></ol></div></div></div><div class="sect1 " id="sec-cap-updating-buildpacks"><div class="titlepage"><div><div><h2 class="title"><span class="number">25.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Updating Buildpacks</span> <a title="Permalink" class="permalink" href="#sec-cap-updating-buildpacks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_buildpacks.xml</li><li><span class="ds-label">ID: </span>sec-cap-updating-buildpacks</li></ul></div></div></div></div><p>
   Currently installed buildpacks can be updated using the
   <code class="command">cf update-buildpack</code> command. To see all values that can be
   updated, run <code class="command">cf update-buildpack -h</code>.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     List the currently installed buildpacks that can be updated.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks
Getting buildpacks...

buildpack                position   enabled   locked   filename                                           stack
staticfile_buildpack     1          true      false    staticfile-buildpack-v1.4.43.1-1.1-53227ab3.zip
nginx_buildpack          2          true      false    nginx-buildpack-v1.0.15.1-1.1-868e3dbf.zip
java_buildpack           3          true      false    java-buildpack-v4.20.0.1-7b3efeee.zip
ruby_buildpack           4          true      false    ruby-buildpack-v1.7.42.1-1.1-897dec18.zip
nodejs_buildpack         5          true      false    nodejs-buildpack-v1.6.53.1-1.1-ca7738ac.zip
go_buildpack             6          true      false    go-buildpack-v1.8.42.1-1.1-c93d1f83.zip
python_buildpack         7          true      false    python-buildpack-v1.6.36.1-1.1-4c0057b7.zip
php_buildpack            8          true      false    php-buildpack-v4.3.80.1-6.1-613615bf.zip
binary_buildpack         9          true      false    binary-buildpack-v1.0.33.1-1.1-a53fa79d.zip
ANOTHER_RUBY_BUILDPACK   10         true      false    ruby-buildpack-v1.7.41.1-1.1-c4cd5fed.zip
dotnet-core_buildpack    11         true      false    dotnet-core-buildpack-v2.2.13.1-1.1-cf41131a.zip</pre></div></li><li class="step "><p>
     Use the <code class="command">cf update-buildpack</code> command to update a
     buildpack.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf update-buildpack <em class="replaceable ">ANOTHER_RUBY_BUILDPACK</em> <em class="replaceable ">-i 11</em></pre></div><p>
     To see all available options, run:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf update-buildpack -h</pre></div></li><li class="step "><p>
     Verify the new buildpack has been updated.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks
Getting buildpacks...

buildpack                position   enabled   locked   filename                                           stack
staticfile_buildpack     1          true      false    staticfile-buildpack-v1.4.43.1-1.1-53227ab3.zip
nginx_buildpack          2          true      false    nginx-buildpack-v1.0.15.1-1.1-868e3dbf.zip
java_buildpack           3          true      false    java-buildpack-v4.20.0.1-7b3efeee.zip
ruby_buildpack           4          true      false    ruby-buildpack-v1.7.42.1-1.1-897dec18.zip
nodejs_buildpack         5          true      false    nodejs-buildpack-v1.6.53.1-1.1-ca7738ac.zip
go_buildpack             6          true      false    go-buildpack-v1.8.42.1-1.1-c93d1f83.zip
python_buildpack         7          true      false    python-buildpack-v1.6.36.1-1.1-4c0057b7.zip
php_buildpack            8          true      false    php-buildpack-v4.3.80.1-6.1-613615bf.zip
binary_buildpack         9          true      false    binary-buildpack-v1.0.33.1-1.1-a53fa79d.zip
dotnet-core_buildpack    10         true      false    dotnet-core-buildpack-v2.2.13.1-1.1-cf41131a.zip
ANOTHER_RUBY_BUILDPACK   11         true      false    ruby-buildpack-v1.7.41.1-1.1-c4cd5fed.zip</pre></div></li></ol></div></div></div><div class="sect1 " id="sec-cap-offline-buildpacks"><div class="titlepage"><div><div><h2 class="title"><span class="number">25.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Offline Buildpacks</span> <a title="Permalink" class="permalink" href="#sec-cap-offline-buildpacks">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_buildpacks.xml</li><li><span class="ds-label">ID: </span>sec-cap-offline-buildpacks</li></ul></div></div></div></div><p>
   An offline, or cached, buildpack packages the runtimes, frameworks, and
   dependencies needed to run your applications into an archive that is then
   uploaded to your Cloud Application Platform deployment. When an application is deployed using an
   offline buildpack, access to the Internet to download dependencies is no
   longer required. This has the benefit of providing improved staging
   performance and allows for staging to take place on air-gapped environments.
  </p><div class="sect2 " id="sec-cap-create-offline-buildpack"><div class="titlepage"><div><div><h3 class="title"><span class="number">25.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating an Offline Buildpack</span> <a title="Permalink" class="permalink" href="#sec-cap-create-offline-buildpack">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_admin_buildpacks.xml</li><li><span class="ds-label">ID: </span>sec-cap-create-offline-buildpack</li></ul></div></div></div></div><p>
    Offline buildpacks can be created using the
    <a class="link" href="https://github.com/SUSE/cf-buildpack-packager-docker" target="_blank">cf-buildpack-packager-docker</a>
    tool, which is available as a
    <a class="link" href="https://www.docker.com/" target="_blank">Docker</a> image. The only
    requirement to use this tool is a system with Docker support.
   </p><div id="id-1.3.5.15.7.3.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important: Disclaimer</h6><p>
     Some Cloud Foundry buildpacks can reference binaries with proprietary or
     mutually incompatible open source licenses which cannot be distributed
     together as offline/cached buildpack archives. Operators who wish to
     package and maintain offline buildpacks will be responsible for any
     required licensing or export compliance obligations.
    </p><p>
     For automation purposes, you can use the
     <code class="command">--accept-external-binaries</code> option to accept this
     disclaimer without the interactive prompt.
    </p></div><p>
    <a class="link" href="https://github.com/SUSE/cf-buildpack-packager-docker#usage" target="_blank">Usage</a>
    of the tool is as follows:
   </p><div class="verbatim-wrap"><pre class="screen">package [--accept-external-binaries] org [all [stack] | language [tag] [stack]]</pre></div><p>
    Where:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      <em class="replaceable ">org</em> is the Github organization hosting the
      buildpack repositories, such as
      <a class="link" href="https://github.com/cloudfoundry" target="_blank">"cloudfoundry"</a>
      or <a class="link" href="https://github.com/SUSE" target="_blank">"SUSE"</a>
     </p></li><li class="listitem "><p>
      A <em class="replaceable ">tag</em> cannot be specified when using
      <em class="replaceable ">all</em> as the language because the tag is
      different for each language
     </p></li><li class="listitem "><p>
      <em class="replaceable ">tag</em> is not optional if a
      <em class="replaceable ">stack</em> is specified. To specify the latest
      release, use <em class="replaceable ">""</em> as the
      <em class="replaceable ">tag</em>
     </p></li><li class="listitem "><p>
      A maximum of one stack can be specified
     </p></li></ul></div><p>
    The following example demonstrates packaging an offline Ruby buildpack and
    uploading it to your Cloud Application Platform deployment to use. The packaged buildpack will be
    a Zip file placed in the current working directory,
    <em class="replaceable ">$PWD</em>.
   </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
      Build the latest released SUSE Ruby buildpack for the SUSE Linux Enterprise 15 stack:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>docker run --interactive --tty --rm -v $PWD:/out splatform/cf-buildpack-packager <em class="replaceable ">SUSE</em> <em class="replaceable ">ruby</em> <em class="replaceable ">""</em> <em class="replaceable ">sle15</em></pre></div></li><li class="step "><p>
      Verify the archive has been created in your current working directory:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>ls
<em class="replaceable ">ruby_buildpack-cached-sle15-v1.7.30.1.zip</em></pre></div></li><li class="step "><p>
      Log into your Cloud Application Platform deployment. Select an organization and space to work
      with, creating them if needed:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf api --skip-ssl-validation <em class="replaceable ">https://api.example.com</em>
<code class="prompt user">tux &gt; </code>cf login -u <em class="replaceable ">admin</em> -p <em class="replaceable ">password</em>
<code class="prompt user">tux &gt; </code>cf create-org <em class="replaceable ">MY_ORG</em>
<code class="prompt user">tux &gt; </code>cf create-space <em class="replaceable ">MY_SPACE</em> -o <em class="replaceable ">MY_ORG</em>
<code class="prompt user">tux &gt; </code>cf target -o <em class="replaceable ">MY_ORG</em> -s <em class="replaceable ">MY_SPACE</em></pre></div></li><li class="step "><p>
      List the currently available buildpacks:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks
Getting buildpacks...

buildpack               position   enabled   locked   filename
staticfile_buildpack    1          true      false    staticfile_buildpack-v1.4.34.1-1.1-1dd6386a.zip
java_buildpack          2          true      false    java-buildpack-v4.16.1-e638145.zip
ruby_buildpack          3          true      false    ruby_buildpack-v1.7.26.1-1.1-c2218d66.zip
nodejs_buildpack        4          true      false    nodejs_buildpack-v1.6.34.1-3.1-c794e433.zip
go_buildpack            5          true      false    go_buildpack-v1.8.28.1-1.1-7508400b.zip
python_buildpack        6          true      false    python_buildpack-v1.6.23.1-1.1-99388428.zip
php_buildpack           7          true      false    php_buildpack-v4.3.63.1-1.1-2515c4f4.zip
binary_buildpack        8          true      false    binary_buildpack-v1.0.27.1-3.1-dc23dfe2.zip
dotnet-core_buildpack   9          true      false    dotnet-core-buildpack-v2.0.3.zip</pre></div></li><li class="step "><p>
      Upload your packaged offline buildpack to your Cloud Application Platform deployment:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-buildpack <em class="replaceable ">RUBY_BUILDPACK_CACHED</em> <em class="replaceable ">/tmp/ruby_buildpack-cached-sle15-v1.7.30.1.zip</em> <em class="replaceable ">1</em> <em class="replaceable ">--enable</em>
Creating buildpack <em class="replaceable ">RUBY_BUILDPACK_CACHED</em>...
OK

Uploading buildpack <em class="replaceable ">RUBY_BUILDPACK_CACHED</em>...
Done uploading
OK</pre></div></li><li class="step "><p>
      Verify your buildpack is available:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks
Getting buildpacks...

buildpack               position   enabled   locked   filename
<em class="replaceable ">RUBY_BUILDPACK_CACHED</em>   1          true      false    ruby_buildpack-cached-sle15-v1.7.30.1.zip
staticfile_buildpack    2          true      false    staticfile_buildpack-v1.4.34.1-1.1-1dd6386a.zip
java_buildpack          3          true      false    java-buildpack-v4.16.1-e638145.zip
ruby_buildpack          4          true      false    ruby_buildpack-v1.7.26.1-1.1-c2218d66.zip
nodejs_buildpack        5          true      false    nodejs_buildpack-v1.6.34.1-3.1-c794e433.zip
go_buildpack            6          true      false    go_buildpack-v1.8.28.1-1.1-7508400b.zip
python_buildpack        7          true      false    python_buildpack-v1.6.23.1-1.1-99388428.zip
php_buildpack           8          true      false    php_buildpack-v4.3.63.1-1.1-2515c4f4.zip
binary_buildpack        9          true      false    binary_buildpack-v1.0.27.1-3.1-dc23dfe2.zip
dotnet-core_buildpack   10         true      false    dotnet-core-buildpack-v2.0.3.zip</pre></div></li><li class="step "><p>
      Deploy a sample Rails app using the new buildpack:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>git clone <em class="replaceable ">https://github.com/scf-samples/12factor</em>
<code class="prompt user">tux &gt; </code>cd <em class="replaceable ">12factor</em>
<code class="prompt user">tux &gt; </code>cf push <em class="replaceable ">12factor</em> -b <em class="replaceable ">RUBY_BUILDPACK_CACHED</em></pre></div></li></ol></div></div><div id="id-1.3.5.15.7.3.10" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning: Deprecation of <code class="literal">cflinuxfs2</code> and <code class="literal">sle12</code> Stacks</h6><p>
   As of SUSE Cloud Foundry 2.18.0, since our <code class="literal">cf-deployment</code> version is 9.5
   , the <code class="literal">cflinuxfs2</code> stack is no longer supported, as was
   advised in SUSE Cloud Foundry 2.17.1 or Cloud Application Platform 1.4.1. The <code class="literal">cflinuxfs2</code>
   buildpack is no longer shipped, but if you are upgrading from an earlier
   version, <code class="literal">cflinuxfs2</code> will not be removed. However, for
   migration purposes, we encourage all admins to move to
   <code class="literal">cflinuxfs3</code> or <code class="literal">sle15</code> as newer buildpacks
   will not work with the deprecated <code class="literal">cflinuxfs2</code>. If you still
   want to use the older stack, you will need to build an older version of a
   buildpack to continue for the application to work, but you will be
   unsupported. (If you are running on <code class="literal">sle12</code>, we will be
   retiring that stack in a future version so start planning your migration to
   <code class="literal">sle15</code>. The procedure is described below.)
  </p><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>
     Migrate applications to the new stack using one of the methods listed. Note
     that both methods will cause application downtime. Downtime can be avoided
     by following a Blue-Green Deployment strategy. See
     <a class="link" href="https://docs.cloudfoundry.org/devguide/deploy-apps/blue-green.html" target="_blank">https://docs.cloudfoundry.org/devguide/deploy-apps/blue-green.html</a>
     for details.
    </p><p>
     Note that stack association support is available as of cf CLI v6.39.0.
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       Option 1 - Migrating applications using the Stack Auditor plugin.
      </p><p>
       Stack Auditor rebuilds the application onto the new stack without a
       change in the application source code. If you want to move to a new stack
       with updated code, please follow Option 2 below. For additional
       information about the Stack Auditor plugin, see
       <a class="link" href="https://docs.cloudfoundry.org/adminguide/stack-auditor.html" target="_blank">https://docs.cloudfoundry.org/adminguide/stack-auditor.html</a>.
      </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
         Install the Stack Auditor plugin for the cf CLI. For instructions, see
         <a class="link" href="https://docs.cloudfoundry.org/adminguide/stack-auditor.html#install" target="_blank">https://docs.cloudfoundry.org/adminguide/stack-auditor.html#install</a>.
        </p></li><li class="step "><p>
         Identify the stack applications are using. The audit lists all
         applications in orgs you have access to. To list all applications in
         your Cloud Application Platform deployment, ensure you are logged in as a user with access
         to all orgs.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf audit-stack</pre></div><p>
         For each application requiring migration, perform the steps below.
        </p></li><li class="step "><p>
         If necessary, switch to the org and space the application is deployed
         to.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf target ORG SPACE</pre></div></li><li class="step "><p>
         Change the stack to <code class="literal">sle15</code>.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf change-stack APP_NAME sle15</pre></div></li><li class="step "><p>
         Identify all buildpacks associated with the <code class="literal">sle12</code>
         and <code class="literal">cflinuxfs2</code> stacks.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks</pre></div></li><li class="step "><p>
         Remove all buildpacks associated with the <code class="literal">sle12</code>
         and <code class="literal">cflinuxfs2</code> stacks.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf delete-buildpack BUILDPACK -s sle12

<code class="prompt user">tux &gt; </code>cf delete-buildpack BUILDPACK -s cflinuxfs2</pre></div></li><li class="step "><p>
         Remove the <code class="literal">sle12</code> and <code class="literal">cflinuxfs2</code>
         stacks.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf delete-stack sle12

<code class="prompt user">tux &gt; </code>cf delete-stack cflinuxfs2</pre></div></li></ol></div></div></li><li class="listitem "><p>
       Option 2 - Migrating applications using the cf CLI.
      </p><p>
       Perform the following for all orgs and spaces in your Cloud Application Platform deployment.
       Ensure you are logged in as a user with access to all orgs.
      </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
         Target an org and space.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf target ORG SPACE</pre></div></li><li class="step "><p>
         Identify the stack an applications in the org and space is using.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf app APP_NAME</pre></div></li><li class="step "><p>
         Re-push the app with the <code class="literal">sle15</code> stack using one of
         the following methods.
        </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
           Push the application with the stack option, <code class="command">-s</code>
           passed.
          </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf push APP_NAME -s sle15</pre></div></li><li class="listitem "><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
             Update the application manifest file to include
             <code class="literal">stack: sle15</code>. See
             <a class="link" href="https://docs.cloudfoundry.org/devguide/deploy-apps/manifest-attributes.html#stack" target="_blank">https://docs.cloudfoundry.org/devguide/deploy-apps/manifest-attributes.html#stack</a>
             for details.
            </p><div class="verbatim-wrap"><pre class="screen">---
  ...
  stack: sle15</pre></div></li><li class="step "><p>
              Push the application.
            </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf push APP_NAME</pre></div></li></ol></div></div></li></ul></div></li><li class="step "><p>
         Identify all buildpacks associated with the <code class="literal">sle12</code>
         and <code class="literal">cflinuxfs2</code> stacks.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf buildpacks</pre></div></li><li class="step "><p>
         Remove all buildpacks associated with the <code class="literal">sle12</code>
         and <code class="literal">cflinuxfs2</code> stacks.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf delete-buildpack BUILDPACK -s sle12

<code class="prompt user">tux &gt; </code>cf delete-buildpack BUILDPACK -s cflinuxfs2</pre></div></li><li class="step "><p>
         Remove the <code class="literal">sle12</code> and <code class="literal">cflinuxfs2</code>
         stacks using the CF API. See
         <a class="link" href="https://apidocs.cloudfoundry.org/7.11.0/#stacks" target="_blank">https://apidocs.cloudfoundry.org/7.11.0/#stacks</a>
         for details.
        </p><p>
         List all stacks then find the GUID of the <code class="literal">sle12</code>
         <code class="literal">cflinuxfs2</code> stacks.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf curl /v2/stacks</pre></div><p>
         Delete the <code class="literal">sle12</code> and <code class="literal">cflinuxfs2</code>
         stacks.
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf curl -X DELETE /v2/stacks/SLE12_STACK_GUID

<code class="prompt user">tux &gt; </code>cf curl -X DELETE /v2/stacks/CFLINUXFS2_STACK_GUID</pre></div></li></ol></div></div></li></ul></div></li></ul></div></div></div></div></div></div></div><div class="part" id="part-cap-user-guide"><div class="titlepage"><div><div><h1 class="title"><span class="number">Part IV </span><span class="name">SUSE Cloud Application Platform User Guide </span><a title="Permalink" class="permalink" href="#part-cap-user-guide">#</a></h1></div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="#cha-cap-cf-cli"><span class="number">26 </span><span class="name">Deploying and Managing Applications with the Cloud Foundry Client</span></a></span></dt><dd class="toc-abstract"><p>
   The Cloud Foundry command line interface (cf CLI) is for deploying and managing your
   applications. You may use it for all the orgs and spaces that you are a
   member of. Install the client on a workstation for remote administration of
   your SUSE Cloud Foundry instances.
  </p></dd></dl></div><div class="chapter " id="cha-cap-cf-cli"><div class="titlepage"><div><div><h2 class="title"><span class="number">26 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying and Managing Applications with the Cloud Foundry Client</span> <a title="Permalink" class="permalink" href="#cha-cap-cf-cli">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_user_cf_cli.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-cf-cli"><span class="number">26.1 </span><span class="name">Using the cf CLI with SUSE Cloud Application Platform</span></a></span></dt></dl></div></div><div class="sect1 " id="sec-cap-cf-cli"><div class="titlepage"><div><div><h2 class="title"><span class="number">26.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the cf CLI with SUSE Cloud Application Platform</span> <a title="Permalink" class="permalink" href="#sec-cap-cf-cli">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_user_cf_cli.xml</li><li><span class="ds-label">ID: </span>sec-cap-cf-cli</li></ul></div></div></div></div><p>
   The Cloud Foundry command line interface (cf CLI) is for deploying and managing your
   applications. You may use it for all the orgs and spaces that you are a
   member of. Install the client on a workstation for remote administration of
   your SUSE Cloud Foundry instances.
  </p><p>
   The complete guide is at
   <a class="link" href="https://docs.cloudfoundry.org/cf-cli/" target="_blank">Using the Cloud
   Foundry Command Line Interface</a>, and source code with a demo video is
   on GitHub at
   <a class="link" href="https://github.com/cloudfoundry/cli/blob/master/README.md" target="_blank">Cloud
   Foundry CLI</a>.
  </p><p>
   The following examples demonstrate some of the commonly-used commands. The
   first task is to log into your new Cloud Application Platform instance.
   You need to provide the API endpoint of your SUSE Cloud Application Platform instance to log
   in. The API endpoint is the <code class="envar">system_domain</code> value you provided in
   <code class="filename">kubecf-config-values.yaml</code>, plus the
   <code class="literal">api.</code> prefix, as it shows in the above welcome screen. Set
   your endpoint, and use <code class="command">--skip-ssl-validation</code> when you
   have self-signed SSL certificates. It asks for an e-mail address, but you
   must enter <code class="literal">admin</code> instead (you cannot change this to a
   different username, though you may create additional users), and the
   password is the one you created in
   <code class="filename">kubecf-config-values.yaml</code>:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login --skip-ssl-validation -a https://api.example.com
API endpoint: https://api.example.com

Email&gt; admin

Password&gt;
Authenticating...
OK

Targeted org system

API endpoint:   https://api.example.com (API version: 2.134.0)
User:           admin
Org:            system
Space:          No space targeted, use 'cf target -s SPACE'</pre></div><p>
   <code class="command">cf help</code> displays a list of commands and options.
   <code class="command">cf help [command]</code> provides information on specific
   commands.
  </p><p>
   You may pass in your credentials and set the API endpoint in a single
   command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf login -u admin -p <em class="replaceable ">PASSWORD</em> --skip-ssl-validation -a https://api.example.com</pre></div><p>
   Log out with <code class="command">cf logout</code>.
  </p><p>
   Change the admin password:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf passwd
Current Password&gt;
New Password&gt;
Verify Password&gt;
Changing password...
OK
Please log in again</pre></div><p>
   View your current API endpoint, user, org, and space:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf target</pre></div><p>
   Switch to a different org or space:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf target -o <em class="replaceable ">MY_ORG</em>
<code class="prompt user">tux &gt; </code>cf target -s <em class="replaceable ">MY_SPACE</em></pre></div><p>
   List all apps in the current space:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf apps</pre></div><p>
   Query the health and status of a particular app:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf app <em class="replaceable ">MY_APP</em></pre></div><p>
   View app logs. The first example tails the log of a running app. The
   <code class="command">--recent</code> option dumps recent logs instead of tailing,
   which is useful for stopped and crashed apps:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf logs <em class="replaceable ">MY_APP</em>
<code class="prompt user">tux &gt; </code>cf logs --recent <em class="replaceable ">MY_APP</em></pre></div><p>
   Restart all instances of an app:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf restart <em class="replaceable ">MY_APP</em></pre></div><p>
   Restart a single instance of an app, identified by its index number, and
   restart it with the same index number:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf restart-app-instance <em class="replaceable ">MY_APP</em> <em class="replaceable ">APP_INSTANCE</em></pre></div><p>
   After you have set up a service broker (see
   <a class="xref" href="#cha-cap-service-brokers" title="Chapter 22. Service Brokers">Chapter 22, <em>Service Brokers</em></a>), create new services:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf create-service <em class="replaceable ">SERVICE_NAME</em> <em class="replaceable ">default</em> <em class="replaceable ">MY_DB</em></pre></div><p>
   Then you may bind a service instance to an app:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf bind-service <em class="replaceable ">MY_APP</em> <em class="replaceable ">SERVICE_INSTANCE</em></pre></div><p>
   The most-used command is <code class="command">cf push</code>, for pushing new apps
   and changes to existing apps.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf push <em class="replaceable ">NEW_APP</em> -b <em class="replaceable ">buildpack</em></pre></div><p>
   If you need to debug your application or run one-off tasks, start an SSH
   session into your application container.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cf ssh <em class="replaceable ">MY_APP</em></pre></div><p>
   When the SSH connection is established, run the following to have the
   environment match that of the application and its associated buildpack.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>/tmp/lifecycle/shell</pre></div></div></div></div><div class="part" id="part-cap-troubleshooting"><div class="titlepage"><div><div><h1 class="title"><span class="number">Part V </span><span class="name">Troubleshooting </span><a title="Permalink" class="permalink" href="#part-cap-troubleshooting">#</a></h1></div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="#cha-cap-depl-troubleshooting"><span class="number">27 </span><span class="name">Troubleshooting</span></a></span></dt><dd class="toc-abstract"><p>Cloud stacks are complex, and debugging deployment issues often requires digging through multiple layers to find the information you need. Remember that the KubeCF releases must be deployed in the correct order, and that each release must deploy successfully, with no failed pods, before deploying th…</p></dd></dl></div><div class="chapter " id="cha-cap-depl-troubleshooting"><div class="titlepage"><div><div><h2 class="title"><span class="number">27 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshooting</span> <a title="Permalink" class="permalink" href="#cha-cap-depl-troubleshooting">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#sec-cap-tbl-logging"><span class="number">27.1 </span><span class="name">Logging</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-supportconfig"><span class="number">27.2 </span><span class="name">Using Supportconfig</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-toolong"><span class="number">27.3 </span><span class="name">Deployment Is Taking Too Long</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-rebuild-depl"><span class="number">27.4 </span><span class="name">Deleting and Rebuilding a Deployment</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-kubectl-queries"><span class="number">27.5 </span><span class="name">Querying with Kubectl</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-admission-webhook"><span class="number">27.6 </span><span class="name">Admission webhook denied</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-helm-namespace"><span class="number">27.7 </span><span class="name">Namespace does not exist</span></a></span></dt><dt><span class="sect1"><a href="#sec-cap-tbl-log-cache-memory"><span class="number">27.8 </span><span class="name">Log-cache Memory Allocation Issue</span></a></span></dt></dl></div></div><p>
  Cloud stacks are complex, and debugging deployment issues often requires
  digging through multiple layers to find the information you need. Remember
  that the KubeCF releases must be deployed in the correct order, and that each
  release must deploy successfully, with no failed pods, before deploying the
  next release.
 </p><p>
  Before proceeding with in depth troubleshooting, ensure the following have
  been met as defined in the Support Statement at <a class="xref" href="#sec-cap-platform-support" title="5.2. Platform Support">Section 5.2, “Platform Support”</a>.
 </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     The Kubernetes cluster satisfies the Requirements listed here at
     <a class="link" href="https://documentation.suse.com/suse-cap/2.1.0/html/cap-guides/cha-cap-depl-kube-requirements.html#sec-cap-changes-kube-reqs" target="_blank">https://documentation.suse.com/suse-cap/2.1.0/html/cap-guides/cha-cap-depl-kube-requirements.html#sec-cap-changes-kube-reqs</a>.
    </p></li><li class="listitem "><p>
     The <code class="filename">kube-ready-state-check.sh</code> script has been run on
     the target Kubernetes cluster and does not show any configuration problems.
    </p></li><li class="listitem "><p>
     A SUSE Services or Sales Engineer has verified that SUSE Cloud Application Platform works
     correctly on the target Kubernetes cluster.
    </p></li></ol></div><div class="sect1 " id="sec-cap-tbl-logging"><div class="titlepage"><div><div><h2 class="title"><span class="number">27.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Logging</span> <a title="Permalink" class="permalink" href="#sec-cap-tbl-logging">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_troubleshooting.xml</li><li><span class="ds-label">ID: </span>sec-cap-tbl-logging</li></ul></div></div></div></div><p>
   There are two types of logs in a deployment of SUSE Cloud Application Platform, applications
   logs and component logs. The following provides a brief overview of each log
   type and how to retrieve them for monitoring and debugging use.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Application logs provide information specific to a given application that
    has been deployed to your Cloud Application Platform cluster and can be accessed through:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      The cf CLI using the <code class="command">cf logs</code> command
     </p></li><li class="listitem "><p>
      The application's log stream within the Stratos console
     </p></li></ul></div></li><li class="listitem "><p>
    Access to logs for a given component of your Cloud Application Platform deployment can be
    obtained by:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      The <code class="command">kubectl logs</code> command
     </p><p>
      The following example retrieves the logs of the <code class="literal">router</code>
      container of <code class="literal">router-0</code> pod in the <code class="literal">kubecf</code>
      namespace
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl logs --namespace kubecf <em class="replaceable ">router-0</em> <em class="replaceable ">router</em></pre></div></li><li class="listitem "><p>
      Direct access to the log files using the following:
     </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
        Open a shell to the container of the component using the
        <code class="command">kubectl exec</code> command
       </p></li><li class="listitem "><p>
        Navigate to the logs directory at
        <code class="filename">/var/vcap/sys/logs</code>, at which point there will be
        subdirectories containing the log files for access.
       </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl exec --stdin --tty --namespace kubecf router-0 /bin/bash

router/0:/# cd /var/vcap/sys/log

router/0:/var/vcap/sys/log# ls -R
.:
gorouter  loggregator_agent

./gorouter:
access.log  gorouter.err.log  gorouter.log  post-start.err.log  post-start.log

./loggregator_agent:
agent.log</pre></div></li></ol></div></li></ul></div></li></ul></div></div><div class="sect1 " id="sec-cap-tbl-supportconfig"><div class="titlepage"><div><div><h2 class="title"><span class="number">27.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Supportconfig</span> <a title="Permalink" class="permalink" href="#sec-cap-tbl-supportconfig">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_troubleshooting.xml</li><li><span class="ds-label">ID: </span>sec-cap-tbl-supportconfig</li></ul></div></div></div></div><p>
   If you ever need to request support, or just want to generate detailed
   system information and logs, use the <code class="command">supportconfig</code>
   utility. Run it with no options to collect basic system information, and
   also cluster logs including Docker, etcd, flannel, and Velum.
   <code class="command">supportconfig</code> may give you all the information you need.
  </p><p>
   <code class="command">supportconfig -h</code> prints the options. Read the "Gathering
   System Information for Support" chapter in any SUSE Linux Enterprise <em class="citetitle ">Administration Guide</em> to
   learn more.
  </p></div><div class="sect1 " id="sec-cap-tbl-toolong"><div class="titlepage"><div><div><h2 class="title"><span class="number">27.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment Is Taking Too Long</span> <a title="Permalink" class="permalink" href="#sec-cap-tbl-toolong">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_troubleshooting.xml</li><li><span class="ds-label">ID: </span>sec-cap-tbl-toolong</li></ul></div></div></div></div><p>
   A deployment step seems to take too long, or you see that some pods are not
   in a ready state hours after all the others are ready, or a pod shows a lot
   of restarts. This example shows not-ready pods many hours after the others
   have become ready:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get pods --namespace kubecf
NAME                     READY STATUS    RESTARTS  AGE
router-3137013061-wlhxb  0/1   Running   0         16h
routing-api-0            0/1   Running   0         16h</pre></div><p>
   The <code class="literal">Running</code> status means the pod is bound to a node and
   all of its containers have been created. However, it is not
   <code class="literal">Ready</code>, which means it is not ready to service requests.
   Use <code class="command">kubectl</code> to print a detailed description of pod events
   and status:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl describe pod --namespace kubecf router-0</pre></div><p>
   This prints a lot of information, including IP addresses, routine events,
   warnings, and errors. You should find the reason for the failure in this
   output.
  </p><div id="id-1.3.7.3.7.7" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
  During deployment, pods are spawned over time, starting with a single
  pod whose name stars with <code class="literal">ig-</code>. This pod will eventually
  disappear and will be replaced by other pods whose progress
  then can be followed as usual.
 </p><p>
  The whole process can take around 20—30 minutes to finish.
 </p><p>
  The initial stage may look like this:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get pods --namespace kubecf
ig-kubecf-f9085246244fbe70-jvg4z   1/21    Running             0          8m28s</pre></div><p>
  Later the progress may look like this:
 </p><div class="verbatim-wrap"><pre class="screen">NAME                        READY   STATUS       RESTARTS   AGE
adapter-0                   4/4     Running      0          6m45s
api-0                       0/15    Init:30/63   0          6m38s
bits-0                      0/6     Init:8/15    0          6m34s
bosh-dns-7787b4bb88-2wg9s   1/1     Running      0          7m7s
bosh-dns-7787b4bb88-t42mh   1/1     Running      0          7m7s
cc-worker-0                 0/4     Init:5/9     0          6m36s
credhub-0                   0/5     Init:6/11    0          6m33s
database-0                  2/2     Running      0          6m36s
diego-api-0                 6/6     Running      2          6m38s
doppler-0                   0/9     Init:7/16    0          6m40s
eirini-0                    9/9     Running      0          6m37s
log-api-0                   0/7     Init:6/13    0          6m35s
nats-0                      4/4     Running      0          6m39s
router-0                    0/5     Init:5/11    0          6m33s
routing-api-0               0/4     Init:5/10    0          6m42s
scheduler-0                 0/8     Init:8/17    0          6m35s
singleton-blobstore-0       0/6     Init:6/11    0          6m46s
tcp-router-0                0/5     Init:5/11    0          6m37s
uaa-0                       0/6     Init:8/13    0          6m36s</pre></div></div></div><div class="sect1 " id="sec-cap-tbl-rebuild-depl"><div class="titlepage"><div><div><h2 class="title"><span class="number">27.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deleting and Rebuilding a Deployment</span> <a title="Permalink" class="permalink" href="#sec-cap-tbl-rebuild-depl">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_troubleshooting.xml</li><li><span class="ds-label">ID: </span>sec-cap-tbl-rebuild-depl</li></ul></div></div></div></div><p>
   There may be times when you want to delete and rebuild a deployment, for
   example when there are errors in your <code class="filename">kubecf-config-values.yaml</code> file, you wish to
   test configuration changes, or a deployment fails and you want to try it again.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Remove the <code class="literal">kubecf</code> release. All resources associated with
     the release of the <code class="literal">suse/kubecf</code> chart will be removed.
     Replace the example release name with the one used during your installation. 
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm uninstall <em class="replaceable ">kubecf</em></pre></div></li><li class="step "><p>
     Remove the <code class="literal">kubecf</code> namespace. Replace with the namespace
     where the <code class="literal">suse/kubecf</code> chart was installed.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl delete namespace <em class="replaceable ">kubecf</em></pre></div></li><li class="step "><p>
     Remove the <code class="literal">cf-operator</code> release. All resources associated
     with the release of the <code class="literal">suse/cf-operator</code> chart will be
     removed. Replace the example release name with the one used during your
     installation.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm uninstall <em class="replaceable ">cf-operator</em></pre></div></li><li class="step "><p>
     Remove the <code class="literal">cf-operator</code> namespace. Replace with the namespace
     where the <code class="literal">suse/cf-operator</code> chart was installed.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl delete namespace <em class="replaceable ">cf-operator</em></pre></div></li><li class="step "><p>
     Verify all of the releases are removed.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm list --all-namespaces</pre></div></li><li class="step "><p>
     Verify all of the namespaces are removed.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get namespaces</pre></div></li></ol></div></div></div><div class="sect1 " id="sec-cap-tbl-kubectl-queries"><div class="titlepage"><div><div><h2 class="title"><span class="number">27.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Querying with Kubectl</span> <a title="Permalink" class="permalink" href="#sec-cap-tbl-kubectl-queries">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_troubleshooting.xml</li><li><span class="ds-label">ID: </span>sec-cap-tbl-kubectl-queries</li></ul></div></div></div></div><p>
   You can safely query with <code class="command">kubectl</code> to get information
   about resources inside your Kubernetes cluster. <code class="command">kubectl cluster-info
   dump | tee clusterinfo.txt</code> outputs a large amount of information
   about the Kubernetes master and cluster services to a text file.
  </p><p>
   The following commands give more targeted information about your cluster.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     List all cluster resources:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get all --all-namespaces</pre></div></li><li class="listitem "><p>
     List all of your running pods:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get pods --all-namespaces</pre></div></li><li class="listitem "><p>
     List all of your running pods, their internal IP addresses, and which
     Kubernetes nodes they are running on:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get pods --all-namespaces --output wide</pre></div></li><li class="listitem "><p>
     See all pods, including those with Completed or Failed statuses:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get pods --show-all --all-namespaces</pre></div></li><li class="listitem "><p>
     List pods in one namespace:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get pods --namespace kubecf</pre></div></li><li class="listitem "><p>
     Get detailed information about one pod:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl describe --namespace kubecf po/diego-cell-0</pre></div></li><li class="listitem "><p>
     Read the log file of a pod:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl logs --namespace kubecf po/diego-cell-0</pre></div></li><li class="listitem "><p>
     List all Kubernetes nodes, then print detailed information about a single
     node:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get nodes
<code class="prompt user">tux &gt; </code>kubectl describe node 6a2752b6fab54bb889029f60de6fa4d5.infra.caasp.local</pre></div></li><li class="listitem "><p>
     List all containers in all namespaces, formatted for readability:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get pods --all-namespaces --output jsonpath="{..image}" |\
tr -s '[[:space:]]' '\n' |\
sort |\
uniq -c</pre></div></li><li class="listitem "><p>
     These two commands check node capacities, to verify that there are enough
     resources for the pods:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl get nodes --output yaml | grep '\sname\|cpu\|memory'
<code class="prompt user">tux &gt; </code>kubectl get nodes --output json | \
jq '.items[] | {name: .metadata.name, cap: .status.capacity}'</pre></div></li></ul></div></div><div class="sect1 " id="sec-cap-tbl-admission-webhook"><div class="titlepage"><div><div><h2 class="title"><span class="number">27.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Admission webhook denied</span> <a title="Permalink" class="permalink" href="#sec-cap-tbl-admission-webhook">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_troubleshooting.xml</li><li><span class="ds-label">ID: </span>sec-cap-tbl-admission-webhook</li></ul></div></div></div></div><p>
    When switching back to Diego from Eirini, the error below can occur:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>helm install <em class="replaceable ">kubecf</em> suse/kubecf --namespace <em class="replaceable ">kubecf</em> --values kubecf-config-values.yaml
Error: admission webhook "validate-boshdeployment.quarks.cloudfoundry.org" denied the request: Failed to resolve manifest: Failed to interpolate ops 'kubecf-user-provided-properties' for manifest 'kubecf': Applying ops on manifest obj failed in interpolator: Expected to find exactly one matching array item for path '/instance_groups/name=eirini' but found 0</pre></div><p>
    To avoid this error, remove the <code class="literal">eirini-persi-broker</code> configuration
    before running the command.
  </p></div><div class="sect1 " id="sec-cap-tbl-helm-namespace"><div class="titlepage"><div><div><h2 class="title"><span class="number">27.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Namespace does not exist</span> <a title="Permalink" class="permalink" href="#sec-cap-tbl-helm-namespace">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_troubleshooting.xml</li><li><span class="ds-label">ID: </span>sec-cap-tbl-helm-namespace</li></ul></div></div></div></div><p>
    When running a Helm command, an error occurs stating that a namespace does not
    exist. To avoid this error, create the namespace manually with <code class="command">kubectl</code>; before
    running the command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>kubectl create namespace <em class="replaceable ">name</em></pre></div></div><div class="sect1 " id="sec-cap-tbl-log-cache-memory"><div class="titlepage"><div><div><h2 class="title"><span class="number">27.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Log-cache Memory Allocation Issue</span> <a title="Permalink" class="permalink" href="#sec-cap-tbl-log-cache-memory">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cap_troubleshooting.xml</li><li><span class="ds-label">ID: </span>sec-cap-tbl-log-cache-memory</li></ul></div></div></div></div><p>
   The log-cache component currently has a memory allocation issue where the node
   memory available is reported instead of the one assigned to the container under
   cgroups. In such a situation, log-cache would start allocating memory based on
   these values, causing a varying range of issues (OOMKills, performance
   degradation, etc.). To address this issue, node affinity must be used to tie
   log-cache to nodes of a uniform size, and then declaring the cache percentage
   based on that number. A limit of 3% has been identified as sufficient.
  </p><p>
   Add the following to your <code class="filename">kubecf-config-values.yaml</code>. In the node affinity
   configuration, the values for <code class="literal">key</code> and
   <code class="literal">values</code> may need to be changed depending on how notes in
   your cluster are labeled. For more information on labels, see
   <a class="link" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels" target="_blank">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels</a>.
  </p><div class="verbatim-wrap"><pre class="screen">properties:
  log-cache:
    log-cache:
      memory_limit_percent: 3

operations:
  inline:
  - type: replace
    path: /instance_groups/name=log-cache/env?/bosh/agent/settings/affinity
    value:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: <em class="replaceable ">kubernetes.io/hostname</em>
              operator: In
              values:
              - <em class="replaceable ">LABEL_VALUE_OF_NODE</em></pre></div></div></div></div><div class="appendix " id="id-1.3.8"><div class="titlepage"><div><div><h1 class="title"><span class="number">A </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Appendix</span> <a title="Permalink" class="permalink" href="#id-1.3.8">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>appendix.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#app-kubecf-values-yaml"><span class="number">A.1 </span><span class="name">Complete suse/kubecf values.yaml File</span></a></span></dt><dt><span class="sect1"><a href="#app-cf-operator-values-yaml"><span class="number">A.2 </span><span class="name">Complete suse/cf-operator values.yaml File</span></a></span></dt></dl></div></div><div class="sect1 " id="app-kubecf-values-yaml"><div class="titlepage"><div><div><h2 class="title"><span class="number">A.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Complete suse/kubecf values.yaml File</span> <a title="Permalink" class="permalink" href="#app-kubecf-values-yaml">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>app_kubecf_values_yaml.xml</li><li><span class="ds-label">ID: </span>app-kubecf-values-yaml</li></ul></div></div></div></div><p>
  This is the complete output of <code class="command">helm inspect values suse/kubecf</code> for
  the current SUSE Cloud Application Platform 2.1.0 release.
 </p><div class="verbatim-wrap"><pre class="screen"># REQUIRED: the domain that the deployment will be visible to the user.
# system_domain: example.com

# List of stacks to install; the first one will be used as the default.
# A stack is a prebuilt root file system that supports a specific
# operating system with a corresponding set of buildpacks.
install_stacks: [sle15, cflinuxfs3]

# Set or override job properties. The first level of the map is the instance group name. The second
# level of the map is the job name. E.g.:
#  properties:
#    adapter:
#      adapter:
#        scalablesyslog:
#          adapter:
#            logs:
#              addr: kubecf-log-api:8082
#
properties: {}

# Override credentials to not be auto-generated.  The credentials can either be
# specified as a nested mapping, or with a dot-separated key.  For example:
#  credentials:
#    cf_admin_password: changeme
#    credhub_tls.ca: credhub-real-ca
#    credhub_tls:
#      certificate: the-cert
credentials: {}

# Override variable values to not be auto-generated.  The variables are a simple
# mapping with keys/values.  Note that the `system_domain` domain is handled
# differently and must be set via the top-level key (which is required).
# For example:
#  variables:
#    key: value
variables: {}

kube:
  # The storage class to be used for the instance groups that need it (e.g. bits, database and
  # singleton-blobstore). If it's not set, the default storage class will be used.
  storage_class: ~
  # The psp key contains the configuration related to Pod Security Policies. By default, a PSP will
  # be generated with the necessary permissions for running KubeCF. To pass an existing PSP and
  # prevent KubeCF from creating a new one, set the kube.psp.default with the PSP name.
  psp:
    default: ~

# Set to true to enable support for multiple availability zones.
multi_az: false

# Set to true to enable high availability mode, where pods are replicated in
# order to prevent downtime when a node is temporarily unavailable.
high_availability: false

# Instance sizing takes precedence over the high_availability property. I.e. setting the
# instance count for an instance group greater than 1 will make it highly available.
#
# It is also possible to specify custom affinity rules for each instance group. If no rule
# is provided, then each group as anti-affinity to itself, to try to spread the pods between
# different nodes. In addition diego-cell and router also have anti-affinity to each other.
#
# The default rules look like this:
#
# sizing:
#   sample_group:
#     affinity:
#       podAntiAffinity:
#         preferredDuringSchedulingIgnoredDuringExecution:
#         - weight: 100
#           podAffinityTerm:
#             labelSelector:
#               matchExpressions:
#               - key: quarks.cloudfoundry.org/quarks-statefulset-name
#                 operator: In
#                 values:
#                 - sample_group
#             topologyKey: kubernetes.io/hostname
#
# Any affinity rules specified here will *overwrite* the default rule and not merge with it.

sizing:
  adapter:
    instances: ~
  api:
    instances: ~
  apps_dns:
    instances: ~
  asactors:
    instances: ~
  asapi:
    instances: ~
  asmetrics:
    instances: ~
  asnozzle:
    instances: ~
  auctioneer:
    instances: ~
  bits:
    instances: ~
  cc_worker:
    instances: ~
  credhub:
    instances: ~
  database:
    persistence:
      size: 20Gi
  diego_api:
    instances: ~
  diego_cell:
    ephemeral_disk:
      # Size of the ephemeral disk used to store applications in MB
      size: 40960
      # IMPORTANT! Only set this if you understand the consequences of using a PVC as ephemeral
      # storage for diego cells. The storage class should be high performance, and not based on NFS.
      # Do not set this value in production environments unless you've tested your storage class with
      # diego cells and have found no problems.
      # The name of the storage class used for the ephemeral disk PVC.
      storage_class: ~
    instances: ~
  doppler:
    instances: ~
  eirini:
    instances: ~
  log_api:
    instances: ~
  nats:
    instances: ~
  router:
    instances: ~
  routing_api:
    instances: ~
  scheduler:
    instances: ~
  uaa:
    instances: ~
  tcp_router:
    instances: ~

#  External endpoints are created for the instance groups only if features.ingress.enabled is false.
services:
  router:
    annotations: {}
    type: LoadBalancer
    externalIPs: []
    clusterIP: ~
    loadBalancerIP: ~
  ssh-proxy:
    annotations: {}
    type: LoadBalancer
    externalIPs: []
    clusterIP: ~
    loadBalancerIP: ~
  tcp-router:
    annotations: {}
    type: LoadBalancer
    externalIPs: []
    clusterIP: ~
    loadBalancerIP: ~
    port_range:
      start: 20000
      end: 20008

# CPU and memory resources can be configured via the `resources` tree when features.cpu_limits.enabled
# or features.memory_limits.enabled are set respectively. Each setting covers both limit and request
# settings for their resource type.
#
# The helm chart includes default memory limits for all processes, and some explicit requests. When no
# request size is specified, a default is calculated as a percentage of the limit, but at least some
# minimum threshold, but never more than the limit itself. See the features.memory_limits setting to
# finetune this algorithm.
#
# All values are integers; cpu values are in millicpus (m) and memory is in megabytes (Mi).
#
# More information about the `resources` structure can be found in the config/resources.yaml file
# inside this helm chart.

resources:
  diego-cell:
    garden:
      garden: {memory: {limit: 524288, request: 16}}

settings:
  router:
    # tls sets up the public TLS for the router. The tls keys:
    #   crt: the certificate in the PEM format. Required.
    #   key: the private key in the PEM format. Required.
    tls: {}
    # crt: |
    #   -----BEGIN CERTIFICATE-----
    #   ...
    #   -----END CERTIFICATE-----
    # key: |
    #   -----BEGIN PRIVATE KEY-----
    #   ...
    #   -----END PRIVATE KEY-----


features:
  # Set default memory limits and requests for all containers
  memory_limits:
    enabled: true
    # The memory request size default is calculated as a percentage of the limit.
    # The default is always at least a minimum value, but never larger than the limit itself.
    default_request_minimum: 32
    default_request_in_percent: 25
  eirini:
    enabled: false
  # To support multi-clusters, deploy diego-cell separately please set control_plane is false  and cell_segment is true
  multiple_cluster_mode:
    control_plane:
      enabled: false
    cell_segment:
      enabled: false
    # To support multi-clusters, services for diego-cell deployed separately
    control_plane_workers:
      uaa:
        name: uaa
        addresses:
        - ip: ~
      diego_api:
        name: diego-api
        addresses:
        - ip: ~
      api:
        name: api
        addresses:
        - ip: ~
      singleton_blobstore:
        name: singleton-blobstore
        addresses:
        - ip: ~
    # To support multi-clusters, provider link secrets for diego-cell deployed separately
    provider_link_service:
      nats:
        secret_name: minion-link-nats
        service_name: minion-service-nats
        addresses:
        - ip: ~
        # To support multi-clusters, fill the provider link secrets context of nats, for example:
        # link: |
        #   ---
        #   nats.user: "nats"
        #   nats.password: "xxxxxx"
        #   nats.hostname: "nats"
        #   nats.port: 4222
        link: ~
      nats_tls:
        secret_name: minion-link-nats-tls
        service_name: minion-service-nats-tls
        addresses:
        - ip: ~
        # To support multi-clusters, fill the provider link secrets context of nats_tls, for example:
        # link: |
        #   ---
        #   nats.user: "nats"
        #   nats.password: "xxxxxx"
        #   nats.hostname: "nats"
        #   nats.port: 4223
        #   nats.external.tls.ca: ""
        link: ~
      routing_api:
        secret_name: minion-link-routing-api
        service_name: minion-service-routing-api
        addresses:
        - ip: ~
        # To support multi-clusters, fill the provider link secrets context of routing-api, for example:
        # link: |
        #   routing_api.clients: ~
        #   routing_api.system_domain: "xxx.xxx.xxx"
        #   routing_api.port: 3000
        #   routing_api.mtls_port: 3001
        #   routing_api.mtls_ca: |
        #     -----BEGIN CERTIFICATE-----
        #     xxxxxx
        #     -----END CERTIFICATE-----
        #   ......
        link: ~
      doppler:
        secret_name: minion-link-doppler
        service_name: minion-service-doppler
        addresses:
        - ip: ~
        # To support multi-clusters, fill the provider link secrets context of doppler, for example:
        # link: |
        #   doppler.grpc_port: 8082
        link: ~
      loggregator:
        secret_name: minion-link-loggregator
        service_name: minion-service-loggregator
        addresses:
        - ip: ~
        # To support multi-clusters, fill the provider link secrets context of loggregator, for example:
        # link: |
        #   loggregator.tls.ca_cert: |
        #     -----BEGIN CERTIFICATE-----
        #     xxxxxx
        #     -----END CERTIFICATE-----
        #   ......
        link: ~
      cloud_controller:
        secret_name: minion-link-cloud-controller
        service_name: minion-service-cloud-controller
        addresses:
        - ip: ~
        # To support multi-clusters, fill the provider link secrets context of cloud-controller, for example:
        # link: |
        #   system_domain: "{{ .Values.system_domain }}"
        #   app_domains: []
        link: ~
      cloud_controller_container_networking_info:
        secret_name: minion-link-cloud-controller-container-networking-info
        service_name: minion-service-cloud-controller-container-networking-info
        addresses:
        - ip: ~
        # link: |
        #   cc.internal_route_vip_range: "127.128.0.0/9"
        link: ~
      cf_network:
        secret_name: minion-link-cf-network
        service_name: minion-service-cf-network
        addresses:
        - ip: ~
        # link: |
        #   network: "10.255.0.0/16"
        #   subnet_prefix_length: 24
        link: ~
  ingress:
    enabled: false
    tls:
      # TLS certificate for the ingress controller.  This should be a wildcard certificate for the
      # system domain (*.example.com, where api.example.com is the API endpoint).  It should also
      # include the full certificate chain (that is, include the intermediate certificates).
      crt: ~
      # TLS certificate private key for the ingress controller, matching features.ingress.tls.crt.
      key: ~
    annotations: {}
    labels: {}
  autoscaler:
    # Enable the application autoscaler.  The autoscaler service must be manually registered; see
    # https://github.com/cloudfoundry/app-autoscaler-release#register-service for details.
    enabled: false
    mysql:
      enabled: false
  credhub:
    # Enable credhub; this is only used as a service broker for applications, and is not used for
    # authentication with the Cloud Foundry deployment.
    enabled: true
  routing_api:
    # Enable the routing API.  Disabling this will also disable TCP routing, which is used for TCP
    # port forwarding.
    # Enabled by default, except under Eirini, where the routing-api is not (yet) supported.
    enabled: ~
  embedded_database:
    # Enable the embedded database.  If this is disabled, then features.external_database should be
    # configured to use an external database.
    enabled: true
    # Number of seconds to wait for the database to be ready, per iteration of the waiter loop
    connect_timeout: 3
  blobstore:
    # Possible values for provider: singleton and s3.
    provider: singleton
    s3:
      aws_region: ~
      blobstore_access_key_id: ~
      blobstore_secret_access_key: ~
      blobstore_admin_users_password: ~
      # The following values are used as S3 bucket names.
      app_package_directory_key: ~
      buildpack_directory_key: ~
      droplet_directory_key: ~
      resource_directory_key: ~

  # Configuration for the external database; see also features.embedded_database.  Please refer to
  # https://kubecf.io/docs/deployment/kubernetes-deploy/#external-database for details.
  external_database:
    enabled: false
    require_ssl: false
    ca_cert: ~
    # The external database type; it can be either 'mysql' or 'postgres'.
    type: ~
    host: ~
    port: ~
    # Number of seconds to wait for the database to be ready, per iteration of the waiter loop
    connect_timeout: 3
    # If seed is set to true, we will initialize the database using the provided
    # root password (see `.variables.pxc-root-password`); in that case it is not
    # necessary to provide the configuration for the individual databases.
    seed: false
    databases:
      uaa:
        name: uaa
        password: ~
        username: ~
      cc:
        name: cloud_controller
        password: ~
        username: ~
      bbs:
        name: diego
        password: ~
        username: ~
      routing_api:
        name: routing-api
        password: ~
        username: ~
      policy_server:
        name: network_policy
        password: ~
        username: ~
      silk_controller:
        name: network_connectivity
        password: ~
        username: ~
      locket:
        name: locket
        password: ~
        username: ~
      credhub:
        name: credhub
        password: ~
        username: ~

# Enable or disable instance groups for the different test suites.
# Only smoke tests should be run in production environments.
testing:
  # __ATTENTION__: The brain tests do things with the cluster which
  # required them to have `cluster-admin` permissions (i.e. root).
  # Enabling them is thus potentially insecure. They should only be
  # activated for isolated testing.
  brain_tests:
    enabled: false
    # Delete the testing pod after completion (default: false)
    delete_pod: false
  cf_acceptance_tests:
    enabled: false
    # Delete the testing pod after completion (default: false)
    delete_pod: false
  smoke_tests:
    enabled: true
    # Delete the testing pod after completion (default: false)
    delete_pod: false
  sync_integration_tests:
    enabled: false
    # Delete the testing pod after completion (default: false)
    delete_pod: false

ccdb:
  encryption:
    # Configure CCDB key rotation.  Please see
    # https://kubecf.io/docs/tasks/secrets/#rotating-the-ccdb-encryption-keys for details.
    rotation:
      # Key labels must be &lt;= 240 characters long.
      key_labels:
      - encryption_key_0
      current_key_label: encryption_key_0

operations:
  # A list of configmap names that should be applied to the BOSH manifest.
  custom: []
  # Inlined operations that get into generated ConfigMaps. E.g. adding a password variable:
  # operations:
  #   inline:
  #   - type: replace
  #     path: /variables/-
  #     value:
  #       name: my_password
  #       type: password
  inline: []

eirinix:
  persi-broker:
    # Service plans for Eirini persistant storage support
    service-plans:
    - id: default
      name: "default"
      description: "Existing default storage class"
      kube_storage_class: ~
      free: true
      default_size: "1Gi"
    description: Eirini persistence broker
    long_description: Eirini persistence broker to provide Kubernete storage classes
    provider_display_name: Eirini broker
    documentation_url: https://github.com/SUSE/eirini-persi-broker
    support_url: https://github.com/SUSE/eirini-persi-broker/issues
    display_name: Eirini broker
    icon_image: Eirini broker
    secrets:
      auth-password: ~ # Password is randomly generated if not given</pre></div></div><div class="sect1 " id="app-cf-operator-values-yaml"><div class="titlepage"><div><div><h2 class="title"><span class="number">A.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Complete suse/cf-operator values.yaml File</span> <a title="Permalink" class="permalink" href="#app-cf-operator-values-yaml">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>app_cf_operator_values_yaml.xml</li><li><span class="ds-label">ID: </span>app-cf-operator-values-yaml</li></ul></div></div></div></div><p>
  This is the complete output of <code class="command">helm inspect values suse/cf-operator</code> for
  the current SUSE Cloud Application Platform 2.1.0 release.
 </p><div class="verbatim-wrap"><pre class="screen">## Default values for Cf-operator Helm Chart.
## This is a YAML-formatted file.
## Declare variables to be passed into your templates.


# applyCRD is a boolean to control the installation of CRD's.
applyCRD: true

cluster:
  # domain is the the Kubernetes cluster domain
  domain: "cluster.local"

# createWatchNamespace is a boolean to control creation of the watched namespace.
createWatchNamespace: true

# fullnameOverride overrides the release name
fullnameOverride: ""

# image is the docker image of quarks job.
image:
  # repository that provides the operator docker image.
  repository: cf-operator
  # org that provides the operator docker image.
  org: registry.suse.com/cap
  # tag of the operator docker image
  tag: v4.5.13-0.gd4738712

# logrotateInterval is the time between logrotate calls for instance groups in minutes
logrotateInterval: 1440

# logLevel defines from which level the logs should be printed (trace,debug,info,warn).
logLevel: debug

# workers are the int values for running maximum number of workers of the respective controller.
workers:
  boshdeployment: 1
  quarksSecret: 1
  quarksStatefulset: 1

operator:
  webhook:
    # host under which the webhook server can be reached from the cluster
    host: ~
    # port the webhook server listens on
    port: "2999"
  # boshDNSDockerImage is the docker image used for emulating bosh DNS (a CoreDNS image).
  boshDNSDockerImage: "registry.suse.com/cap/coredns:0.1.0-1.6.7-bp152.1.2"

# nameOverride overrides the chart name part of the release name
nameOverride: ""

# serviceAccount contains the configuration
# values of the service account used by cf-operator.
serviceAccount:
  # create is a boolean to control the creation of service account name.
  create: true
  # name of the service account.
  name:

global:
  # Context Timeout for each K8's API request in seconds.
  contextTimeout: 300
  image:
    # pullPolicy defines the policy used for pulling docker images.
    pullPolicy: IfNotPresent
    # credentials is used for pulling docker images.
    credentials: ~
      # username:
      # password:
      # servername:
  operator:
    # watchNamespace is used for watching the BOSH deployments.
    watchNamespace: staging
    webhook:
      # useServiceReference is a boolean to control the use of the
      # service reference in the webhook spec instead of a url.
      useServiceReference: true

  rbac:
    # create is a boolean to control the installation of quarks job cluster role template.
    create: true

quarks-job:
  # createWatchNamespace is a boolean to control creation of the watched namespace.
  createWatchNamespace: false
  serviceAccount:
    # create is a boolean to control the creation of service account name.
    create: true
    # name of the service account.
    name:</pre></div></div></div><div class="legal-section"><div class="appendix " id="id-1.3.9"><div class="titlepage"><div><div><h1 class="title"><span class="number">B </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GNU Licenses</span> <a title="Permalink" class="permalink" href="#id-1.3.9">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_legal.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.3.9.4"><span class="number">B.1 </span><span class="name">GNU Free Documentation License</span></a></span></dt></dl></div></div><p>
  This appendix contains the GNU Free Documentation License version 1.2.
 </p><div class="sect1 " id="id-1.3.9.4"><div class="titlepage"><div><div><h2 class="title legal"><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GNU Free Documentation License</span> <a title="Permalink" class="permalink" href="#id-1.3.9.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>common_gfdl1.2_i.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
  Copyright (C) 2000, 2001, 2002 Free Software Foundation, Inc. 51 Franklin St,
  Fifth Floor, Boston, MA 02110-1301 USA. Everyone is permitted to copy and
  distribute verbatim copies of this license document, but changing it is not
  allowed.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.4"><span class="name">
    0. PREAMBLE
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.4">#</a></h5></div><p>
  The purpose of this License is to make a manual, textbook, or other
  functional and useful document "free" in the sense of freedom: to assure
  everyone the effective freedom to copy and redistribute it, with or without
  modifying it, either commercially or non-commercially. Secondarily, this
  License preserves for the author and publisher a way to get credit for their
  work, while not being considered responsible for modifications made by
  others.
 </p><p>
  This License is a kind of "copyleft", which means that derivative works of
  the document must themselves be free in the same sense. It complements the
  GNU General Public License, which is a copyleft license designed for free
  software.
 </p><p>
  We have designed this License to use it for manuals for free software,
  because free software needs free documentation: a free program should come
  with manuals providing the same freedoms that the software does. But this
  License is not limited to software manuals; it can be used for any textual
  work, regardless of subject matter or whether it is published as a printed
  book. We recommend this License principally for works whose purpose is
  instruction or reference.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.8"><span class="name">
    1. APPLICABILITY AND DEFINITIONS
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.8">#</a></h5></div><p>
  This License applies to any manual or other work, in any medium, that
  contains a notice placed by the copyright holder saying it can be distributed
  under the terms of this License. Such a notice grants a world-wide,
  royalty-free license, unlimited in duration, to use that work under the
  conditions stated herein. The "Document", below, refers to any such manual or
  work. Any member of the public is a licensee, and is addressed as "you". You
  accept the license if you copy, modify or distribute the work in a way
  requiring permission under copyright law.
 </p><p>
  A "Modified Version" of the Document means any work containing the Document
  or a portion of it, either copied verbatim, or with modifications and/or
  translated into another language.
 </p><p>
  A "Secondary Section" is a named appendix or a front-matter section of the
  Document that deals exclusively with the relationship of the publishers or
  authors of the Document to the Document's overall subject (or to related
  matters) and contains nothing that could fall directly within that overall
  subject. (Thus, if the Document is in part a textbook of mathematics, a
  Secondary Section may not explain any mathematics.) The relationship could be
  a matter of historical connection with the subject or with related matters,
  or of legal, commercial, philosophical, ethical or political position
  regarding them.
 </p><p>
  The "Invariant Sections" are certain Secondary Sections whose titles are
  designated, as being those of Invariant Sections, in the notice that says
  that the Document is released under this License. If a section does not fit
  the above definition of Secondary then it is not allowed to be designated as
  Invariant. The Document may contain zero Invariant Sections. If the Document
  does not identify any Invariant Sections then there are none.
 </p><p>
  The "Cover Texts" are certain short passages of text that are listed, as
  Front-Cover Texts or Back-Cover Texts, in the notice that says that the
  Document is released under this License. A Front-Cover Text may be at most 5
  words, and a Back-Cover Text may be at most 25 words.
 </p><p>
  A "Transparent" copy of the Document means a machine-readable copy,
  represented in a format whose specification is available to the general
  public, that is suitable for revising the document straightforwardly with
  generic text editors or (for images composed of pixels) generic paint
  programs or (for drawings) some widely available drawing editor, and that is
  suitable for input to text formatters or for automatic translation to a
  variety of formats suitable for input to text formatters. A copy made in an
  otherwise Transparent file format whose markup, or absence of markup, has
  been arranged to thwart or discourage subsequent modification by readers is
  not Transparent. An image format is not Transparent if used for any
  substantial amount of text. A copy that is not "Transparent" is called
  "Opaque".
 </p><p>
  Examples of suitable formats for Transparent copies include plain ASCII
  without markup, Texinfo input format, LaTeX input format, SGML or XML using a
  publicly available DTD, and standard-conforming simple HTML, PostScript or
  PDF designed for human modification. Examples of transparent image formats
  include PNG, XCF and JPG. Opaque formats include proprietary formats that can
  be read and edited only by proprietary word processors, SGML or XML for which
  the DTD and/or processing tools are not generally available, and the
  machine-generated HTML, PostScript or PDF produced by some word processors
  for output purposes only.
 </p><p>
  The "Title Page" means, for a printed book, the title page itself, plus such
  following pages as are needed to hold, legibly, the material this License
  requires to appear in the title page. For works in formats which do not have
  any title page as such, "Title Page" means the text near the most prominent
  appearance of the work's title, preceding the beginning of the body of the
  text.
 </p><p>
  A section "Entitled XYZ" means a named subunit of the Document whose title
  either is precisely XYZ or contains XYZ in parentheses following text that
  translates XYZ in another language. (Here XYZ stands for a specific section
  name mentioned below, such as "Acknowledgements", "Dedications",
  "Endorsements", or "History".) To "Preserve the Title" of such a section when
  you modify the Document means that it remains a section "Entitled XYZ"
  according to this definition.
 </p><p>
  The Document may include Warranty Disclaimers next to the notice which states
  that this License applies to the Document. These Warranty Disclaimers are
  considered to be included by reference in this License, but only as regards
  disclaiming warranties: any other implication that these Warranty Disclaimers
  may have is void and has no effect on the meaning of this License.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.19"><span class="name">
    2. VERBATIM COPYING
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.19">#</a></h5></div><p>
  You may copy and distribute the Document in any medium, either commercially
  or non-commercially, provided that this License, the copyright notices, and
  the license notice saying this License applies to the Document are reproduced
  in all copies, and that you add no other conditions whatsoever to those of
  this License. You may not use technical measures to obstruct or control the
  reading or further copying of the copies you make or distribute. However, you
  may accept compensation in exchange for copies. If you distribute a large
  enough number of copies you must also follow the conditions in section 3.
 </p><p>
  You may also lend copies, under the same conditions stated above, and you may
  publicly display copies.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.22"><span class="name">
    3. COPYING IN QUANTITY
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.22">#</a></h5></div><p>
  If you publish printed copies (or copies in media that commonly have printed
  covers) of the Document, numbering more than 100, and the Document's license
  notice requires Cover Texts, you must enclose the copies in covers that
  carry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the
  front cover, and Back-Cover Texts on the back cover. Both covers must also
  clearly and legibly identify you as the publisher of these copies. The front
  cover must present the full title with all words of the title equally
  prominent and visible. You may add other material on the covers in addition.
  Copying with changes limited to the covers, as long as they preserve the
  title of the Document and satisfy these conditions, can be treated as
  verbatim copying in other respects.
 </p><p>
  If the required texts for either cover are too voluminous to fit legibly, you
  should put the first ones listed (as many as fit reasonably) on the actual
  cover, and continue the rest onto adjacent pages.
 </p><p>
  If you publish or distribute Opaque copies of the Document numbering more
  than 100, you must either include a machine-readable Transparent copy along
  with each Opaque copy, or state in or with each Opaque copy a
  computer-network location from which the general network-using public has
  access to download using public-standard network protocols a complete
  Transparent copy of the Document, free of added material. If you use the
  latter option, you must take reasonably prudent steps, when you begin
  distribution of Opaque copies in quantity, to ensure that this Transparent
  copy will remain thus accessible at the stated location until at least one
  year after the last time you distribute an Opaque copy (directly or through
  your agents or retailers) of that edition to the public.
 </p><p>
  It is requested, but not required, that you contact the authors of the
  Document well before redistributing any large number of copies, to give them
  a chance to provide you with an updated version of the Document.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.27"><span class="name">
    4. MODIFICATIONS
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.27">#</a></h5></div><p>
  You may copy and distribute a Modified Version of the Document under the
  conditions of sections 2 and 3 above, provided that you release the Modified
  Version under precisely this License, with the Modified Version filling the
  role of the Document, thus licensing distribution and modification of the
  Modified Version to whoever possesses a copy of it. In addition, you must do
  these things in the Modified Version:
 </p><div class="orderedlist "><ol class="orderedlist" type="A"><li class="listitem "><p>
    Use in the Title Page (and on the covers, if any) a title distinct from
    that of the Document, and from those of previous versions (which should, if
    there were any, be listed in the History section of the Document). You may
    use the same title as a previous version if the original publisher of that
    version gives permission.
   </p></li><li class="listitem "><p>
    List on the Title Page, as authors, one or more persons or entities
    responsible for authorship of the modifications in the Modified Version,
    together with at least five of the principal authors of the Document (all
    of its principal authors, if it has fewer than five), unless they release
    you from this requirement.
   </p></li><li class="listitem "><p>
    State on the Title page the name of the publisher of the Modified Version,
    as the publisher.
   </p></li><li class="listitem "><p>
    Preserve all the copyright notices of the Document.
   </p></li><li class="listitem "><p>
    Add an appropriate copyright notice for your modifications adjacent to the
    other copyright notices.
   </p></li><li class="listitem "><p>
    Include, immediately after the copyright notices, a license notice giving
    the public permission to use the Modified Version under the terms of this
    License, in the form shown in the Addendum below.
   </p></li><li class="listitem "><p>
    Preserve in that license notice the full lists of Invariant Sections and
    required Cover Texts given in the Document's license notice.
   </p></li><li class="listitem "><p>
    Include an unaltered copy of this License.
   </p></li><li class="listitem "><p>
    Preserve the section Entitled "History", Preserve its Title, and add to it
    an item stating at least the title, year, new authors, and publisher of the
    Modified Version as given on the Title Page. If there is no section
    Entitled "History" in the Document, create one stating the title, year,
    authors, and publisher of the Document as given on its Title Page, then add
    an item describing the Modified Version as stated in the previous sentence.
   </p></li><li class="listitem "><p>
    Preserve the network location, if any, given in the Document for public
    access to a Transparent copy of the Document, and likewise the network
    locations given in the Document for previous versions it was based on.
    These may be placed in the "History" section. You may omit a network
    location for a work that was published at least four years before the
    Document itself, or if the original publisher of the version it refers to
    gives permission.
   </p></li><li class="listitem "><p>
    For any section Entitled "Acknowledgements" or "Dedications", Preserve the
    Title of the section, and preserve in the section all the substance and
    tone of each of the contributor acknowledgements and/or dedications given
    therein.
   </p></li><li class="listitem "><p>
    Preserve all the Invariant Sections of the Document, unaltered in their
    text and in their titles. Section numbers or the equivalent are not
    considered part of the section titles.
   </p></li><li class="listitem "><p>
    Delete any section Entitled "Endorsements". Such a section may not be
    included in the Modified Version.
   </p></li><li class="listitem "><p>
    Do not retitle any existing section to be Entitled "Endorsements" or to
    conflict in title with any Invariant Section.
   </p></li><li class="listitem "><p>
    Preserve any Warranty Disclaimers.
   </p></li></ol></div><p>
  If the Modified Version includes new front-matter sections or appendices that
  qualify as Secondary Sections and contain no material copied from the
  Document, you may at your option designate some or all of these sections as
  invariant. To do this, add their titles to the list of Invariant Sections in
  the Modified Version's license notice. These titles must be distinct from any
  other section titles.
 </p><p>
  You may add a section Entitled "Endorsements", provided it contains nothing
  but endorsements of your Modified Version by various parties--for example,
  statements of peer review or that the text has been approved by an
  organization as the authoritative definition of a standard.
 </p><p>
  You may add a passage of up to five words as a Front-Cover Text, and a
  passage of up to 25 words as a Back-Cover Text, to the end of the list of
  Cover Texts in the Modified Version. Only one passage of Front-Cover Text and
  one of Back-Cover Text may be added by (or through arrangements made by) any
  one entity. If the Document already includes a cover text for the same cover,
  previously added by you or by arrangement made by the same entity you are
  acting on behalf of, you may not add another; but you may replace the old
  one, on explicit permission from the previous publisher that added the old
  one.
 </p><p>
  The author(s) and publisher(s) of the Document do not by this License give
  permission to use their names for publicity for or to assert or imply
  endorsement of any Modified Version.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.34"><span class="name">
    5. COMBINING DOCUMENTS
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.34">#</a></h5></div><p>
  You may combine the Document with other documents released under this
  License, under the terms defined in section 4 above for modified versions,
  provided that you include in the combination all of the Invariant Sections of
  all of the original documents, unmodified, and list them all as Invariant
  Sections of your combined work in its license notice, and that you preserve
  all their Warranty Disclaimers.
 </p><p>
  The combined work need only contain one copy of this License, and multiple
  identical Invariant Sections may be replaced with a single copy. If there are
  multiple Invariant Sections with the same name but different contents, make
  the title of each such section unique by adding at the end of it, in
  parentheses, the name of the original author or publisher of that section if
  known, or else a unique number. Make the same adjustment to the section
  titles in the list of Invariant Sections in the license notice of the
  combined work.
 </p><p>
  In the combination, you must combine any sections Entitled "History" in the
  various original documents, forming one section Entitled "History"; likewise
  combine any sections Entitled "Acknowledgements", and any sections Entitled
  "Dedications". You must delete all sections Entitled "Endorsements".
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.38"><span class="name">
    6. COLLECTIONS OF DOCUMENTS
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.38">#</a></h5></div><p>
  You may make a collection consisting of the Document and other documents
  released under this License, and replace the individual copies of this
  License in the various documents with a single copy that is included in the
  collection, provided that you follow the rules of this License for verbatim
  copying of each of the documents in all other respects.
 </p><p>
  You may extract a single document from such a collection, and distribute it
  individually under this License, provided you insert a copy of this License
  into the extracted document, and follow this License in all other respects
  regarding verbatim copying of that document.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.41"><span class="name">
    7. AGGREGATION WITH INDEPENDENT WORKS
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.41">#</a></h5></div><p>
  A compilation of the Document or its derivatives with other separate and
  independent documents or works, in or on a volume of a storage or
  distribution medium, is called an "aggregate" if the copyright resulting from
  the compilation is not used to limit the legal rights of the compilation's
  users beyond what the individual works permit. When the Document is included
  in an aggregate, this License does not apply to the other works in the
  aggregate which are not themselves derivative works of the Document.
 </p><p>
  If the Cover Text requirement of section 3 is applicable to these copies of
  the Document, then if the Document is less than one half of the entire
  aggregate, the Document's Cover Texts may be placed on covers that bracket
  the Document within the aggregate, or the electronic equivalent of covers if
  the Document is in electronic form. Otherwise they must appear on printed
  covers that bracket the whole aggregate.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.44"><span class="name">
    8. TRANSLATION
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.44">#</a></h5></div><p>
  Translation is considered a kind of modification, so you may distribute
  translations of the Document under the terms of section 4. Replacing
  Invariant Sections with translations requires special permission from their
  copyright holders, but you may include translations of some or all Invariant
  Sections in addition to the original versions of these Invariant Sections.
  You may include a translation of this License, and all the license notices in
  the Document, and any Warranty Disclaimers, provided that you also include
  the original English version of this License and the original versions of
  those notices and disclaimers. In case of a disagreement between the
  translation and the original version of this License or a notice or
  disclaimer, the original version will prevail.
 </p><p>
  If a section in the Document is Entitled "Acknowledgements", "Dedications",
  or "History", the requirement (section 4) to Preserve its Title (section 1)
  will typically require changing the actual title.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.47"><span class="name">
    9. TERMINATION
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.47">#</a></h5></div><p>
  You may not copy, modify, sublicense, or distribute the Document except as
  expressly provided for under this License. Any other attempt to copy, modify,
  sublicense or distribute the Document is void, and will automatically
  terminate your rights under this License. However, parties who have received
  copies, or rights, from you under this License will not have their licenses
  terminated so long as such parties remain in full compliance.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.49"><span class="name">
    10. FUTURE REVISIONS OF THIS LICENSE
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.49">#</a></h5></div><p>
  The Free Software Foundation may publish new, revised versions of the GNU
  Free Documentation License from time to time. Such new versions will be
  similar in spirit to the present version, but may differ in detail to address
  new problems or concerns. See
  <a class="link" href="http://www.gnu.org/copyleft/" target="_blank">http://www.gnu.org/copyleft/</a>.
 </p><p>
  Each version of the License is given a distinguishing version number. If the
  Document specifies that a particular numbered version of this License "or any
  later version" applies to it, you have the option of following the terms and
  conditions either of that specified version or of any later version that has
  been published (not as a draft) by the Free Software Foundation. If the
  Document does not specify a version number of this License, you may choose
  any version ever published (not as a draft) by the Free Software Foundation.
 </p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title legal" id="id-1.3.9.4.52"><span class="name">
    ADDENDUM: How to use this License for your documents
  </span><a title="Permalink" class="permalink" href="#id-1.3.9.4.52">#</a></h5></div><div class="verbatim-wrap"><pre class="screen">Copyright (c) YEAR YOUR NAME.
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.2
or any later version published by the Free Software Foundation;
with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts.
A copy of the license is included in the section entitled “GNU
Free Documentation License”.</pre></div><p>
  If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts,
  replace the “with...Texts.” line with this:
 </p><div class="verbatim-wrap"><pre class="screen">with the Invariant Sections being LIST THEIR TITLES, with the
Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST.</pre></div><p>
  If you have Invariant Sections without Cover Texts, or some other combination
  of the three, merge those two alternatives to suit the situation.
 </p><p>
  If your document contains nontrivial examples of program code, we recommend
  releasing these examples in parallel under your choice of free software
  license, such as the GNU General Public License, to permit their use in free
  software.
 </p></div></div></div></div></div><div class="page-bottom"><div class="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span class="_share-fb bottom-button">Facebook</span><span class="spacer"> • </span><span class="_share-in bottom-button">LinkedIn</span><span class="spacer"> • </span><span class="_share-tw bottom-button">Twitter</span><span class="spacer"> • </span><span class="_share-mail bottom-button">E-Mail</span></span></div><div class="print"><span class="_print-button bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2021 
        SUSE</p><ul><li><a href="https://jobs.suse.com/" target="_top">Careers</a></li><li><a href="https://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="https://www.suse.com/company/about/" target="_top">About</a></li><li><a href="https://www.suse.com/contact/" target="_top">Contact Us</a></li></ul></div></div></body></html>